{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf0e2f4",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1f5a4",
   "metadata": {},
   "source": [
    "## Note to students.\n",
    "During periods of high load you may find the notebook unresponsive. It may appear to execute a cell, update the completion number in brackets [#] at the left of the cell but you may find the cell has not executed. This is particularly obvious on print statements when there is no output. If this happens, restart the kernel using the command under the Kernel tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038ef6a",
   "metadata": {},
   "source": [
    "## Retrieval augmented generation\n",
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41284636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce95c4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.78.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.78.0-py3-none-any.whl (680 kB)\n",
      "   ---------------------------------------- 0.0/680.4 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 262.1/680.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 680.4/680.4 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------- ----------------------------- 1/4 [jiter]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ---------------------------------------- 4/4 [openai]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 openai-1.78.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff6e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1bd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load variables from .env into the environment, load_dotenv() by default loads from .env in the current directory.\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c5b67",
   "metadata": {},
   "source": [
    "## PDFs\n",
    "Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21479aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.4.0\n"
     ]
    }
   ],
   "source": [
    "# The course will show the pip installs you would need to install packages on your own machine.\n",
    "# These packages are already installed on this platform and should not be run again.\n",
    "! pip install pypdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102777c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c29cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d3b72",
   "metadata": {},
   "source": [
    "Each page is a Document.\n",
    "\n",
    "A Document contains text (page_content) and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10979ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c498c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a872d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3492cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed023a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc7adbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e86cbec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c0dacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817343a",
   "metadata": {},
   "source": [
    "## YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b5c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade --quiet  youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c13932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade --quiet  pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba30b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade --quiet yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8564984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loader with desired parameters\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    #\"https://www.youtube.com/watch?v=jGwO_UgTS7I\",  # Replace with your video's URL\n",
    "    \"https://www.youtube.com/watch?v=x8FASlLf5ls\",\n",
    "    add_video_info=False,                         # Set to True to fetch video metadata\n",
    "    language=[\"zh\", \"en\"],                             # Specify transcript language(s)\n",
    "    translation=\"en\"                             # Translate transcript if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bdeb6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e2ac3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bba653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'jGwO_UgTS7I'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6c6cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "787d3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_youtube_metadata(url: str):\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'skip_download': True,  # Don't download the video\n",
    "        'extract_flat': False,  # Extract full metadata\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "        return {\n",
    "            \"title\": info.get(\"title\"),\n",
    "            \"description\": info.get(\"description\"),\n",
    "            \"upload_date\": info.get(\"upload_date\"),\n",
    "            \"duration\": info.get(\"duration\"),\n",
    "            \"view_count\": info.get(\"view_count\"),\n",
    "            \"like_count\": info.get(\"like_count\"),\n",
    "            \"channel\": info.get(\"uploader\"),\n",
    "            \"channel_url\": info.get(\"uploader_url\"),\n",
    "            \"tags\": info.get(\"tags\"),\n",
    "            \"categories\": info.get(\"categories\"),\n",
    "            \"thumbnail\": info.get(\"thumbnail\"),\n",
    "            \"webpage_url\": info.get(\"webpage_url\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35cf6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Stanford CS229: Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018)', 'description': \"For more information about Stanford’s Artificial Intelligence professional and graduate programs, visit: https://stanford.io/ai\\n\\nListen to the first lecture in Andrew Ng's machine learning course. This course provides a broad introduction to machine learning and statistical pattern recognition. Learn about both supervised and unsupervised learning as well as learning theory, reinforcement learning and control. Explore recent applications of machine learning and design and develop algorithms for machines.\\n\\nAndrew Ng is an Adjunct Professor of Computer Science at Stanford University. View more about Andrew on his website: https://www.andrewng.org/\\n \\nTo follow along with the course schedule and syllabus, visit: \\nhttp://cs229.stanford.edu/syllabus-autumn2018.html\\n\\n0:00 Introduction\\n05:21 Teaching team introductions\\n06:42 Goals for the course and the state of machine learning across research and industry\\n10:09 Prerequisites for the course\\n11:53 Homework, and a note about the Stanford honor code\\n16:57 Overview of the class project\\n25:57 Questions\\n\\n#AndrewNg #machinelearning\", 'upload_date': '20200417', 'duration': 4520, 'view_count': 3465335, 'like_count': 45314, 'channel': 'Stanford Online', 'channel_url': 'https://www.youtube.com/@stanfordonline', 'tags': ['Andrew Ng', 'Computer Science', 'Stanford', 'Machine Learning', 'Graduate Course', 'Artificial Intelligence', 'AI', 'Stanford Online', 'ML'], 'categories': ['Education'], 'thumbnail': 'https://i.ytimg.com/vi/jGwO_UgTS7I/maxresdefault.jpg', 'webpage_url': 'https://www.youtube.com/watch?v=jGwO_UgTS7I'}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "#url = \"https://www.youtube.com/watch?v=x8FASlLf5ls\"\n",
    "metadata = fetch_youtube_metadata(url)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b317204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'description',\n",
       " 'upload_date',\n",
       " 'duration',\n",
       " 'view_count',\n",
       " 'like_count',\n",
       " 'channel',\n",
       " 'channel_url',\n",
       " 'tags',\n",
       " 'categories',\n",
       " 'thumbnail',\n",
       " 'webpage_url']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "265f99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata = metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61c5393c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Stanford CS229: Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018)',\n",
       " 'description': \"For more information about Stanford’s Artificial Intelligence professional and graduate programs, visit: https://stanford.io/ai\\n\\nListen to the first lecture in Andrew Ng's machine learning course. This course provides a broad introduction to machine learning and statistical pattern recognition. Learn about both supervised and unsupervised learning as well as learning theory, reinforcement learning and control. Explore recent applications of machine learning and design and develop algorithms for machines.\\n\\nAndrew Ng is an Adjunct Professor of Computer Science at Stanford University. View more about Andrew on his website: https://www.andrewng.org/\\n \\nTo follow along with the course schedule and syllabus, visit: \\nhttp://cs229.stanford.edu/syllabus-autumn2018.html\\n\\n0:00 Introduction\\n05:21 Teaching team introductions\\n06:42 Goals for the course and the state of machine learning across research and industry\\n10:09 Prerequisites for the course\\n11:53 Homework, and a note about the Stanford honor code\\n16:57 Overview of the class project\\n25:57 Questions\\n\\n#AndrewNg #machinelearning\",\n",
       " 'upload_date': '20200417',\n",
       " 'duration': 4520,\n",
       " 'view_count': 3465063,\n",
       " 'like_count': 45309,\n",
       " 'channel': 'Stanford Online',\n",
       " 'channel_url': 'https://www.youtube.com/@stanfordonline',\n",
       " 'tags': ['Andrew Ng',\n",
       "  'Computer Science',\n",
       "  'Stanford',\n",
       "  'Machine Learning',\n",
       "  'Graduate Course',\n",
       "  'Artificial Intelligence',\n",
       "  'AI',\n",
       "  'Stanford Online',\n",
       "  'ML'],\n",
       " 'categories': ['Education'],\n",
       " 'thumbnail': 'https://i.ytimg.com/vi/jGwO_UgTS7I/maxresdefault.jpg',\n",
       " 'webpage_url': 'https://www.youtube.com/watch?v=jGwO_UgTS7I'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04251c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5195b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import (\n",
    "    YoutubeAudioLoader,\n",
    ")\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers.audio import (\n",
    "    OpenAIWhisperParser,\n",
    "    OpenAIWhisperParserLocal,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade --quiet  yt_dlp\n",
    "#%pip install --upgrade --quiet  pydub\n",
    "#%pip install --upgrade --quiet  librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db05a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e80fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efe997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5168b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6816338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Karpathy lecture videos\n",
    "urls = [\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"]\n",
    "# Directory to save audio files\n",
    "save_dir = \"docs/youtube/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52b7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a flag to switch between local and remote parsing\n",
    "# change this to True if you want to use local parsing\n",
    "local = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SuperEngineer\\Training\\Cousera\\LangChain-Chat-with-Your-Data\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following model:  openai/whisper-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SuperEngineer\\Training\\Cousera\\LangChain-Chat-with-Your-Data\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Owner\\.cache\\huggingface\\hub\\models--openai--whisper-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading tv client config\n",
      "[youtube] jGwO_UgTS7I: Downloading tv player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] Destination: docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a\n",
      "[download] 100% of   69.76MiB in 00:00:35 at 1.95MiB/s   \n",
      "[FixupM4a] Correcting container of \"docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a\"\n",
      "[ExtractAudio] Not converting audio docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a; file is already in target format m4a\n",
      "Transcribing part docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SuperEngineer\\Training\\Cousera\\LangChain-Chat-with-Your-Data\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "# Transcribe the videos to text\n",
    "if local:\n",
    "    loader = GenericLoader(\n",
    "        YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal(language=\"en\")\n",
    "    )\n",
    "else:\n",
    "    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser(language=\"en\"))\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdfd96f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Welcome to CS229 Machine Learning. Some of you know that this class is for this Stanford for a long time. And this is often the class that I most look forward to teaching each year because this is where we've helped, I think several generations of Stanford students become experts in machine learning, got built many of their products and services and startups that I'm sure many of you, all of you are using today. So what I want to do today was spend some time talking over logistics and then spend some time giving you a beginning of an intro, talk a little bit about machine learning. So about two, three, nine. You know, all of you have been reading about AI in the news, about machine learning in the news. And you've pretty heard me or they say AI is a new electricity. Much less a rise of electricity about a hundred years ago, transform every major industry. I think AI, or really, we call it machine learning, but the rest of the world seems to call it AI. Machine learning and AI and deep learning will change the world. And I hope that through 2.29 we'll give you the tools you need so that you can be many of these future titans of industries, that you can be one, the girl that built, you know, hope the large tech companies do the amazing things they do, or build your own startup, or go into some other industry, go transform healthcare, or go transform transportation, or go build a self-driving car, and do all of these things that after this class, I think you'd be able to do. You know, the majority of students applying, the demand for AI skills, the demand for machine learning skills is so vast. I think you all know that. And I think it's because machine learning has advanced so rapidly in the last few years that there are so many opportunities to apply learning algorithms, right? Both in industry as well as in academia. I think today we have the English department professors trying to apply learning algorithms to understand history better. We have lawyers trying to apply machine learning to process legal documents and off campus, every company, both the tech companies as well as a lot of companies that you wouldn't consider tech companies, everything from manufacturing companies, the healthcare companies, the logistics companies are also trying to apply machine learning. So I think that if you look at it on a factual basis, the number of people doing very valuable machine learning projects today is much greater than it was six months ago, and six months ago, it's much greater than it was 12 months ago. And the amount of value, the amount of exciting meaningful work being done in machine learning is very strongly going up. And I think that given the rise of the amount of data we have, as well as the new machine learning tools that we have, it would be a long time before we run out of opportunities, before society as a whole has enough people with the machine learning skillset. So just as maybe 20 years ago was a good time to start working on this internet thing. A lot of people that started working on the internet like 20 years ago at fantastic careers, I think today is a wonderful time to jump to machine learning and the number of, and the opportunities for you to do unique things that no one is, no one else is doing, right? The opportunity for you to go to logistics company and find an exciting way to apply machine learning will be very high because chances are that logistics company has no one else even working on this because they probably can't, they may not be able to hire a fantastic Stanford student as a graduate CS239, right? Because they're just on the law of CS239 graduates around. So what I want to do today is do a quick intro, talk a little bit about logistics, and then we'll spend a second half of the day giving an overview and talk a little bit more about machine learning. And I apologize. I think that this room, according to that sign there, seats, what 300 something students? We have not quite 800 people enrolled in this class. So So if there are people outside and all of the classes are recorded, broadcast on the SPD, they usually, the videos usually made available same day. So for those of you that can't get into the room, my apologies. There were some years where even I had trouble getting into the room, but I'm glad you left me in. But hopefully you can watch, hopefully you can watch all of these things online shortly. Oh, I see, yes. Yeah. I don't know. It's a bit complicated. Yeah. Thank you. I think it's okay. Yeah. Next few classes, if you can squeeze in and use the D NTC. So for now, it might be too complicated. Okay. So quick and chose. Oh, I'm sorry, I should have introduced myself. My name is Andrew. And I want to introduce some of the rest of the teaching team as well. There's a class coordinator. She has been playing this role for many years now and helps keep the trains run on time and make sure that everything in class happens when it's supposed to. So, so, so should be a, and then what's real to have? Do you guys want to stand up? Be the co-head TA. So, our respective, theC students working with me. And so, bring a lot of technical experience, technical experience in machine learning as well as practical know-how on how to actually make these things work. And with the large class that we have, we have a large TA team. Maybe I won't introduce all of the TA's here today, but you meet many of them throughout the school. But the TAs expertise span everything from confusion to natural language processing, to computer biology, to robotics. And so through this quarter, as you work on your class projects, I hope that you get a lot of hope and advice and mentoring from the TAs, all of which all of whom have deep expertise, not just in machine learning, will often in a specific vertical application area of machine learning. So depending on what your project would try to match you to a TAs that can give you advice that's most relevant to whatever project you end up working on. So go out this class. I hope that after the next 10 weeks, you will be an expert in machine learning. It turns out that, you know, and I hope that after this class, you'll be able to go out and build very meaningful machine learning applications, either in an academic setting where hopefully you can apply it to your problems in mechanical engineering, electrical engineering, and English, and law, and education. All of this wonderful work that happens on campus, as well as after you graduate from Stanford to be able to apply it to whatever jobs you find. One of the things I find very exciting about machine learning is that it's no longer a pure tech company only kind of thing. I think that many years ago machine learning was like a thing that computer science department would do and that the elite AI companies like Google and Facebook and by-do and Microsoft would do. But now it is so pervasive that even companies that are not traditional tech companies see a huge need to apply these tools. And I find a lot of the most exciting work these days. And maybe some of you guys know my history, some of the buy-dates. I let the Google Brain team, which helped Google transform from what was already a great company 10 years ago to today, which is a great AI company and then I also let the AI group that I do and you know let the companies technology strategy to help by do also transform from what was already a great company many years ago to today arguably China's greatest AI company so having let the you know build the teams that let the AI transformations of two large tech companies I feel like that's a great thing to do but even beyond tech I think that there's a lot of exciting work to do as well to help other industries to help other sectors Embrace machine learning and use these tools effectively But after this class, I hope that each one of you will be well qualified to get a job at Shiny tech Company and do machine learning there or go into one of these industries and do very valuable machine learning projects there. And in addition, if any of you are taking this class with the primary goal of being able to do research in machine learning, you know, so actually some of you I our PhD students, I hope that this class will also leave you well equipped to really read and understand research papers as well as be qualified to start pushing forward the state of the art. So let's see. So today, so just as machine learning is evolving rapidly, the whole teaching team would be constantly updating CS222.9 as well. So it's actually very interesting. I feel like the pace of progress in machine learning has accelerated. So it actually feels like that the amount we changed the class year over year has been increasing over time. So if your friends took the class last year, things are a little bit different this year because we're constantly updating the class to keep up with what feels like still accelerating progress in the whole future machine learning. So there are some logistical changes. For example, we've gone from a, we used to hand out paper copies of handouts that we're trying to make this class digital only. But let me talk a little bit about prerequisites as well as in case your friends have taken this class before, some of the differences for this year. So prerequisites, We are going to assume that all of you have a knowledge of basic computer skills and principles. So, you know, big old notation, Q, Starrings, binary trees, hopefully you understand what all of those concepts are. And assume that all of you have a basic familiarity with probability, right? That hopefully, you know, what's the random variable, what's the expected value of a random variable, what's the variance of a random variable. And if, for some of you, maybe especially the SCP-D students taking turns in early, if it's been, you know, some number of years since you lost at a probability of statistics loss, we will have review sessions on Fridays where we'll go over some of these prerequisite materials as well. So hopefully you know what the random variables, what the expected value is, but if you're a little bit fuzzy on those concepts, we'll go over them again at a discussion section on Friday. Also assume the familiar basic linear algebra. So hopefully that you know what's the matrix, what's the vector, how to multiply two matrices, or multiply a matrix in a vector. If you know what an eigenvector, then that's even better. If you're not quite sure what an eigenvector is, we'll go over it. And then a large part of this class is having you practice these ideas through the homeworks as well as I mentioned later, an open-ended project. And so, one, we've actually, until now, we used to use MATLAB and ARCTI for the Fermi assignments. But this year we're trying to shift the programming assignments to Python. And so I think for a long time, even today, I sometimes use Octave to prototype because the syntax for Octave is so nice and just run very simple experiments very quickly. But I think the machine learning world is really migrating, I think, from Matt that Python world to increasing, excuse me, Matt that octave world to increasingly a Python maybe an then eventually for production in Java, C++ kind of world. And so we're rewriting a lot of the assignments that this causes quarter. Having driving that process so that this course that you could do more of the assignments, maybe all of the assignments in Python numpy instead. Now, note on the honor codes, we actually encourage you to form study groups. So up and fascinated by I've been fascinated by education for a long time. So, in a long time, studying education and pedagogy and how instructors like us can help support you to learn more efficiently. And one of the lessons I've learned from the educational research literature is that for highly technical classes like this, if you form study groups, you will probably have an easier time, right? So, CSU's denying we go for the highly technical material. There's a lot of math, some of the programs are hard, and if you have a group of friends to study with, you probably have an easier time because you can ask each other questions and work together to help each other. When we ask you to draw the line, or what we ask you to do relative to the standards on the code is We ask that you do the homework problems by yourself, right? And and and more specifically is okay to discuss the homework problems of friends, but if you But after discussing homework problems of friends, we ask you to go back and write up the solutions by yourself without referring to notes that you and your friends had developed together. The classes on the code is written clearly on the class on Handel's Posted digitally on the website. So if you ever have any questions about what is the log collaboration and what isn't allowed, please refer to that written document on the course website where we described it more clearly. But all the respect for the San Philanical as well as for students kind of doing their own work, we ask you to basically do your own work for the Zokid discuss it, but after discussing home problems with friends ultimately we ask you to write up your problems by yourself so that the whole world submissions reflect your own work, right? And I care about this because it turns out that having CS239, you know, CS239 is one of those classes that employers recognize. I don't know if you guys know, but there have been companies that have put up job ads that say stuff like, so long as you've got, so long as you complete a CS239, we guarantee you get an interview, right? I've seen stuff like that. And so I think, you know, in order to maintain that sanctity of what it means to be a CS239 competitor, I think, I asked it all of you, sort of really do your own work, or stay within the bounds of a set of collaboration relative to the on the code. Let's see. And I think that if, you know what, this is, and I think that one of the best parts of CS239, it turns out is, excuse me. So, sorry, I'm awkward. So one of the best parts of the class is, oh shoot, sorry about that. All right, no mind, I won't do this. You could do it on, you could do it yourself online later. Yeah, I started using Firefox recently in addition to Chrome. One of the best parts of the class is the class project. One of the goals of the class is to leave you well-qualified to do a meaningful machine learning project. One so one of the best ways to make sure you have that skillset is through this class and hopefully with the help of some of the T8, we want to support you to work on a small group to complete a meaningful machine learning project. And so one thing I hope you start doing later today is to start brainstorming maybe of your friends some of the class projects you might work on. And the most common class project that people do in CS2.9 is to pick an application that excites you and to apply machine learning to it and see if you can build a good machine learning system for some application in the area. And so if you go to the course website, you know, cs229.stamp.edu and look at previous years projects, you see machine learning projects applied to pretty much every imaginable application under the sun. Everything from, you know, diagnosed in cancer, to creating art, to lots of projects applied to other areas of engineering, applying to application areas in double E or mechanical engineering or so on, to applying it to understand literature, to applying it to, I don't know, and so if you look at the previous years projects, many of which are posted on the course website, you can use that as inspiration to see the types of projects students completing those classes are able to do and I also encourage you to, you can look at that for inspiration, to get a sense of what you'll be able to do at the conclusion of this class and also see if looking at previous years projects gives you inspiration for what you might do yourself. So we invite you, I guess, to do class projects in small groups. And so after class today, I also encourage you to start making friends in the class, both for the purpose of forming study groups as well as for the purpose of maybe finding a small group to do a class project with. We ask you the form project groups of up to size three, most project groups end up being size two or three. If you insist on doing it by yourself, right, without any partners, that's actually okay too, you're welcome to do that. But I think often, you know, having one or two others to work with may give you an easier time. And for projects of exceptional scope, if you have a very, very large project, they just cannot be done by three people. Sometimes, you know, let us know and we're open to some project groups of size four, but our expectation, but we do hold projects, you know, with a group of four to a higher standard than projects of size one to three. So what that means is that if your project team size is one, two, or three persons, the grading is one criteria. If your project group is bigger than three persons, we use a strict criteria when it comes to grading class projects. Oh, and that reminds me. I know that, let's see, so for most of you, since this started 9.30 AM on the first day of the quarter, for many of you, this may be, this probably your very first class at Stanford. How many of you, this is your very first class at Stanford? Wow, cool. Okay, awesome. Great. Welcome to Stanford. And if someone makes you just raise their hand, actually raise your hand again. So I hope that maybe after class today, if someone makes you raise your hand, I hope welcome them to Stanford and then say hi and she's so big friends after that. Cool, let's see, in addition to the main lectures that we'll have here on Mondays and Wednesdays, CS3.9 also has discussion sections on held on Fridays that are, and everything we do, including all the lectures and discussion sections that recorded and broadcast through SCPD, through the online website. And one of the discussion sections are taught usually by the TAs on Fridays and attendance at discussion sections is optional. And what I mean is that you know, you know, you're 100% promise there won't be material on the midterm that was sneakin' from the discussion section. So it's 100% optional. And you will be able to do all the homeworks and the projects without attending the discussion section. But what we're used to discussion section for, for the first V discussion sections. So, you know, this week, next week, week after that, we'll use the discussion sections to go over prerequisite material and greater depth. So, go over linear algebra, basic problem statistics, teach you a little bit about Python numpy in case you're less familiar with those programming frameworks. So, do that for the first few weeks. And then for the discussion sections that are held later this quarter, we'll usually use them to go over more advanced optional material. For example, CS239, a lot of the learning algorithms you hear about in the class rely on convex optimization algorithms. But we want to focus the class on the learning algorithms and spend less time on convex optimization. So if you want to come in here about more advanced concepts and convex optimization, we'll defer that to discussion section. And then there are a few other advanced topics, hidden markup models, time series that we're planning to defer to the Friday discussion sections. Okay. So let's see. Cool. And final bit of logistics for there are digital tools that some of you have seen. But for this class, we'll drive a lot of the discussion through the online website Piazza. How many of you have used Piazza before? Okay, cool, most of all of you, that's amazing. Good, so online discussion board for those of you that haven't seen it before but definitely encourage you to participate actively on Piazza and also to answer other students' questions. I think that one of the best ways to learn, as well as contribute back to the causes of ho is if you see someone else ask a question on Piazza, if you jump in and help answer that, that often helps you and helps your classmates. So I strongly encourage you to do that. For those of you that have a private question, sometimes we have students reaching out to us with a personal matter or something that is not appropriate to share on the public forum, in which case you're welcome to email us at the email address as well. And we also, and the cost email address, the teaching slots email address on the course website. You can find it there in contact us. But for anything technical or anything reasonable to share the cost, which includes most technical questions and most logistical questions, right? Questions like, you know, can you confirm what data is in the term or what happens? Can you confirm when's the handout for this going on and so on? For questions that are not personal or private in nature, strongly encourage you to post on P-Onswer rather than emailing us because statistically, you actually get a faster answer posting on P-Onswer than if you wait for one of us to respond to you. And we'll be using great scope as well for online grading. If you don't know what great scope is, don't worry about it. We'll send you links and show you how to use it later. And again, relative to one last logistical thing to plan for, unlike previous years where we taught CS229, so we're constantly updating the syllabus right the technical content to try to show you the latest when she learning algorithms and the two big little changes we're making this year I guess one is a Python instead of MATLAB and the other one is instead of having a midterm exam, you know, there's a timed midterm, we're planning to have a take-home midterm, the squatter, this day. So, I don't know. Some people just breathed in sharply when I said that. I don't know what that means. Was that shock or happiness? Okay. Don't worry, midterm's a fun. You love it. All right, so that's it for the logistical aspects. Let me check the, and so let me check there any questions. Oh yeah, go ahead. Oh, yeah, so that's interesting. Let's see, I think it's offered in spring and one other person. Oh, yes, and teaching it. So someone else is teaching it in spring quarter. I actually did not know it was going to be offered in winter. Yeah. Yeah, right. Yeah. Yeah. So I think I'm a great guy and teaching it. Sorry, you can go for a minute. Teaching it in a screen and I don't think it's offered in Windows. Well, this one section if you record it, yes, it will be. By the way, if you wonder why I'm repeating the question, I know it feels weird. I'm recording for the microphone so that people watching this can hear the question. But both the lectures and the discussion sections will be recorded and put on the website. Maybe the one thing we do that's not recorded and broadcast the office hours, right? Is that right? Oh, but I think this year we have a 60 hour, how many hours? 60 office hours per week. Right? Yeah. So, so hopefully, again, what constantly trying to improve the cause in previous years, one of the feedback we got was that the office hours are really crowded. So, we have 60 slots per week this year. That seems like a lot. So hopefully if you need to track down one of us, track down the tier to get help. Hopefully that'll make it easier for you to do so. Go ahead. Say the game. Well. Oh, well, it just go to the course website and click on the syllabus link, that has a calendar with when each homework assignment is called and when OP-DU. So full homeworks and a project proposal do a few weeks from now and then final projects do at the end of the quarter. But all the exact dates are listed on the course website. Thank you. Sure, yes. Difference between this class and 239A. Let me think how to answer that. Yes. So, yeah, I know I was debating earlier this morning how to answer that, because I've asked that a few times. So I think that what has happened at Stanford is that the volume of demand for machine learning education is just skyrocketing because everyone sees, everyone wants to learn this stuff. And so the computer science department has been trying to grow the number of machine learning offerings we have. We actually kept the enrollment of CS239A at a relatively low number at 100 students. So I actually don't want to encourage too many of you to sign up because I think we might be hitting the enrollment cap already. So please don't all sign up for CS239A because CS239A does not have the capacity to score. But CS239A is a much less mathematical and much more quite relatively more applied version of machine learning. And so I guess I'm teaching CS229, CS229, CS229 Discordero. Of the three, CS229 is the most mathematical. It is a little bit less applied than CS229, which is more applied machine learning and CS230, which is deep learning. My advice to students is that CS229A, let me write this down. I think I'm right. So CS229A is taught in the flip classroom format, which means that students taking it will mainly watch videos on the course of our website and do a lot of programming exercises and then meet for weekly discussion sections. But it's a smaller class with captain enrollment. I would advise you that if you feel ready for CS229 and CS233 to do those, but CS229, you know, because of the map we do, this is a very heavy workload and pretty challenging class, and so if you're not sure if you're ready for CS229A, maybe a good thing to take first. And then CS229, CS229A cover a broader range of machine learning algorithms and CS230 is more focused on deep learning algorithms specifically, which is a much narrower set of algorithms, but it is one of the hottest areas of deep learning. There is not that much overlap in content between the three classes. So if you actually take all three, you learn relatively different things from all of them. In the past, we've had students simultaneously take 229 and 229.8, and there is a little bit of overlap. They do kind of cover related algorithms, but from different points of view. So some people actually take multiple of these causes at the same time. But Studio 9A is more applied, a bit more practical, know how hands on and so on, and much less mathematical. And CS230 is also less mathematical, more applied, more about coming, getting to work, where CS290, we do much more mathematical derivations in CS290. Any other questions? Yes. Someone had a hand. So why don't you say that what I would generally prefer students not do that in the interest of time, but what do you want? Oh, I see. Show a go for it. Who's enrolled in 2009-2030? Oh, not that many of you. Interesting. Oh, that's actually really interesting. Cool. Yeah. Thank you. Yeah. I just didn't want to set a presence of students using this as a forum to run surveys. So that was a interesting question. So thank you. Cool. All right. And by the way, I think just one thing about just one thing about Stanford is the AI world, machine learning world, AI has begun the machine learning, right? And machine learning has begun the deep learning. One of the great things about being a Stanford student is you can, and I think should take multiple classes, right? I think that, you know, CS239 has for many years been the core of the machine learning world at Stanford. But even beyond CS239 is worth your while to take multiple classes and give multiple perspectives. So if you want to be really effective, you know, after you've dragged from Stanford, you do want to be an expert in machine learning. You do want to be an expert in deep learning. And you probably want to know probably some statistics, maybe want to know a bit of confidence optimization, maybe want to know a bit more about reinforcement learning, know a little bit about planning, know a bit about lots of things. So I actually encourage you to take multiple classes, I guess. Cool. All right, good. If there are no more questions, let's go on to talk a bit about machine learning. All right, so the remainder of this class, what I'd like to do is give a quick overview of the major areas of machine learning and also give you an overview of the things you learn in the next 10 weeks. So what is machine learning? It seems to be everywhere these days and it's useful for so many places. that's um and you know and I feel like I'm just a share of my personal bias right you read the news about these people making so much money building learning algorithms I think that's great I hope I hope all of you go make a lot of money but the thing I find even more exciting is the meaningful work we could do right I think that every time there's a major technological disruption, which there is now through machine learning, it gives us an opportunity to remake launch paths of the world. And if we behave ethically in a principal way and use the superpowers of machine learning to do things that helps people's lives. Maybe you can improve the healthcare system, maybe you can improve, give every child a personalized tutor, maybe you can make a democracy run better rather than make it run worse. But I think that the meaning I find in machine learning is that there's so many people that are so eager for us to go in and help them with these tools that if you become good at these tools, it gives you an opportunity to really remake some piece, some meaningful piece of the world, hopefully in a way that helps other people and makes the world kind of, makes the world a better place, is very appreciated in Silicon Valley. But I think with these tools, you actually have the power to do that. And if you go make a ton of money, that's great too. But I find the much greater meaning of the work we could do. It gives us a unique opportunity to do these things. But all the excitement of machine learning, what is machine learning? So let me give you a couple definitions of machine learning. Autosamil, whose claim to fame was building a checklist playing program, defined it as follows. Field study gives computer belief, learn about being a specific program. And, you know, interesting, when Arthur Samuel many, many decades ago wrote a checklist playing program, the debate of the day was, can a computer ever do something that it wasn't explicitly told to do? And Arthur Samuel wrote, Czechoslovakian program, that through self play learned what are the patterns of Czechovo that are more likely to lead to win versus more likely to lose and learn to be even better than Arthur Samuel, the author himself, at playing checkers. So back then, there was this view as a remarkable result that the computer programmer could write a piece of software to do something that the computer programmer himself could not do, right? Because this program became better at Arthur Samuel at the toss of play checkers. And I think today we used computers or machine learning algorithms outperforming humans on so many toss. But it turns out that when you choose a narrow toss, like speech recognition on a certain type of toss, you can maybe surpass human level performance, if you choose a narrow toss like playing the game of Go, then by throwing really tons of accomplished power at it and self-play, you can have a computer, you know, become very good at these narrow toss, but this was maybe one of the first such examples in history of computing. And I think this is the one of the most widely cited definitions, right? Just compute disability learning while being explicitly programmed. My friend Tom Mitchell in his textbook defined this as a well-pulled learning problem. Program set to learn from experience e-respect a TAST on some performance major P, P is measured by P improves experience E. I asked Tom this. I asked Tom if he wrote this definition just because he wanted it to rhyme. He did not say yes, but I don't know. But in this definition, the experience E, in the case of playing checkers, the experience E would be the experience of having a checker's program play tons of games against itself. So computers, lots of patients, and sit there for days playing games of checkers against itself. So that's the experience E. The task T is the task of playing checkers. The performance measure P maybe was the chance of this program winning the next game of checkers at plays against the next opponent. So we say that this is a well-posed learning problem learning thing. Checkers. Now within this set of ideas of machine learning, there are many different tools we use in machine learning. And so in the next 10 weeks, you learn about a variety of these different tools. And so the first of them, and the most widely used one, is supervised learning. Let's see, I want to switch to the white board. Do you guys know how that erase the screen? Oh, look at that. Okay. All right, good. So what I want to do today is really go over some of the major categories of machine learning tools and and and so what you learn in the next by the end of the quarter. So the most widely used machine learning tool is today is supervised learning. Actually, let me check how many many of you know what supervised learning is? Like a two-thirds, half of you maybe? Okay, cool. Let me just briefly define it. Here's one example. Let's say you have a database of housing prices. And so I'm going to plot your data set where on the horizontal axis, I'm going to plot the size of the house in square feet. And then the vertical axis will plot the price of the house. And maybe your data set looks like that. And so horizontal axis, I guess we call this x, and the vertical axis will call that y. So the supervised learning problem is, given the data set like this, the value of the value of the value of the value of the value of the value of say you have a, let's say you're fortunate enough to own a house in Palo Alto, right? And you're trying to sell it, and you want to know how to price the hulls. So maybe your hulls has a size of that amount on the horizontal axis. I don't know, maybe this is a five-inch square feet, 1,000 square feet, 1,500 square feet. So your hulls is 1250 square feet, right? And you want to know, how do you price this hulls? So given data set, one thing you can do is fill the straight line to it. And then you could estimate or predict the price to be whatever value you read off on the vertical axis. So in supervised learning, you are given a data set with imposex and labels y, and your goal is to learn a mapping from x to y. Now, for the straight line to data is maybe the simplest possible learning algorithm, maybe one of the simplest learning algorithms. Given the data set, there's many possible ways to learn and mapping, to learn a function, mapping from the input size to the estimated price. And so maybe you want to fit a quadratic function instead. Maybe that actually fits the data a little bit better. And so how do you choose among different models will be either automatically or manual intervention will be something we'll spend a lot of time talking about. Now to give a little bit more, to define a few more things, this particular example is a problem called a regression problem. And the term regression refers to that the value why you're trying to predict is continuous. In contrast, here is a different type of problem. So a problem that some of my friends were working on and I'll simplify it was a healthcare problem where they were looking at breast cancer, breast tumors, and trying to decide if a tumor is benign or malignant.? So tumor, you know, is of a lump in a woman's breast, can be malign or cancerous or benign, meaning, you have roughly, there's not that harmful. And so if on the horizontal axis, you plot the size of a tumor and on the vertical axis, you plot, is it malignant or not? So malignant means harmful, right? And some tumors are harmful some or not. And so whether it's malignant or not, it takes only two values, one or zero. And so you may have a data set like that. And given this, can you learn a mapping from X to Y so that if a new patient walks into your office, walks into the doctor's office and the tumor sizes, you know, say this. Can you learn the algorithm to figure out from this data? That, you know, it's probably, well, based on this data set, it looks like there's a high chance that that tumor is malignant. So, this is an example of a classification problem. And deterrent classification refers to that why here takes on a discrete number of variables. So for regression problem, why is a real number? I guess technically prices can be rounded off to the nearest dollar and cents. So prices aren't really real numbers. Because you probably not price a house at like pi times 1 million or whatever. But for all practical purposes, prices are continuous. So we call them housing price prediction to be a regression problem, whereas if you have two values, the possible output is 0, 1, call that classification problem. If you have K, the street outputs. So if the two may be malignant, or if they have k-dustreet outputs, so if the two may can be malignant, or if they're five types of cancer, right? So you have one of five possible outputs, then that's also a classification problem. If the output is discrete. Now, I want to find a different way to visualize this data set, which is, let me draw a line on top. And I'm just going to, you know, map all this data on horizontal axis, up, width, onto a line. But, well, let me show you what I'm going to do. I'm going to use a symbol all to denote, right? I hope what I did was clear. So I took the two sets of examples, the positive and negative examples. Positive examples is one, negative examples is zero. And I took all of these examples and kind of pushed them up onto straight line. And I used two symbols, I used O's to denote negative examples. And I use crosses to denote positive examples. So this is just a different way of visualizing the same data, but drawing it on a line and using two symbols to denote the two discrete values around one. So it turns out that in both of these examples, the input x was one dimensional. It was a single row number. For most of the machine learning applications to work with, the input x will be multi-dimensional. You won't be given just one number and also predict another number. Instead, you often be given multiple features and multiple numbers, so predict another number. So for example, instead of just using tumor size to predict, to estimate malignant versus benign tumors, you may instead have two features where one is tumor size and the second is age of the patient and be given the data set. And be given the data set that looks like that. Right? Right? Right now your task is given two input features. So X is tumor size and age, you know, like a two dimensional vector. And your task is given these two input features to predict whether a given tumor is molecular and lupinine. So the new patient walks in the doctor's office and the tumor size is here and the age is here. So that point there, then hopefully you can conclude that this patient's tumor is probably benign, right? Cosfunding is a negative example. And so one thing you learn next week is a learning algorithm that can fit a straight line to the data as follows, kind of like that to separate out the positive and negative examples, separate out the holes in the crosses. And so next week you learn about the logistic regression algorithm, which can do that. Okay. So one of the most interesting things you learn about is, let's see. So, in this example, I drew this set with two input features. When, so I have friends that actually worked on the breast cancer prediction problem, and in practice, you usually have a lot more than one or two features, and usually you have so many features you can't plot them in the board. And so for an actual breast cancer prediction problem, my friends are working on this. We're using many other features, such as, don't worry about what these mean. I guess clump thickness, your uniformity of cell size, uniformity of cell shape, right? At Heejin, how will the cells stick together? Don't worry about what these means, but if you're actually doing this in an actual medical application, there's a good chance that you'll be using a lot more features than just two. And this means that you actually can't plot this data, right. It's too high dimensional. You can't plot things higher than three dimensional, or maybe four dimensional, or something. We have a lot of features, actually difficult to plot this data. I'll come back to this in a second in learning theory. And one of the things you learn about, so as we develop learning algorithms, you learn how to build regression algorithms or classification algorithms that can deal with these relatively larger number of features. One of the most fascinating results you learn is that you also learn about an algorithm called support vector machine, which uses not one or two or three or ten or a hundred or a million input features, but uses an infinite number of input features. So just to clear, in this example, the state of a patient represents this one number, two size. In this example, we get two features. So the state of a patient would represented using two numbers, two size in the age. If you use this list of features, maybe it's a patient that would have represented five or six numbers. But there's an algorithm called the support vector machine that allows you to use an infinite dimensional vector to represent a patient. And how do you deal with that and how can a computer even store an infinite dimensional vector? Computer memory, you can store one row number, two row numbers, but you can't store an infinite number of real numbers in a computer without running out of memory or process speed or whatever. So how do you do that? So we talk about support vector machines and specifically the technical method called kernels, you learn how to build learning algorithms that work with an infinitely long list of features. An infinitely long list of features for which you can imagine that if you have an infinitely long list of numbers to represent a patient, that might give you a lot of information about that patient. And so that is one of the relatively effective learning algorithms to send problems. Okay. So that's supervised learning. And you know, let me just play a video. Show you a fun, slightly older example of supervised learning. It gives you a sense of what this means. But at the heart of supervised learning is the idea that during training, you are given inputs x together with the labels y, and you're given both at the same time. And the job of your learning algorithm is to find a mapping so that given a new x, you can map it to the most appropriate output Y. So this is a very old video made by Dean Palmondo, known for a long time as well, using supervised learning for autonomous driving. This is not stay the art for autonomous driving anymore, but it actually does remarkable to you well. Oh, and as you hear a few technical terms, like back propagation, you learn all those techniques in disk class. And by the end of the class, you will have been learning a very much more effective than what you see here. But let's see this application. Could you turn up the volume? that was built at Carnegie Mellon University many years ago. And what happens is during training, it watches the human drive the vehicle, and I think 10 times a second, it digitizes the image in front of the vehicle. And so that's the picture taken by a front facing camera. And what it does is in order to collect label data, the car, while the human is driving it, records both the image, such as the scene here, as well as the steering direction that was chosen by human. So at the bottom here is the image turned to the gray scale and lower res. And on top, let me pause this for a second, this is the driver direction, the font's kind of blurry, but this text says driver direction. So this is the Y label, the label Y, that the human driver chose. And so the position of this white bar, of this white blob, shows how the human is choosing to steer the car. So in this image, the white blob is a little bit to the left of center, so the human is steering just a little bit to the left. This second line here is the output of the neural network. And initially, the neural network doesn't know how to drive, and so it's just outputting this white smear everywhere. I don't know, did I drive left, right center? I don't know. So I'll put in this gray blur everywhere. And as the algorithm learns using the back propagation learning algorithm or gradient descent, which you learn about, you actually learn about gradient descent this Wednesday. You see that the neural networks outputs becomes less and less of this white smear of supervised learning because the human driver demonstrates inputs x and outputs y. If you see this in front of the car, steer like that, so that's x and y. And after the learning algorithm has learned, you can then, well, he pushes the button, takes a hand off the steering wheel, and then it's using this neural network to drive itself, right? Digitizing the image in front of the load, taking this image and passing it through the learning algorithm through the train neural network, letting the neural network select the steering direction and then using a little motor to turn the wheel. This is slightly more advanced version, which has trained two separate models. One for, I think, a two-lane road, one for a four-lane road. So that's the second and third lines. This is for a two-lane road, this is a four-lane road, and the arbitrator is another algorithm that tries to decide whether the two-lane or the four-lane road model is layer network, and one will see you soon. All right. Oh, all right, fine. We just see the final dramatic moment of switching from one narrow to two narrow. All right. And I think, you know, so this is just using supervised learning to take us input what's in to decide on steering direction. This is not so the art for how self-driving cars are built today, but you know, it could do some things in some limited context. And I think in several weeks you actually be able to build something that is more sophisticated than this. So after supervised learning, we will in this class of spend a bit of time talking about machine learning strategy. I think on the class notes, we annotate this as a learning theory. But what that means is I want to give you the tools to go out and apply learning algorithms effectively. And I think I've been fortunate to have, you know, to know a lot of, I think that I've been fortunate to have, you know, over the years constantly visited lots of great tech companies, more than ones that I've been publicly associated with, right? But often, just to help friends out, I visit various tech companies of the sort of whose products I'm sure are installing on your cell phone. But I often visit tech companies and talk to them, see what they're doing, see if I can help them out. And what I see is that there's a huge difference in the effectiveness of how two different teams could apply the exact same learning algorithm. And I think that what I've seen sadly is that sometimes there will be a team, even in some of the best tech companies, right, the elite AI companies, right, in multiple of them, where you go talk to a team and they'll tell you about something they've been working on for six months and then you can quickly take a look at the data and hear that they're not, they're everything quite working and sometimes you can look at what they're doing and go, yeah, you know, I could have told you six months ago that this approach is never going to work, right? And what I find is that the most skilled machine learning practitioners are very strategic by which I mean that your skill at deciding when you work on the machine learning project, you have a lot of decisions to make, right? Do you collect more data? Do you try a different learning algorithm? Do you rent faster GPUs to train your learning algorithm for longer? Or if you collect more data, what type of data do you collect? Or for all of these architecture choices, using neural networks, well, that's machine-led, just regression, which one do you pick? But there are a lot of decisions you need to make when building these learning algorithms. So one thing that's quite unique to the way we teach is we want to help you become more systematic in driving machine learning as a systematic engineering discipline. So that when one day you are working on machine learning project, you can efficiently figure out what to do next. And I sometimes make an analogy to software engineering. You know, many years ago, I had a friend that would debug code by compiling it, and then this friend would look at all these syntax errors, right, that C++ is compiler outputs, and they thought that the best way to eliminate the errors is to delete all the lines of code with syntax errors, and that was their first seriously. So that did not go well, right? Took me a while to persuade them to start doing that. But so it turns out that when you run a learning algorithm, you know, it almost never works the first time. All right, that's just life. And the way you go about debugging the learning algorithm, we have a huge impact on your efficiency on how quickly you can build effective learning systems. And I think until now, too much of this process of making your learning arborist work well has been a black magic kind of process where you know, has worked on this for decades. So when you run something, you don't know why it's not working well. Hey, what do I do? And what does it say? Oh, yeah I do that. And then because he's so experienced, it works. But I think what we're trying to do with the discipline of machine learning is to evolve it from a black magic tribal knowledge experience-based thing to a systematic engineering process. And so later the squatter, as we talk about machine learning strategy, or talk about learning theory, you try to systematically give you tools on how to go about strategizing. So it can be very efficient in how you yourself, how you can lead a team to build an effective learning system. Because I don't want you to be one of those people that, you know, waste six months on some direction that maybe could have relatively quickly figured out what's not promising. Well, maybe one last analogy, if you're used to optimizing code, right, making code run faster, not Xiaomi have you done that. Less experience software engineers will just dive in and optimize the code to try to make it run faster, right? Let's take the C++ and code and assemble assembly or something. But more experienced people will run a profiler to try to figure out what part of your code is actually the blah blah and act and then just focus on the engine on that. So one of the things hope to do this quarter is convey to you some of these more systematic engineering principles. And actually, very interesting. Actually, I've been writing some of the, how many of you have heard of machine learning you're earning? Oh, just a few of you, interesting. So actually, if any of you are interested, just in my spare time, I've been writing a book to try to codify systematic engineering principles for machine learning. And so if you want to, you know, free draft copy of the book, sign up for a mailing list here. I tend to just write stuff and put it on the internet for free. So if you want to free draft copy of the book, you know, go to this website, enter your email address and the website will send you a copy of the book. Go to this website, enter your email address, and the website will send you a copy of the book. I'll talk a little bit about these engineering principles as well. All right. So first subject, machine learning, second subject, learning theory. And the third major subject we'll talk about is deep learning. And so, you know, the lot of tools in machine learning and many of them are worth learning about. And I use many different tools in machine learning, you know, for many different applications. There's one subset of machine learning that's really hot right now because it's just advancing very rapidly, which is deep learning. And so we'll spend a bit of time talking about deep learning so that you can understand the basics of how to train a neural network as well. But I think that whereas 2.39 covers a much broader set of algorithms which are all useful, CS230 more narrowly covers just deep learning. So other than deep learning, after deep learning, new networks, the fourth of the five major topics we'll cover will be unsupervised learning. So what is unsupervised learning? So you saw me draw a picture like this just now, right? And this would be a classification problem, like the tumor and the ligament benign problem, this is a classification problem. And that was a supervised learning problem because you had to learn a function mapping from x to y. Unsupervised learning would be if I give you a data set like this with no labels. So you just give inputs x and no y. And you're asked to find me something interesting in this data. Figure out interesting structure in this data. And so in this data set, it looks like there are two clusters. And then unsupervised learning algorithm, which you'll learn about called K-means Clustering, would discover this structure in the data. Other examples on supervised learning, you know, if you, actually Google News is a very interesting website. Sometimes I use it to look up latest news. This is an old example. But Google News every day crawls or leads many, many thousands or tens of thousands of news articles on the internet and groups them together. For example, this is a set of articles on the BPR well spill and it has taken a lot of the articles written by different reporters and grouped them together. So you can figure out that with BP, Macondo Oilwell, right, that this is a CNN article about the Oilwell spill, there's a Guardian article about Oilwell spill, and this is an example of a clustering algorithm, where it's taking these different new sources and figuring out that these are all stories kind of about the same thing. And other examples of clustering, just getting data and figuring out what groups belong together. A lot of work on genetic data, this is a visualization of genetic microwave data where given data like this, you can group individuals into different types of individuals, different characteristics. Clustering algorithms grouping the stuff that data is together is used to organize computing clusters, figure out what machines work those are more related to each other and all of those community costs appropriately. So, to take a social network like LinkedIn or Facebook or other social networks and figure out which other groups are friends or which are the cohesive communities within a social network or market segmentation. Actually, many companies have worked with local customer database and cluster the users together. So, you can say that, looks like we're four types of users. You know, looks like that there are the young professionals learning brought the concept of using unlabeled data. So just X and finding interesting things about it. So for example, actually here's shoot. This won't work without audio. We'll do this later in the class, I guess. Maybe I'll see you and do this later. Cartel party problem is another unsuathized learning problem problem really need audio for this to explain this though Everything how to explain this you know, Cartel party problems I'll try to do the demo when we can get all your work on this laptop is a problem where if you have a noisy room and you stick multiple microphones in the room and record overlapping voices, so there are no labels. There are multiple microphones in the room with lots of people talking. How can you have the algorithm separate out the people's voices? That's a non-sue as learning problem because there are no labels. You just stick microphones in the room and have every court different people's voices, overlapping voices, you on the same time and then have it try to separate out people's voices and one of the primary exercises you do later is if we have you know five people talking So each microphone records five people's overlapping voices right because you know each microphone here's five people at the same time How can you have an algorithm separate out these voices so you can clean recordings of just one voice at a time So that's called a cocktail party problem and the algorithm you used to do this is called ICA independent components analysis and that's something you implement in one of the latest homework exercises And there are other examples of us who are learning as well The internet has has tons of unlabeled text data. You just suck down data from the internet. There are no labels necessarily. But can you learn interesting things about language? Figure out one of the best cited results recently was learning analogies like, you know, Manus, the woman is King of the Queen, right? Or what's a Tokyo is to Japan as Washington DC is the United States, right? To learn analogies like that. To say you can learn analogies like that from unlabeled data, just from text on the internet. So there's also unsupervised learning, okay? So after unsupervised learning, oh, and unsupervised learning, so machine learning is very useful today. It turns out that most of the recent wave of economic value created by machine learning is through supervised learning. But there are important use cases for unsupervised learning as well. So I use them in my work occasionally. And it's also a beating edge for a lot of exciting research. And then the final topic, final of the five topics we cover. So talk about supervised learning, machine learning strategy, deep learning, unsupervised learning, and then the fifth one is reinforcement learning is this, which is, let's say I give you the keys to Stanford, Latana, Telecopter. This helicopter is actually studying actually sitting in my office and trying to figure out how to get rid of it. And I'll see the right program to make it fly, right? So how do you do that? So this is a video of a helicopter flying. The audio is just a lot of helicopter noise, so that's not important. But we'll zoom out the video, you can see three sponge in the sky. But so you can use learning algorithms to get robots to do pretty interesting things like this. And it turns out that a good way to do this is through reinforcement learning. So what's reinforcement learning? It turns out that no one knows what's the optimal way to fly a helicopter. If you fly a helicopter, you have two control sticks that you're moving, but no one knows what's the optimal way to move the control sticks. So the way you can get a helicopter fly itself is let the helicopter do whatever. Think of it as training a dog, right? Like how, you can't teach a dog the optimal way to behave, but actually, how many of you have a pet dog or pet cat before? Not that many, that's fascinating. Okay, so I had a pet dog when I was a kid and my family made it my job to train the dog, so I'll be training the dog. You let the dog do whatever it wants and then whenever it behaves well, you go, oh, good dog. And when it misbehaves, you go bad dog. And then over time, the dog learns to do more of the good dog things and fear of the bad dog things. And so reinforcement learning is a bit like that, right? I don't know what's the awful way to fly a helicopter. So you let the helicopter do whatever it wants and then whenever it flies well, you know, does the maneuver you winds or flies accurately without jitting around too much, you go, oh, good helicopter. And when it crashes, you go bad helicopter. And it's the job of the reinforcement learning algorithms to figure out how to control it over time so as to get more of the good helicopter things and feel the bad helicopter things. And I think, well, just one more video. Oh. Interesting. Yeah, all right. And so again, give me the robot like this. I actually don't know how the programmer, actually, you know, the robot like this has a lot of joints, right? So how do you get a robot like this to climb or obstacles? So, well, this is actually a robot dog, so you can actually say good dog or bad dog. But by giving those signals called a reward signal, you can have a learning algorithm figured out by itself how to optimize the reward. Climb over these types of obstacles. And I think recently the most famous application is a reinforcement learning happen for game playing. Playing Atari games or playing game of Go, I think that's a, I think that's a game playing has made for some remarkable stunts, a remarkable PR, but I'm also equally excited, or maybe even more excited about the in-rolls. The reinforcement learning is making it to robot applications. So I think, yeah, reinforcement has been proven to be fantastic for playing games. It's also making road traction in optimizing robots and optimizing the logistics system and things like that. So you learn about all these things. Last thing for today, I hope that you will start to talk, meet people in the class, meet friends, phone project partners and study groups. And if you have any questions, you know, dive on the P out, there are also questions that will help others answer the questions. So let's break for today and look forward to seeing you on Wednesday. Welcome to Tutorial.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f839c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs\\\\youtube\\\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b20bd514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Stanford CS229: Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018)',\n",
       " 'description': \"For more information about Stanford’s Artificial Intelligence professional and graduate programs, visit: https://stanford.io/ai\\n\\nListen to the first lecture in Andrew Ng's machine learning course. This course provides a broad introduction to machine learning and statistical pattern recognition. Learn about both supervised and unsupervised learning as well as learning theory, reinforcement learning and control. Explore recent applications of machine learning and design and develop algorithms for machines.\\n\\nAndrew Ng is an Adjunct Professor of Computer Science at Stanford University. View more about Andrew on his website: https://www.andrewng.org/\\n \\nTo follow along with the course schedule and syllabus, visit: \\nhttp://cs229.stanford.edu/syllabus-autumn2018.html\\n\\n0:00 Introduction\\n05:21 Teaching team introductions\\n06:42 Goals for the course and the state of machine learning across research and industry\\n10:09 Prerequisites for the course\\n11:53 Homework, and a note about the Stanford honor code\\n16:57 Overview of the class project\\n25:57 Questions\\n\\n#AndrewNg #machinelearning\",\n",
       " 'upload_date': '20200417',\n",
       " 'duration': 4520,\n",
       " 'view_count': 3465260,\n",
       " 'like_count': 45313,\n",
       " 'channel': 'Stanford Online',\n",
       " 'channel_url': 'https://www.youtube.com/@stanfordonline',\n",
       " 'tags': ['Andrew Ng',\n",
       "  'Computer Science',\n",
       "  'Stanford',\n",
       "  'Machine Learning',\n",
       "  'Graduate Course',\n",
       "  'Artificial Intelligence',\n",
       "  'AI',\n",
       "  'Stanford Online',\n",
       "  'ML'],\n",
       " 'categories': ['Education'],\n",
       " 'thumbnail': 'https://i.ytimg.com/vi/jGwO_UgTS7I/maxresdefault.jpg',\n",
       " 'webpage_url': 'https://www.youtube.com/watch?v=jGwO_UgTS7I',\n",
       " 'source': 'docs\\\\youtube\\\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata| docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "852adfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers.audio import (\n",
    "    OpenAIWhisperParser,\n",
    "    OpenAIWhisperParserLocal,\n",
    ")\n",
    "from langchain_community.document_loaders.blob_loaders import YoutubeAudioLoader\n",
    "\n",
    "# Optional: Suppress Hugging Face symlink warning on Windows\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "def transcribe_youtube_videos(\n",
    "    urls: list[str],\n",
    "    save_dir: str = \"docs/youtube\",\n",
    "    local: bool = False,\n",
    "    language: str = \"en\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Downloads and transcribes YouTube videos using OpenAI Whisper.\n",
    "\n",
    "    Parameters:\n",
    "        urls (list[str]): List of YouTube video URLs.\n",
    "        save_dir (str): Directory to save downloaded audio.\n",
    "        local (bool): Whether to use the local Whisper model.\n",
    "        language (str): Language code (e.g., \"en\", \"zh\") or \"auto\" for detection.\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: LangChain documents containing the transcribed text.\n",
    "    \"\"\"\n",
    "    parser = (\n",
    "        OpenAIWhisperParserLocal()\n",
    "        if local\n",
    "        else OpenAIWhisperParser(language=language)\n",
    "    )\n",
    "\n",
    "    loader = GenericLoader(\n",
    "        YoutubeAudioLoader(urls, save_dir),\n",
    "        parser\n",
    "    )\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c19d0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following model:  openai/whisper-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=x8FASlLf5ls\n",
      "[youtube] x8FASlLf5ls: Downloading webpage\n",
      "[youtube] x8FASlLf5ls: Downloading tv client config\n",
      "[youtube] x8FASlLf5ls: Downloading tv player API JSON\n",
      "[youtube] x8FASlLf5ls: Downloading ios player API JSON\n",
      "[youtube] x8FASlLf5ls: Downloading m3u8 information\n",
      "[info] x8FASlLf5ls: Downloading 1 format(s): 140\n",
      "[download] Destination: docs\\youtube\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a\n",
      "[download] 100% of   23.07MiB in 00:00:10 at 2.14MiB/s   \n",
      "[FixupM4a] Correcting container of \"docs\\youtube\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a\"\n",
      "[ExtractAudio] Not converting audio docs\\youtube\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a; file is already in target format m4a\n",
      "Transcribing part docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SuperEngineer\\Training\\Cousera\\LangChain-Chat-with-Your-Data\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing part docs\\youtube\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a!\n",
      " Welcome to CS229 Machine Learning. Some of you know that this class is for this Stanford for a long time. And this is often the class that I most look forward to teaching each year because this is where we've helped, I think several generations of Stanford students become experts in machine learnin\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://www.youtube.com/watch?v=x8FASlLf5ls\"]\n",
    "docs = transcribe_youtube_videos(urls, save_dir=\"docs/youtube/\", local=True, language=\"en\")#\"en\"\n",
    "\n",
    "print(docs[0].page_content[:300])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcf20a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs\\\\youtube\\\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a'}, page_content=\" Welcome to CS229 Machine Learning. Some of you know that this class is for this Stanford for a long time. And this is often the class that I most look forward to teaching each year because this is where we've helped, I think several generations of Stanford students become experts in machine learning, got built many of their products and services and startups that I'm sure many of you, all of you are using today. So what I want to do today was spend some time talking over logistics and then spend some time giving you a beginning of an intro, talk a little bit about machine learning. So about two, three, nine. You know, all of you have been reading about AI in the news, about machine learning in the news. And you've pretty heard me or they say AI is a new electricity. Much less a rise of electricity about a hundred years ago, transform every major industry. I think AI, or really, we call it machine learning, but the rest of the world seems to call it AI. Machine learning and AI and deep learning will change the world. And I hope that through 2.29 we'll give you the tools you need so that you can be many of these future titans of industries, that you can be one, the girl that built, you know, hope the large tech companies do the amazing things they do, or build your own startup, or go into some other industry, go transform healthcare, or go transform transportation, or go build a self-driving car, and do all of these things that after this class, I think you'd be able to do. You know, the majority of students applying, the demand for AI skills, the demand for machine learning skills is so vast. I think you all know that. And I think it's because machine learning has advanced so rapidly in the last few years that there are so many opportunities to apply learning algorithms, right? Both in industry as well as in academia. I think today we have the English department professors trying to apply learning algorithms to understand history better. We have lawyers trying to apply machine learning to process legal documents and off campus, every company, both the tech companies as well as a lot of companies that you wouldn't consider tech companies, everything from manufacturing companies, the healthcare companies, the logistics companies are also trying to apply machine learning. So I think that if you look at it on a factual basis, the number of people doing very valuable machine learning projects today is much greater than it was six months ago, and six months ago, it's much greater than it was 12 months ago. And the amount of value, the amount of exciting meaningful work being done in machine learning is very strongly going up. And I think that given the rise of the amount of data we have, as well as the new machine learning tools that we have, it would be a long time before we run out of opportunities, before society as a whole has enough people with the machine learning skillset. So just as maybe 20 years ago was a good time to start working on this internet thing. A lot of people that started working on the internet like 20 years ago at fantastic careers, I think today is a wonderful time to jump to machine learning and the number of, and the opportunities for you to do unique things that no one is, no one else is doing, right? The opportunity for you to go to logistics company and find an exciting way to apply machine learning will be very high because chances are that logistics company has no one else even working on this because they probably can't, they may not be able to hire a fantastic Stanford student as a graduate CS239, right? Because they're just on the law of CS239 graduates around. So what I want to do today is do a quick intro, talk a little bit about logistics, and then we'll spend a second half of the day giving an overview and talk a little bit more about machine learning. And I apologize. I think that this room, according to that sign there, seats, what 300 something students? We have not quite 800 people enrolled in this class. So So if there are people outside and all of the classes are recorded, broadcast on the SPD, they usually, the videos usually made available same day. So for those of you that can't get into the room, my apologies. There were some years where even I had trouble getting into the room, but I'm glad you left me in. But hopefully you can watch, hopefully you can watch all of these things online shortly. Oh, I see, yes. Yeah. I don't know. It's a bit complicated. Yeah. Thank you. I think it's okay. Yeah. Next few classes, if you can squeeze in and use the D NTC. So for now, it might be too complicated. Okay. So quick and chose. Oh, I'm sorry, I should have introduced myself. My name is Andrew. And I want to introduce some of the rest of the teaching team as well. There's a class coordinator. She has been playing this role for many years now and helps keep the trains run on time and make sure that everything in class happens when it's supposed to. So, so, so should be a, and then what's real to have? Do you guys want to stand up? Be the co-head TA. So, our respective, theC students working with me. And so, bring a lot of technical experience, technical experience in machine learning as well as practical know-how on how to actually make these things work. And with the large class that we have, we have a large TA team. Maybe I won't introduce all of the TA's here today, but you meet many of them throughout the school. But the TAs expertise span everything from confusion to natural language processing, to computer biology, to robotics. And so through this quarter, as you work on your class projects, I hope that you get a lot of hope and advice and mentoring from the TAs, all of which all of whom have deep expertise, not just in machine learning, will often in a specific vertical application area of machine learning. So depending on what your project would try to match you to a TAs that can give you advice that's most relevant to whatever project you end up working on. So go out this class. I hope that after the next 10 weeks, you will be an expert in machine learning. It turns out that, you know, and I hope that after this class, you'll be able to go out and build very meaningful machine learning applications, either in an academic setting where hopefully you can apply it to your problems in mechanical engineering, electrical engineering, and English, and law, and education. All of this wonderful work that happens on campus, as well as after you graduate from Stanford to be able to apply it to whatever jobs you find. One of the things I find very exciting about machine learning is that it's no longer a pure tech company only kind of thing. I think that many years ago machine learning was like a thing that computer science department would do and that the elite AI companies like Google and Facebook and by-do and Microsoft would do. But now it is so pervasive that even companies that are not traditional tech companies see a huge need to apply these tools. And I find a lot of the most exciting work these days. And maybe some of you guys know my history, some of the buy-dates. I let the Google Brain team, which helped Google transform from what was already a great company 10 years ago to today, which is a great AI company and then I also let the AI group that I do and you know let the companies technology strategy to help by do also transform from what was already a great company many years ago to today arguably China's greatest AI company so having let the you know build the teams that let the AI transformations of two large tech companies I feel like that's a great thing to do but even beyond tech I think that there's a lot of exciting work to do as well to help other industries to help other sectors Embrace machine learning and use these tools effectively But after this class, I hope that each one of you will be well qualified to get a job at Shiny tech Company and do machine learning there or go into one of these industries and do very valuable machine learning projects there. And in addition, if any of you are taking this class with the primary goal of being able to do research in machine learning, you know, so actually some of you I our PhD students, I hope that this class will also leave you well equipped to really read and understand research papers as well as be qualified to start pushing forward the state of the art. So let's see. So today, so just as machine learning is evolving rapidly, the whole teaching team would be constantly updating CS222.9 as well. So it's actually very interesting. I feel like the pace of progress in machine learning has accelerated. So it actually feels like that the amount we changed the class year over year has been increasing over time. So if your friends took the class last year, things are a little bit different this year because we're constantly updating the class to keep up with what feels like still accelerating progress in the whole future machine learning. So there are some logistical changes. For example, we've gone from a, we used to hand out paper copies of handouts that we're trying to make this class digital only. But let me talk a little bit about prerequisites as well as in case your friends have taken this class before, some of the differences for this year. So prerequisites, We are going to assume that all of you have a knowledge of basic computer skills and principles. So, you know, big old notation, Q, Starrings, binary trees, hopefully you understand what all of those concepts are. And assume that all of you have a basic familiarity with probability, right? That hopefully, you know, what's the random variable, what's the expected value of a random variable, what's the variance of a random variable. And if, for some of you, maybe especially the SCP-D students taking turns in early, if it's been, you know, some number of years since you lost at a probability of statistics loss, we will have review sessions on Fridays where we'll go over some of these prerequisite materials as well. So hopefully you know what the random variables, what the expected value is, but if you're a little bit fuzzy on those concepts, we'll go over them again at a discussion section on Friday. Also assume the familiar basic linear algebra. So hopefully that you know what's the matrix, what's the vector, how to multiply two matrices, or multiply a matrix in a vector. If you know what an eigenvector, then that's even better. If you're not quite sure what an eigenvector is, we'll go over it. And then a large part of this class is having you practice these ideas through the homeworks as well as I mentioned later, an open-ended project. And so, one, we've actually, until now, we used to use MATLAB and ARCTI for the Fermi assignments. But this year we're trying to shift the programming assignments to Python. And so I think for a long time, even today, I sometimes use Octave to prototype because the syntax for Octave is so nice and just run very simple experiments very quickly. But I think the machine learning world is really migrating, I think, from Matt that Python world to increasing, excuse me, Matt that octave world to increasingly a Python maybe an then eventually for production in Java, C++ kind of world. And so we're rewriting a lot of the assignments that this causes quarter. Having driving that process so that this course that you could do more of the assignments, maybe all of the assignments in Python numpy instead. Now, note on the honor codes, we actually encourage you to form study groups. So up and fascinated by I've been fascinated by education for a long time. So, in a long time, studying education and pedagogy and how instructors like us can help support you to learn more efficiently. And one of the lessons I've learned from the educational research literature is that for highly technical classes like this, if you form study groups, you will probably have an easier time, right? So, CSU's denying we go for the highly technical material. There's a lot of math, some of the programs are hard, and if you have a group of friends to study with, you probably have an easier time because you can ask each other questions and work together to help each other. When we ask you to draw the line, or what we ask you to do relative to the standards on the code is We ask that you do the homework problems by yourself, right? And and and more specifically is okay to discuss the homework problems of friends, but if you But after discussing homework problems of friends, we ask you to go back and write up the solutions by yourself without referring to notes that you and your friends had developed together. The classes on the code is written clearly on the class on Handel's Posted digitally on the website. So if you ever have any questions about what is the log collaboration and what isn't allowed, please refer to that written document on the course website where we described it more clearly. But all the respect for the San Philanical as well as for students kind of doing their own work, we ask you to basically do your own work for the Zokid discuss it, but after discussing home problems with friends ultimately we ask you to write up your problems by yourself so that the whole world submissions reflect your own work, right? And I care about this because it turns out that having CS239, you know, CS239 is one of those classes that employers recognize. I don't know if you guys know, but there have been companies that have put up job ads that say stuff like, so long as you've got, so long as you complete a CS239, we guarantee you get an interview, right? I've seen stuff like that. And so I think, you know, in order to maintain that sanctity of what it means to be a CS239 competitor, I think, I asked it all of you, sort of really do your own work, or stay within the bounds of a set of collaboration relative to the on the code. Let's see. And I think that if, you know what, this is, and I think that one of the best parts of CS239, it turns out is, excuse me. So, sorry, I'm awkward. So one of the best parts of the class is, oh shoot, sorry about that. All right, no mind, I won't do this. You could do it on, you could do it yourself online later. Yeah, I started using Firefox recently in addition to Chrome. One of the best parts of the class is the class project. One of the goals of the class is to leave you well-qualified to do a meaningful machine learning project. One so one of the best ways to make sure you have that skillset is through this class and hopefully with the help of some of the T8, we want to support you to work on a small group to complete a meaningful machine learning project. And so one thing I hope you start doing later today is to start brainstorming maybe of your friends some of the class projects you might work on. And the most common class project that people do in CS2.9 is to pick an application that excites you and to apply machine learning to it and see if you can build a good machine learning system for some application in the area. And so if you go to the course website, you know, cs229.stamp.edu and look at previous years projects, you see machine learning projects applied to pretty much every imaginable application under the sun. Everything from, you know, diagnosed in cancer, to creating art, to lots of projects applied to other areas of engineering, applying to application areas in double E or mechanical engineering or so on, to applying it to understand literature, to applying it to, I don't know, and so if you look at the previous years projects, many of which are posted on the course website, you can use that as inspiration to see the types of projects students completing those classes are able to do and I also encourage you to, you can look at that for inspiration, to get a sense of what you'll be able to do at the conclusion of this class and also see if looking at previous years projects gives you inspiration for what you might do yourself. So we invite you, I guess, to do class projects in small groups. And so after class today, I also encourage you to start making friends in the class, both for the purpose of forming study groups as well as for the purpose of maybe finding a small group to do a class project with. We ask you the form project groups of up to size three, most project groups end up being size two or three. If you insist on doing it by yourself, right, without any partners, that's actually okay too, you're welcome to do that. But I think often, you know, having one or two others to work with may give you an easier time. And for projects of exceptional scope, if you have a very, very large project, they just cannot be done by three people. Sometimes, you know, let us know and we're open to some project groups of size four, but our expectation, but we do hold projects, you know, with a group of four to a higher standard than projects of size one to three. So what that means is that if your project team size is one, two, or three persons, the grading is one criteria. If your project group is bigger than three persons, we use a strict criteria when it comes to grading class projects. Oh, and that reminds me. I know that, let's see, so for most of you, since this started 9.30 AM on the first day of the quarter, for many of you, this may be, this probably your very first class at Stanford. How many of you, this is your very first class at Stanford? Wow, cool. Okay, awesome. Great. Welcome to Stanford. And if someone makes you just raise their hand, actually raise your hand again. So I hope that maybe after class today, if someone makes you raise your hand, I hope welcome them to Stanford and then say hi and she's so big friends after that. Cool, let's see, in addition to the main lectures that we'll have here on Mondays and Wednesdays, CS3.9 also has discussion sections on held on Fridays that are, and everything we do, including all the lectures and discussion sections that recorded and broadcast through SCPD, through the online website. And one of the discussion sections are taught usually by the TAs on Fridays and attendance at discussion sections is optional. And what I mean is that you know, you know, you're 100% promise there won't be material on the midterm that was sneakin' from the discussion section. So it's 100% optional. And you will be able to do all the homeworks and the projects without attending the discussion section. But what we're used to discussion section for, for the first V discussion sections. So, you know, this week, next week, week after that, we'll use the discussion sections to go over prerequisite material and greater depth. So, go over linear algebra, basic problem statistics, teach you a little bit about Python numpy in case you're less familiar with those programming frameworks. So, do that for the first few weeks. And then for the discussion sections that are held later this quarter, we'll usually use them to go over more advanced optional material. For example, CS239, a lot of the learning algorithms you hear about in the class rely on convex optimization algorithms. But we want to focus the class on the learning algorithms and spend less time on convex optimization. So if you want to come in here about more advanced concepts and convex optimization, we'll defer that to discussion section. And then there are a few other advanced topics, hidden markup models, time series that we're planning to defer to the Friday discussion sections. Okay. So let's see. Cool. And final bit of logistics for there are digital tools that some of you have seen. But for this class, we'll drive a lot of the discussion through the online website Piazza. How many of you have used Piazza before? Okay, cool, most of all of you, that's amazing. Good, so online discussion board for those of you that haven't seen it before but definitely encourage you to participate actively on Piazza and also to answer other students' questions. I think that one of the best ways to learn, as well as contribute back to the causes of ho is if you see someone else ask a question on Piazza, if you jump in and help answer that, that often helps you and helps your classmates. So I strongly encourage you to do that. For those of you that have a private question, sometimes we have students reaching out to us with a personal matter or something that is not appropriate to share on the public forum, in which case you're welcome to email us at the email address as well. And we also, and the cost email address, the teaching slots email address on the course website. You can find it there in contact us. But for anything technical or anything reasonable to share the cost, which includes most technical questions and most logistical questions, right? Questions like, you know, can you confirm what data is in the term or what happens? Can you confirm when's the handout for this going on and so on? For questions that are not personal or private in nature, strongly encourage you to post on P-Onswer rather than emailing us because statistically, you actually get a faster answer posting on P-Onswer than if you wait for one of us to respond to you. And we'll be using great scope as well for online grading. If you don't know what great scope is, don't worry about it. We'll send you links and show you how to use it later. And again, relative to one last logistical thing to plan for, unlike previous years where we taught CS229, so we're constantly updating the syllabus right the technical content to try to show you the latest when she learning algorithms and the two big little changes we're making this year I guess one is a Python instead of MATLAB and the other one is instead of having a midterm exam, you know, there's a timed midterm, we're planning to have a take-home midterm, the squatter, this day. So, I don't know. Some people just breathed in sharply when I said that. I don't know what that means. Was that shock or happiness? Okay. Don't worry, midterm's a fun. You love it. All right, so that's it for the logistical aspects. Let me check the, and so let me check there any questions. Oh yeah, go ahead. Oh, yeah, so that's interesting. Let's see, I think it's offered in spring and one other person. Oh, yes, and teaching it. So someone else is teaching it in spring quarter. I actually did not know it was going to be offered in winter. Yeah. Yeah, right. Yeah. Yeah. So I think I'm a great guy and teaching it. Sorry, you can go for a minute. Teaching it in a screen and I don't think it's offered in Windows. Well, this one section if you record it, yes, it will be. By the way, if you wonder why I'm repeating the question, I know it feels weird. I'm recording for the microphone so that people watching this can hear the question. But both the lectures and the discussion sections will be recorded and put on the website. Maybe the one thing we do that's not recorded and broadcast the office hours, right? Is that right? Oh, but I think this year we have a 60 hour, how many hours? 60 office hours per week. Right? Yeah. So, so hopefully, again, what constantly trying to improve the cause in previous years, one of the feedback we got was that the office hours are really crowded. So, we have 60 slots per week this year. That seems like a lot. So hopefully if you need to track down one of us, track down the tier to get help. Hopefully that'll make it easier for you to do so. Go ahead. Say the game. Well. Oh, well, it just go to the course website and click on the syllabus link, that has a calendar with when each homework assignment is called and when OP-DU. So full homeworks and a project proposal do a few weeks from now and then final projects do at the end of the quarter. But all the exact dates are listed on the course website. Thank you. Sure, yes. Difference between this class and 239A. Let me think how to answer that. Yes. So, yeah, I know I was debating earlier this morning how to answer that, because I've asked that a few times. So I think that what has happened at Stanford is that the volume of demand for machine learning education is just skyrocketing because everyone sees, everyone wants to learn this stuff. And so the computer science department has been trying to grow the number of machine learning offerings we have. We actually kept the enrollment of CS239A at a relatively low number at 100 students. So I actually don't want to encourage too many of you to sign up because I think we might be hitting the enrollment cap already. So please don't all sign up for CS239A because CS239A does not have the capacity to score. But CS239A is a much less mathematical and much more quite relatively more applied version of machine learning. And so I guess I'm teaching CS229, CS229, CS229 Discordero. Of the three, CS229 is the most mathematical. It is a little bit less applied than CS229, which is more applied machine learning and CS230, which is deep learning. My advice to students is that CS229A, let me write this down. I think I'm right. So CS229A is taught in the flip classroom format, which means that students taking it will mainly watch videos on the course of our website and do a lot of programming exercises and then meet for weekly discussion sections. But it's a smaller class with captain enrollment. I would advise you that if you feel ready for CS229 and CS233 to do those, but CS229, you know, because of the map we do, this is a very heavy workload and pretty challenging class, and so if you're not sure if you're ready for CS229A, maybe a good thing to take first. And then CS229, CS229A cover a broader range of machine learning algorithms and CS230 is more focused on deep learning algorithms specifically, which is a much narrower set of algorithms, but it is one of the hottest areas of deep learning. There is not that much overlap in content between the three classes. So if you actually take all three, you learn relatively different things from all of them. In the past, we've had students simultaneously take 229 and 229.8, and there is a little bit of overlap. They do kind of cover related algorithms, but from different points of view. So some people actually take multiple of these causes at the same time. But Studio 9A is more applied, a bit more practical, know how hands on and so on, and much less mathematical. And CS230 is also less mathematical, more applied, more about coming, getting to work, where CS290, we do much more mathematical derivations in CS290. Any other questions? Yes. Someone had a hand. So why don't you say that what I would generally prefer students not do that in the interest of time, but what do you want? Oh, I see. Show a go for it. Who's enrolled in 2009-2030? Oh, not that many of you. Interesting. Oh, that's actually really interesting. Cool. Yeah. Thank you. Yeah. I just didn't want to set a presence of students using this as a forum to run surveys. So that was a interesting question. So thank you. Cool. All right. And by the way, I think just one thing about just one thing about Stanford is the AI world, machine learning world, AI has begun the machine learning, right? And machine learning has begun the deep learning. One of the great things about being a Stanford student is you can, and I think should take multiple classes, right? I think that, you know, CS239 has for many years been the core of the machine learning world at Stanford. But even beyond CS239 is worth your while to take multiple classes and give multiple perspectives. So if you want to be really effective, you know, after you've dragged from Stanford, you do want to be an expert in machine learning. You do want to be an expert in deep learning. And you probably want to know probably some statistics, maybe want to know a bit of confidence optimization, maybe want to know a bit more about reinforcement learning, know a little bit about planning, know a bit about lots of things. So I actually encourage you to take multiple classes, I guess. Cool. All right, good. If there are no more questions, let's go on to talk a bit about machine learning. All right, so the remainder of this class, what I'd like to do is give a quick overview of the major areas of machine learning and also give you an overview of the things you learn in the next 10 weeks. So what is machine learning? It seems to be everywhere these days and it's useful for so many places. that's um and you know and I feel like I'm just a share of my personal bias right you read the news about these people making so much money building learning algorithms I think that's great I hope I hope all of you go make a lot of money but the thing I find even more exciting is the meaningful work we could do right I think that every time there's a major technological disruption, which there is now through machine learning, it gives us an opportunity to remake launch paths of the world. And if we behave ethically in a principal way and use the superpowers of machine learning to do things that helps people's lives. Maybe you can improve the healthcare system, maybe you can improve, give every child a personalized tutor, maybe you can make a democracy run better rather than make it run worse. But I think that the meaning I find in machine learning is that there's so many people that are so eager for us to go in and help them with these tools that if you become good at these tools, it gives you an opportunity to really remake some piece, some meaningful piece of the world, hopefully in a way that helps other people and makes the world kind of, makes the world a better place, is very appreciated in Silicon Valley. But I think with these tools, you actually have the power to do that. And if you go make a ton of money, that's great too. But I find the much greater meaning of the work we could do. It gives us a unique opportunity to do these things. But all the excitement of machine learning, what is machine learning? So let me give you a couple definitions of machine learning. Autosamil, whose claim to fame was building a checklist playing program, defined it as follows. Field study gives computer belief, learn about being a specific program. And, you know, interesting, when Arthur Samuel many, many decades ago wrote a checklist playing program, the debate of the day was, can a computer ever do something that it wasn't explicitly told to do? And Arthur Samuel wrote, Czechoslovakian program, that through self play learned what are the patterns of Czechovo that are more likely to lead to win versus more likely to lose and learn to be even better than Arthur Samuel, the author himself, at playing checkers. So back then, there was this view as a remarkable result that the computer programmer could write a piece of software to do something that the computer programmer himself could not do, right? Because this program became better at Arthur Samuel at the toss of play checkers. And I think today we used computers or machine learning algorithms outperforming humans on so many toss. But it turns out that when you choose a narrow toss, like speech recognition on a certain type of toss, you can maybe surpass human level performance, if you choose a narrow toss like playing the game of Go, then by throwing really tons of accomplished power at it and self-play, you can have a computer, you know, become very good at these narrow toss, but this was maybe one of the first such examples in history of computing. And I think this is the one of the most widely cited definitions, right? Just compute disability learning while being explicitly programmed. My friend Tom Mitchell in his textbook defined this as a well-pulled learning problem. Program set to learn from experience e-respect a TAST on some performance major P, P is measured by P improves experience E. I asked Tom this. I asked Tom if he wrote this definition just because he wanted it to rhyme. He did not say yes, but I don't know. But in this definition, the experience E, in the case of playing checkers, the experience E would be the experience of having a checker's program play tons of games against itself. So computers, lots of patients, and sit there for days playing games of checkers against itself. So that's the experience E. The task T is the task of playing checkers. The performance measure P maybe was the chance of this program winning the next game of checkers at plays against the next opponent. So we say that this is a well-posed learning problem learning thing. Checkers. Now within this set of ideas of machine learning, there are many different tools we use in machine learning. And so in the next 10 weeks, you learn about a variety of these different tools. And so the first of them, and the most widely used one, is supervised learning. Let's see, I want to switch to the white board. Do you guys know how that erase the screen? Oh, look at that. Okay. All right, good. So what I want to do today is really go over some of the major categories of machine learning tools and and and so what you learn in the next by the end of the quarter. So the most widely used machine learning tool is today is supervised learning. Actually, let me check how many many of you know what supervised learning is? Like a two-thirds, half of you maybe? Okay, cool. Let me just briefly define it. Here's one example. Let's say you have a database of housing prices. And so I'm going to plot your data set where on the horizontal axis, I'm going to plot the size of the house in square feet. And then the vertical axis will plot the price of the house. And maybe your data set looks like that. And so horizontal axis, I guess we call this x, and the vertical axis will call that y. So the supervised learning problem is, given the data set like this, the value of the value of the value of the value of the value of the value of say you have a, let's say you're fortunate enough to own a house in Palo Alto, right? And you're trying to sell it, and you want to know how to price the hulls. So maybe your hulls has a size of that amount on the horizontal axis. I don't know, maybe this is a five-inch square feet, 1,000 square feet, 1,500 square feet. So your hulls is 1250 square feet, right? And you want to know, how do you price this hulls? So given data set, one thing you can do is fill the straight line to it. And then you could estimate or predict the price to be whatever value you read off on the vertical axis. So in supervised learning, you are given a data set with imposex and labels y, and your goal is to learn a mapping from x to y. Now, for the straight line to data is maybe the simplest possible learning algorithm, maybe one of the simplest learning algorithms. Given the data set, there's many possible ways to learn and mapping, to learn a function, mapping from the input size to the estimated price. And so maybe you want to fit a quadratic function instead. Maybe that actually fits the data a little bit better. And so how do you choose among different models will be either automatically or manual intervention will be something we'll spend a lot of time talking about. Now to give a little bit more, to define a few more things, this particular example is a problem called a regression problem. And the term regression refers to that the value why you're trying to predict is continuous. In contrast, here is a different type of problem. So a problem that some of my friends were working on and I'll simplify it was a healthcare problem where they were looking at breast cancer, breast tumors, and trying to decide if a tumor is benign or malignant.? So tumor, you know, is of a lump in a woman's breast, can be malign or cancerous or benign, meaning, you have roughly, there's not that harmful. And so if on the horizontal axis, you plot the size of a tumor and on the vertical axis, you plot, is it malignant or not? So malignant means harmful, right? And some tumors are harmful some or not. And so whether it's malignant or not, it takes only two values, one or zero. And so you may have a data set like that. And given this, can you learn a mapping from X to Y so that if a new patient walks into your office, walks into the doctor's office and the tumor sizes, you know, say this. Can you learn the algorithm to figure out from this data? That, you know, it's probably, well, based on this data set, it looks like there's a high chance that that tumor is malignant. So, this is an example of a classification problem. And deterrent classification refers to that why here takes on a discrete number of variables. So for regression problem, why is a real number? I guess technically prices can be rounded off to the nearest dollar and cents. So prices aren't really real numbers. Because you probably not price a house at like pi times 1 million or whatever. But for all practical purposes, prices are continuous. So we call them housing price prediction to be a regression problem, whereas if you have two values, the possible output is 0, 1, call that classification problem. If you have K, the street outputs. So if the two may be malignant, or if they have k-dustreet outputs, so if the two may can be malignant, or if they're five types of cancer, right? So you have one of five possible outputs, then that's also a classification problem. If the output is discrete. Now, I want to find a different way to visualize this data set, which is, let me draw a line on top. And I'm just going to, you know, map all this data on horizontal axis, up, width, onto a line. But, well, let me show you what I'm going to do. I'm going to use a symbol all to denote, right? I hope what I did was clear. So I took the two sets of examples, the positive and negative examples. Positive examples is one, negative examples is zero. And I took all of these examples and kind of pushed them up onto straight line. And I used two symbols, I used O's to denote negative examples. And I use crosses to denote positive examples. So this is just a different way of visualizing the same data, but drawing it on a line and using two symbols to denote the two discrete values around one. So it turns out that in both of these examples, the input x was one dimensional. It was a single row number. For most of the machine learning applications to work with, the input x will be multi-dimensional. You won't be given just one number and also predict another number. Instead, you often be given multiple features and multiple numbers, so predict another number. So for example, instead of just using tumor size to predict, to estimate malignant versus benign tumors, you may instead have two features where one is tumor size and the second is age of the patient and be given the data set. And be given the data set that looks like that. Right? Right? Right now your task is given two input features. So X is tumor size and age, you know, like a two dimensional vector. And your task is given these two input features to predict whether a given tumor is molecular and lupinine. So the new patient walks in the doctor's office and the tumor size is here and the age is here. So that point there, then hopefully you can conclude that this patient's tumor is probably benign, right? Cosfunding is a negative example. And so one thing you learn next week is a learning algorithm that can fit a straight line to the data as follows, kind of like that to separate out the positive and negative examples, separate out the holes in the crosses. And so next week you learn about the logistic regression algorithm, which can do that. Okay. So one of the most interesting things you learn about is, let's see. So, in this example, I drew this set with two input features. When, so I have friends that actually worked on the breast cancer prediction problem, and in practice, you usually have a lot more than one or two features, and usually you have so many features you can't plot them in the board. And so for an actual breast cancer prediction problem, my friends are working on this. We're using many other features, such as, don't worry about what these mean. I guess clump thickness, your uniformity of cell size, uniformity of cell shape, right? At Heejin, how will the cells stick together? Don't worry about what these means, but if you're actually doing this in an actual medical application, there's a good chance that you'll be using a lot more features than just two. And this means that you actually can't plot this data, right. It's too high dimensional. You can't plot things higher than three dimensional, or maybe four dimensional, or something. We have a lot of features, actually difficult to plot this data. I'll come back to this in a second in learning theory. And one of the things you learn about, so as we develop learning algorithms, you learn how to build regression algorithms or classification algorithms that can deal with these relatively larger number of features. One of the most fascinating results you learn is that you also learn about an algorithm called support vector machine, which uses not one or two or three or ten or a hundred or a million input features, but uses an infinite number of input features. So just to clear, in this example, the state of a patient represents this one number, two size. In this example, we get two features. So the state of a patient would represented using two numbers, two size in the age. If you use this list of features, maybe it's a patient that would have represented five or six numbers. But there's an algorithm called the support vector machine that allows you to use an infinite dimensional vector to represent a patient. And how do you deal with that and how can a computer even store an infinite dimensional vector? Computer memory, you can store one row number, two row numbers, but you can't store an infinite number of real numbers in a computer without running out of memory or process speed or whatever. So how do you do that? So we talk about support vector machines and specifically the technical method called kernels, you learn how to build learning algorithms that work with an infinitely long list of features. An infinitely long list of features for which you can imagine that if you have an infinitely long list of numbers to represent a patient, that might give you a lot of information about that patient. And so that is one of the relatively effective learning algorithms to send problems. Okay. So that's supervised learning. And you know, let me just play a video. Show you a fun, slightly older example of supervised learning. It gives you a sense of what this means. But at the heart of supervised learning is the idea that during training, you are given inputs x together with the labels y, and you're given both at the same time. And the job of your learning algorithm is to find a mapping so that given a new x, you can map it to the most appropriate output Y. So this is a very old video made by Dean Palmondo, known for a long time as well, using supervised learning for autonomous driving. This is not stay the art for autonomous driving anymore, but it actually does remarkable to you well. Oh, and as you hear a few technical terms, like back propagation, you learn all those techniques in disk class. And by the end of the class, you will have been learning a very much more effective than what you see here. But let's see this application. Could you turn up the volume? that was built at Carnegie Mellon University many years ago. And what happens is during training, it watches the human drive the vehicle, and I think 10 times a second, it digitizes the image in front of the vehicle. And so that's the picture taken by a front facing camera. And what it does is in order to collect label data, the car, while the human is driving it, records both the image, such as the scene here, as well as the steering direction that was chosen by human. So at the bottom here is the image turned to the gray scale and lower res. And on top, let me pause this for a second, this is the driver direction, the font's kind of blurry, but this text says driver direction. So this is the Y label, the label Y, that the human driver chose. And so the position of this white bar, of this white blob, shows how the human is choosing to steer the car. So in this image, the white blob is a little bit to the left of center, so the human is steering just a little bit to the left. This second line here is the output of the neural network. And initially, the neural network doesn't know how to drive, and so it's just outputting this white smear everywhere. I don't know, did I drive left, right center? I don't know. So I'll put in this gray blur everywhere. And as the algorithm learns using the back propagation learning algorithm or gradient descent, which you learn about, you actually learn about gradient descent this Wednesday. You see that the neural networks outputs becomes less and less of this white smear of supervised learning because the human driver demonstrates inputs x and outputs y. If you see this in front of the car, steer like that, so that's x and y. And after the learning algorithm has learned, you can then, well, he pushes the button, takes a hand off the steering wheel, and then it's using this neural network to drive itself, right? Digitizing the image in front of the load, taking this image and passing it through the learning algorithm through the train neural network, letting the neural network select the steering direction and then using a little motor to turn the wheel. This is slightly more advanced version, which has trained two separate models. One for, I think, a two-lane road, one for a four-lane road. So that's the second and third lines. This is for a two-lane road, this is a four-lane road, and the arbitrator is another algorithm that tries to decide whether the two-lane or the four-lane road model is layer network, and one will see you soon. All right. Oh, all right, fine. We just see the final dramatic moment of switching from one narrow to two narrow. All right. And I think, you know, so this is just using supervised learning to take us input what's in to decide on steering direction. This is not so the art for how self-driving cars are built today, but you know, it could do some things in some limited context. And I think in several weeks you actually be able to build something that is more sophisticated than this. So after supervised learning, we will in this class of spend a bit of time talking about machine learning strategy. I think on the class notes, we annotate this as a learning theory. But what that means is I want to give you the tools to go out and apply learning algorithms effectively. And I think I've been fortunate to have, you know, to know a lot of, I think that I've been fortunate to have, you know, over the years constantly visited lots of great tech companies, more than ones that I've been publicly associated with, right? But often, just to help friends out, I visit various tech companies of the sort of whose products I'm sure are installing on your cell phone. But I often visit tech companies and talk to them, see what they're doing, see if I can help them out. And what I see is that there's a huge difference in the effectiveness of how two different teams could apply the exact same learning algorithm. And I think that what I've seen sadly is that sometimes there will be a team, even in some of the best tech companies, right, the elite AI companies, right, in multiple of them, where you go talk to a team and they'll tell you about something they've been working on for six months and then you can quickly take a look at the data and hear that they're not, they're everything quite working and sometimes you can look at what they're doing and go, yeah, you know, I could have told you six months ago that this approach is never going to work, right? And what I find is that the most skilled machine learning practitioners are very strategic by which I mean that your skill at deciding when you work on the machine learning project, you have a lot of decisions to make, right? Do you collect more data? Do you try a different learning algorithm? Do you rent faster GPUs to train your learning algorithm for longer? Or if you collect more data, what type of data do you collect? Or for all of these architecture choices, using neural networks, well, that's machine-led, just regression, which one do you pick? But there are a lot of decisions you need to make when building these learning algorithms. So one thing that's quite unique to the way we teach is we want to help you become more systematic in driving machine learning as a systematic engineering discipline. So that when one day you are working on machine learning project, you can efficiently figure out what to do next. And I sometimes make an analogy to software engineering. You know, many years ago, I had a friend that would debug code by compiling it, and then this friend would look at all these syntax errors, right, that C++ is compiler outputs, and they thought that the best way to eliminate the errors is to delete all the lines of code with syntax errors, and that was their first seriously. So that did not go well, right? Took me a while to persuade them to start doing that. But so it turns out that when you run a learning algorithm, you know, it almost never works the first time. All right, that's just life. And the way you go about debugging the learning algorithm, we have a huge impact on your efficiency on how quickly you can build effective learning systems. And I think until now, too much of this process of making your learning arborist work well has been a black magic kind of process where you know, has worked on this for decades. So when you run something, you don't know why it's not working well. Hey, what do I do? And what does it say? Oh, yeah I do that. And then because he's so experienced, it works. But I think what we're trying to do with the discipline of machine learning is to evolve it from a black magic tribal knowledge experience-based thing to a systematic engineering process. And so later the squatter, as we talk about machine learning strategy, or talk about learning theory, you try to systematically give you tools on how to go about strategizing. So it can be very efficient in how you yourself, how you can lead a team to build an effective learning system. Because I don't want you to be one of those people that, you know, waste six months on some direction that maybe could have relatively quickly figured out what's not promising. Well, maybe one last analogy, if you're used to optimizing code, right, making code run faster, not Xiaomi have you done that. Less experience software engineers will just dive in and optimize the code to try to make it run faster, right? Let's take the C++ and code and assemble assembly or something. But more experienced people will run a profiler to try to figure out what part of your code is actually the blah blah and act and then just focus on the engine on that. So one of the things hope to do this quarter is convey to you some of these more systematic engineering principles. And actually, very interesting. Actually, I've been writing some of the, how many of you have heard of machine learning you're earning? Oh, just a few of you, interesting. So actually, if any of you are interested, just in my spare time, I've been writing a book to try to codify systematic engineering principles for machine learning. And so if you want to, you know, free draft copy of the book, sign up for a mailing list here. I tend to just write stuff and put it on the internet for free. So if you want to free draft copy of the book, you know, go to this website, enter your email address and the website will send you a copy of the book. Go to this website, enter your email address, and the website will send you a copy of the book. I'll talk a little bit about these engineering principles as well. All right. So first subject, machine learning, second subject, learning theory. And the third major subject we'll talk about is deep learning. And so, you know, the lot of tools in machine learning and many of them are worth learning about. And I use many different tools in machine learning, you know, for many different applications. There's one subset of machine learning that's really hot right now because it's just advancing very rapidly, which is deep learning. And so we'll spend a bit of time talking about deep learning so that you can understand the basics of how to train a neural network as well. But I think that whereas 2.39 covers a much broader set of algorithms which are all useful, CS230 more narrowly covers just deep learning. So other than deep learning, after deep learning, new networks, the fourth of the five major topics we'll cover will be unsupervised learning. So what is unsupervised learning? So you saw me draw a picture like this just now, right? And this would be a classification problem, like the tumor and the ligament benign problem, this is a classification problem. And that was a supervised learning problem because you had to learn a function mapping from x to y. Unsupervised learning would be if I give you a data set like this with no labels. So you just give inputs x and no y. And you're asked to find me something interesting in this data. Figure out interesting structure in this data. And so in this data set, it looks like there are two clusters. And then unsupervised learning algorithm, which you'll learn about called K-means Clustering, would discover this structure in the data. Other examples on supervised learning, you know, if you, actually Google News is a very interesting website. Sometimes I use it to look up latest news. This is an old example. But Google News every day crawls or leads many, many thousands or tens of thousands of news articles on the internet and groups them together. For example, this is a set of articles on the BPR well spill and it has taken a lot of the articles written by different reporters and grouped them together. So you can figure out that with BP, Macondo Oilwell, right, that this is a CNN article about the Oilwell spill, there's a Guardian article about Oilwell spill, and this is an example of a clustering algorithm, where it's taking these different new sources and figuring out that these are all stories kind of about the same thing. And other examples of clustering, just getting data and figuring out what groups belong together. A lot of work on genetic data, this is a visualization of genetic microwave data where given data like this, you can group individuals into different types of individuals, different characteristics. Clustering algorithms grouping the stuff that data is together is used to organize computing clusters, figure out what machines work those are more related to each other and all of those community costs appropriately. So, to take a social network like LinkedIn or Facebook or other social networks and figure out which other groups are friends or which are the cohesive communities within a social network or market segmentation. Actually, many companies have worked with local customer database and cluster the users together. So, you can say that, looks like we're four types of users. You know, looks like that there are the young professionals learning brought the concept of using unlabeled data. So just X and finding interesting things about it. So for example, actually here's shoot. This won't work without audio. We'll do this later in the class, I guess. Maybe I'll see you and do this later. Cartel party problem is another unsuathized learning problem problem really need audio for this to explain this though Everything how to explain this you know, Cartel party problems I'll try to do the demo when we can get all your work on this laptop is a problem where if you have a noisy room and you stick multiple microphones in the room and record overlapping voices, so there are no labels. There are multiple microphones in the room with lots of people talking. How can you have the algorithm separate out the people's voices? That's a non-sue as learning problem because there are no labels. You just stick microphones in the room and have every court different people's voices, overlapping voices, you on the same time and then have it try to separate out people's voices and one of the primary exercises you do later is if we have you know five people talking So each microphone records five people's overlapping voices right because you know each microphone here's five people at the same time How can you have an algorithm separate out these voices so you can clean recordings of just one voice at a time So that's called a cocktail party problem and the algorithm you used to do this is called ICA independent components analysis and that's something you implement in one of the latest homework exercises And there are other examples of us who are learning as well The internet has has tons of unlabeled text data. You just suck down data from the internet. There are no labels necessarily. But can you learn interesting things about language? Figure out one of the best cited results recently was learning analogies like, you know, Manus, the woman is King of the Queen, right? Or what's a Tokyo is to Japan as Washington DC is the United States, right? To learn analogies like that. To say you can learn analogies like that from unlabeled data, just from text on the internet. So there's also unsupervised learning, okay? So after unsupervised learning, oh, and unsupervised learning, so machine learning is very useful today. It turns out that most of the recent wave of economic value created by machine learning is through supervised learning. But there are important use cases for unsupervised learning as well. So I use them in my work occasionally. And it's also a beating edge for a lot of exciting research. And then the final topic, final of the five topics we cover. So talk about supervised learning, machine learning strategy, deep learning, unsupervised learning, and then the fifth one is reinforcement learning is this, which is, let's say I give you the keys to Stanford, Latana, Telecopter. This helicopter is actually studying actually sitting in my office and trying to figure out how to get rid of it. And I'll see the right program to make it fly, right? So how do you do that? So this is a video of a helicopter flying. The audio is just a lot of helicopter noise, so that's not important. But we'll zoom out the video, you can see three sponge in the sky. But so you can use learning algorithms to get robots to do pretty interesting things like this. And it turns out that a good way to do this is through reinforcement learning. So what's reinforcement learning? It turns out that no one knows what's the optimal way to fly a helicopter. If you fly a helicopter, you have two control sticks that you're moving, but no one knows what's the optimal way to move the control sticks. So the way you can get a helicopter fly itself is let the helicopter do whatever. Think of it as training a dog, right? Like how, you can't teach a dog the optimal way to behave, but actually, how many of you have a pet dog or pet cat before? Not that many, that's fascinating. Okay, so I had a pet dog when I was a kid and my family made it my job to train the dog, so I'll be training the dog. You let the dog do whatever it wants and then whenever it behaves well, you go, oh, good dog. And when it misbehaves, you go bad dog. And then over time, the dog learns to do more of the good dog things and fear of the bad dog things. And so reinforcement learning is a bit like that, right? I don't know what's the awful way to fly a helicopter. So you let the helicopter do whatever it wants and then whenever it flies well, you know, does the maneuver you winds or flies accurately without jitting around too much, you go, oh, good helicopter. And when it crashes, you go bad helicopter. And it's the job of the reinforcement learning algorithms to figure out how to control it over time so as to get more of the good helicopter things and feel the bad helicopter things. And I think, well, just one more video. Oh. Interesting. Yeah, all right. And so again, give me the robot like this. I actually don't know how the programmer, actually, you know, the robot like this has a lot of joints, right? So how do you get a robot like this to climb or obstacles? So, well, this is actually a robot dog, so you can actually say good dog or bad dog. But by giving those signals called a reward signal, you can have a learning algorithm figured out by itself how to optimize the reward. Climb over these types of obstacles. And I think recently the most famous application is a reinforcement learning happen for game playing. Playing Atari games or playing game of Go, I think that's a, I think that's a game playing has made for some remarkable stunts, a remarkable PR, but I'm also equally excited, or maybe even more excited about the in-rolls. The reinforcement learning is making it to robot applications. So I think, yeah, reinforcement has been proven to be fantastic for playing games. It's also making road traction in optimizing robots and optimizing the logistics system and things like that. So you learn about all these things. Last thing for today, I hope that you will start to talk, meet people in the class, meet friends, phone project partners and study groups. And if you have any questions, you know, dive on the P out, there are also questions that will help others answer the questions. So let's break for today and look forward to seeing you on Wednesday. Welcome to Tutorial.\"),\n",
       " Document(metadata={'source': 'docs\\\\youtube\\\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a'}, page_content='大家好 歡迎回到視野環球財經 我是Rino現在是美東世界 二五年5月9日週五晚上的8點25分今天是標普高開不過美國總統川普提出將中國的關稅從145降到80的想法但他們表示這將取決於美國財長貝森特其實如此之高的關税是大幅高于市场的预期所以股市和国债是双双下跌回徒了高开的账赋今天的收盘价和昨天是基本持平不过今天少数的个股市走出了独立行情比如特斯拉特斯拉这边今天是放量上行朝着突破之后就是2007这个突破上行突破之后的下一个波段目标位更上一层楼这个目标位是3 2 6到367但是我这里要提醒一下这个波段目标的压力是比较大的预计一次非常难过去因为这个地方是它上看前高之前最大的压力位置而且从下个星期的月期权结算的位置来看300块钱上下大概是21美元左右的波动这就意味着下个星期的月期全結算的位置來看300塊錢上下大概是21美元左右的波動這對意味著下個星期想去突破壓力是一個非常小的概率但是如果有一些新的關稅其他的利好消息出來走入到小概率區間出外但向上是有機會摸到壓力位的下延的如果下感性机是下跌那么回撤大概是在2008的上方所以特斯拉后面还是继续上看326到367的这个波段那么做波段的朋友自行做好交易计划好 接下来时间我会直接去跟踪讲解一些个国从亚马运开始是一直会讲到李莱首先说亚马运亚马运昨天其实收盘价就已经是占稳了191块钱这个地方咱们之前曾经讲过191占稳之后它就比较稳当了但是它现在在今天收盘第二天收到了191的上方总体上大家也不要期望他能跑得特别的快因为市场对他的波动压住其实并不高下个星期大概是七八块钱左右的上下波动也就是说能够维持在182的强支撰的上方然后逐渐的寻求低点抬高高点也逐渐抬高的这么一个过程因为沿往讯这只股票的特性它不是那种暴力拉升很快几下就拉上去的它是属于罗选市上升这种走势是比较明显的股票所以所以長期持有亞馬遜的朋友如果你是在191到下方的166區間在這個區間進場的朋友暫時你可以拿得比較穩當了沒有什麼太大的問題了如果想做波段的朋友呢讓他講過不要期待他跑得特別的快會是一個比較慢较慢的过程接下来说一下关于台积电首先说一下关于整个的台湾产品出口的一个背景整个的台湾4月份商品出口是同比增长29.9%几乎是市场预期的2倍值得注意的是对于美国的出口同比增长29.5%当然很大程度上是得益于对高科技产品的旺盛需求按照产品来细分信息通信和视频产品比如电脑笔记本显示器的出货量是同比增长60.5%于是同时半导是同比增長28.2%台積電在這個大的背景下4月的銷售也非常的旺盛4月份銷售額是3495.7億新台幣還比增長28.2%同比增長48.1%遠遠超過分析師預期的38%那麼較上個月的46.5%的同比增速有所加快不過現在有一個逆風就是新台幣最近長得非常的厲害飆升這個會給台積電帶來利潤率的壓力台積電以前曾经说过是新台币每拉升1%就升值1%对美元那么营业利润率就会下降0.4个0.4%所以这一块我们今天看到台级电呢尽管是消息面是利好数据也不错但是也是高开低走最终只收涨了0.74%台级店是我的池仓股我对它的看法再重申一下目前由于标普已经突破了关键的反转的5650点位置所以我所有的滚动计划都已经停下来了台级店也不例外台積電的後續的看法因為從台積電現在的前章故事上來看的25年的前瞻是139到中位的19826年的前瞻是166到中位的236所以如果隨著自然力的推演到了越接近26年的自然力它越有機會去打出前高了但不會說這麼快所以這是一個長期的持商看法目前對於台積電沒有任何的加倉和检倉的计划直接持有避免受到关税的影响但是这个希望在前沾上面看起来似乎是有一点点失望因为Arm的管理层预进它的专利费的收入的10%到20%是来自于美国的进口商这些进口商很容易受到美国关税导致的需求批软的影响所以AMM其实是间接受到了关税的影响它没有直接影响但是它受到了间接的由于关税导致的需求皮软的影响其实所有的公司理论上都会受到类似的这种影响就是大部分的公司有一些是直接影响有一些是由于需求减缓导致的红关经济的影响另外最大的一个立空是他不选择不提供2026才年的前瞻指引因為為什麼是26才年的因為他的材料結局是3月剛剛結束的是25才年3月份的這個材料所以他現在是26年3月新的一個材料開始了材料也開始了那麼他不提供指引主要是首席财务官说市场的现在有一些不可预测的信号因为他的合作伙伴非常的谨慎认为现在的潜在的无关经济干扰是主要的原因他的合作伙伴里边几乎没有提供全年之一的所以到他手里边他就更加没有办法预估了他说特别是与关税相关的不确定性增加了另一个不可预测的因素熟悉财务官表示说如果我们提供了一个直引区间那就必须给出一个比去年更广泛的区间他说这个不知道是否会有帮助既然没有帮助他就选择不提供这也是昨天的 这些是先跌然后市场后来回过味来了也不是他自己的原因整个市场现在都面临不缺电信那大家就以不变应万变的然后就选择了在市场收负了跌幅之后的一个横盘好 这个是阿们的情况那么阿们的前张估值呢 继于高倍的参考40到60倍80到120下个才年27年是108到163中卫是136从他的前站批上来看 市价在155块钱已经是前站批高达了接近60倍这并不是一个很便宜的估值所以说暗其实已经蛮打满算的既嫁了它的增长而且这个增长这边我现在是把它给拿掉了暂时增长率预计后面会有调整的目前是基于共时得出来的一个前占估值的情况所以暗之前其实跑到什么180多块钱的很显然是明显高估的现在是逐渐的回归到基本面但是基本上也是把未来两年的增长的价格全部打进去了所以你要说一定要在这个地方要去强行上车那只能说你可能看得更远就是往后再看个三年四年就可以紧从最近两年的情况来看价格至少在一年之内肯定不算便宜 放到明年还可以 放到再过一年 但现在新的财链才刚刚开始 还有整整两年时间好 他的情况目前是一个宽的震荡区间就是上方是12到136压的下方是68.6到80.4就是上次的低点位置顶着这两个区间是他最近的正当区间他只有突破120到136才能确定结束这个正当区域只有突破148才能确定重回上行区间所以它的价格非常的宽也是一支高波動的股票接下來我想說一下英偉達有两位消息是因为达已经通知了包括头部云服务商灾内的中国的主要客户目标是在7月份发布改200的H20芯片可能会避开美国的限制谈到这件事我就开个玩笑多调侃两句我觉得吧这个芯片这事真的是替老黄为难这个事成了一个死循环为什么你看美国政府说老黄高兴能的芯片要限制因为大家说好我修改后降低性能的我们自己有长得不太一样而已。最后是任天堂结化了,说老黄你这个行,未来的Switch3游戏机我们正好能用上。老黄是不是一口劳学得喷下来不断的去降低性能配合出口的要求但是又面临着中国的竞争对手的竞争本来是高性能的领先的产品高利润毛利率的产品一定要做成低利润低毛利的产品而且本来是一片南海市场的非要跑到红海市场里边去抢夺所以有时候我们说生意归生意其实这波许可症的限制英伟达是产生了额外55亿的费用损失市场预计如果加上赢收的损失可能高达一百亿美元这个是实实在在的损失这个和鼓励美国企业创新支持美国制造的大的思路它是不相符的美国政府必须得拿出细节方案就是到底怎么在保护美国的国家安全还有保护美国企业之间找到一个平衡才行 对不对所以咱们耐心等待下一步美国政府对于芯片关税出口的新的政策细节因为之前不是说要拿掉拜登的三级分类管制嘛那可能要推出一些新的政策咱们看看后面会怎么办这是因为达价格方面就不多说了突破125他才能够确认指跌突破125例的不远还有机会别看今天下跌了实际上今天是个缩量问题不大好来看一下XP的我们在线预定商的财务信息它是第一财纪的财报非常的糟糕盘后其实今天还收服了不少的跌幅之前跌得更多由于公司在一季度财报中描绘了美国境内还有入境旅游需求的案弹前景所以这是股价大跌最主要的原因由需求弱于预期的局面前占给的更差所以优在公司的财报会议上说4月份的业级是略训于3月份而且下条了全年的预定量和收入预期他说目前预计这两项指标的增长幅度只在2%到4%之间之前给的前卵是4%到6%所以也是差不多腰展所以他的錢債估值給大家做完更新是這樣16.5倍到30.8倍的歷數博動25年的錢債是166到310大家看中位高位太高了166到23826年是199到286增速我这里没有写因为市场与记以后面面临的红关风险有可能会让他继续的下条前站这是目前看到的在这个行业里边由于EXP的生意模式经常会有朋友会把它和BKNG来做比较为什么BKNG的价格会好一点然后EXP的价格就比较皮软最主要的原因是两边的生意模式的主营队项不一样EXP的对企业的就是B2B的这个客户一层度非常的高另外BKNG它是B2C比较高所以红关经济的影响影响到企业的支出你想想如果经济大环节不好企業在支出上會稍微的請深一些那你猜旅、住宿、預定你可能都會降下來包括我們現在看到影響到了航空業也是這個原因就是因為大的經濟環境的不穩定企業其實也在減少贏的支出希望能夠保持更多的利潤所以以前可能你出差一年得七八四五六四的朋友现在可能你一年也就出去一次以前可能让你出去住非常好的酒店的朋友现在告诉你你就FBNB湊回一下得了所以这个就不一样这是宏观大经济环境对于这个在线的包括预定 旅行等等企业类要省钱这是他的目前的情况不过好的是下方的几个强制生比较的强从132到154是他比较不错的就是上次的低点到现在的强制生区域如果这个地方能盘出一个底来这个地方还行这个地方还是长线还是因为属于低估的位置还是相对可以的但是你要做好前站继续下条的准备取决于能下条多少如果它从增长转入摔退那就是另外一个故事了好吧好然后我们来看一下另外两个医药相关的一个U and H一个是理来首先说一下U and HU and H最近是麻烦不断一个是业绩成压 第二个是集体诉讼第三个是可能还会面临着依保药费用的改革问题今天是已经跌破了389块钱UH咱们上次讲过一次因为它的前脏孤之的下线目前是400它不应该跌破400就是这个389到426本来是非常强的一个支撑位置也是前章估值的下显位置他不应该跌破而一旦跌破进入低估区域同时失手了最近的强制称代表着机构也正在失去信心风险还在放大所以现在英文史的位置是先寻求指跌为主尽管可能会在下方的370到3701这一线有所反弹但是反弹的目标也只能再是看到389到426因为这是一个关键位置现在是滴破位了如果还没有持有的朋友那么最好的先不要早期进场什么时候能指跌能衡处一个底来再说如果已经持有的朋友要么跌破之后其实你可能已经做过处理了要么你就是没做处理的等反弹之后也得思考一下还值不值得继续冒险因为现在美国的要行业这边也正在面临着一些变化我们就要讲这个变化是什么现在的智要行业要行业面临着来自于政策方面的有三个可能会重大的调整这些东西这个信息有可能在下个星期会有初步的信息出来第一个是关税的调整这是一直在谈的因为有一些药品涉及到关税的问题第二美国药品定价的威胁有可能会把药品的价格给打下来第三就是对药�品送達美國患者的速度的威脅就是有要求對於送貨給藥物送到美國患者身上其實這幾個東西他們都是一個東西就是對於醫藥行業進行改革那麼每個中央的川普表示說藥品定價的相关消息即将到来我们下个星期就会公布其中的78倍政府很可能会限制药价限制药价比如很多的药期对吧像李莱他的�价是不是比较高啊为什么下跌也是因为这些利空市场的现在有点害怕不知道会怎么去限制李莱公司对于下条要价他在给媒体的电子油件回复中是这么说的啊说最会国定价是一种误导性的要品价格调整常试它对患者毫无意处同时还会危急生物质药公司进其宣布的近2,000亿美元的美国的新投资其他的公司没有立即回应智平请求那么李来回应了说明什么说明它很害怕因为它的药价高如果真的限制对他的利润是严重的打击尽管他的药效会好一些但他的药价也会更高的咱们之前还做过一个调查就是在李莱和MGO之间你会选择谁就是如果你能负担的起的情况下很多朋友还是选择能负担的起的情況下選擇要效較好的但現在如果價格被打下來那就會存在一個問題就是毛利潤會下來但是可能銷量會上去就看這裡邊兩邊的拉扯怎麼辦但對於公司來講他們總體上是利空所以下個星期我是建議手上持有要起的朋友要注意一下如果政策真的要求大幅降低要价一定会影响到公司的业绩和持有的信心特别是相对有高估部分的一些要起大家千万要注意不能再追了而且你要做好一定的防御的心态如果你是正在等待做要起比如像李萊这样的对吧711到791是激进的长现为什么是激进的因为你可以看一下他现在25年的前瞻本身就是基于30到40倍的高参考是64 4到859中卫是751那么如果不是基于这么高的增长他的利润下来了呢是不是有这么高的倍数增长呢这是值得去思考的问题所以我才说这个地方是激进的啊如果真的要加下来他也跌破了711会直接下看650的下方代表着前南固执已经市场的从机构层面已经是做出了一些调整好吧所以希望大家下个星期关注一下要起相关的信息生物质药最近很多的公司走得都非常差也主要是受到这些相关的药物改革医疗改革相关信息的影响好这个就是今天带给大家的關於市場的一些個股的更新和解讀在州務的時候那給大家也都講了不少相信大家週末的時候如果拿出來看一看應該還是會有一些幫助的那麼本週末最大的消息我們就是耐心的去等待中美的關稅的第一次談判看看大家能不能吧至少有一個相对友好的氛围吧咱们不说第一次能谈出个什么结果来至少双方谈完之后出来以后都不是怒气冲天对吧都不是互相扯皮而是以一种比较友好的态度共同发表了一些声明一些框架这个就是好消息大家不要对细节暂时抱有太大的希望没有这么快我们通过美国和其他国家的谈判的周期来看不可能有这么快得出结果你再快的话一个一个星期你稍微卖一点一个月两个月都有可能的但是开始谈了这个就是好消息啊然后到了周日的时候呢 仍舊会去更新这个打一体就是在社区下面你加入这个级别之后啊 让我打一级别你会到社区下面载一个带有QA和时间图片的铁字 你在评论区提问每天呢 我的会抽供回答周末的时候会稍微挤压一下好 这个就是咱们今天节目的全部内容希望大家周末呢 也好好的养经序内吧预计呢 計因為下個星期還有月期全的結算再加上中美關稅本週末的消息還有要起的改革的一些消息還有可能會有半導體關稅的一些消息總之一堆亂麻結合到一塊市場也不會太太平今天節目我们今天节目到这非常感谢大家持续不断的点赞评论 准发那我们就下个星期一的同一时间 不见 不散')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3661b2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大家好 歡迎回到視野環球財經 我是Rino現在是美東世界 二五年5月9日週五晚上的8點25分今天是標普高開不過美國總統川普提出將中國的關稅從145降到80的想法但他們表示這將取決於美國財長貝森特其實如此之高的關税是大幅高于市场的预期所以股市和国债是双双下跌回徒了高开的账赋今天的收盘价和昨天是基本持平不过今天少数的个股市走出了独立行情比如特斯拉特斯拉这边今天是放量上行朝着突破之后就是2007这个突破上行突破之后的下一个波段目标位更上一层楼这个目标位是3 2 6到367但是我这里要提醒一下这个波段目标的压力是比较大的预计一次非常难过去因为这个地方是它上看前高之前最大的压力位置而且从下个星期的月期权结算的位置来看300块钱上下大概是21美元左右的波动这就意味着下个星期的月期全結算的位置來看300塊錢上下大概是21美元左右的波動這對意味著下個星期想去突破壓力是一個非常小的概率但是如果有一些新的關稅其他的利好消息出來走入到小概率區間出外但向上是有機會摸到壓力位的下延的如果下感性机是下跌那么回撤大概是在2008的上方所以特斯拉后面还是继续上看326到367的这个波段那么做波段的朋友自行做好交易计划好 接下来时间我会直接去跟踪讲解一些个国从亚马运开始是一直会讲到李莱首先说亚马运亚马运昨天其实收盘价就已经是占稳了191块钱这个地方咱们之前曾经讲过191占稳之后它就比较稳当了但是它现在在今天收盘第二天收到了191的上方总体上大家也不要期望他能跑得特别的快因为市场对他的波动压住其实并不高下个星期大概是七八块钱左右的上下波动也就是说能够维持在182的强支撰的上方然后逐渐的寻求低点抬高高点也逐渐抬高的这么一个过程因为沿往讯这只股票的特性它不是那种暴力拉升很快几下就拉上去的它是属于罗选市上升这种走势是比较明显的股票所以所以長期持有亞馬遜的朋友如果你是在191到下方的166區間在這個區間進場的朋友暫時你可以拿得比較穩當了沒有什麼太大的問題了如果想做波段的朋友呢讓他講過不要期待他跑得特別的快會是一個比較慢较慢的过程接下来说一下关于台积电首先说一下关于整个的台湾产品出口的一个背景整个的台湾4月份商品出口是同比增长29.9%几乎是市场预期的2倍值得注意的是对于美国的出口同比增长29.5%当然很大程度上是得益于对高科技产品的旺盛需求按照产品来细分信息通信和视频产品比如电脑笔记本显示器的出货量是同比增长60.5%于是同时半导是同比增長28.2%台積電在這個大的背景下4月的銷售也非常的旺盛4月份銷售額是3495.7億新台幣還比增長28.2%同比增長48.1%遠遠超過分析師預期的38%那麼較上個月的46.5%的同比增速有所加快不過現在有一個逆風就是新台幣最近長得非常的厲害飆升這個會給台積電帶來利潤率的壓力台積電以前曾经说过是新台币每拉升1%就升值1%对美元那么营业利润率就会下降0.4个0.4%所以这一块我们今天看到台级电呢尽管是消息面是利好数据也不错但是也是高开低走最终只收涨了0.74%台级店是我的池仓股我对它的看法再重申一下目前由于标普已经突破了关键的反转的5650点位置所以我所有的滚动计划都已经停下来了台级店也不例外台積電的後續的看法因為從台積電現在的前章故事上來看的25年的前瞻是139到中位的19826年的前瞻是166到中位的236所以如果隨著自然力的推演到了越接近26年的自然力它越有機會去打出前高了但不會說這麼快所以這是一個長期的持商看法目前對於台積電沒有任何的加倉和检倉的计划直接持有避免受到关税的影响但是这个希望在前沾上面看起来似乎是有一点点失望因为Arm的管理层预进它的专利费的收入的10%到20%是来自于美国的进口商这些进口商很容易受到美国关税导致的需求批软的影响所以AMM其实是间接受到了关税的影响它没有直接影响但是它受到了间接的由于关税导致的需求皮软的影响其实所有的公司理论上都会受到类似的这种影响就是大部分的公司有一些是直接影响有一些是由于需求减缓导致的红关经济的影响另外最大的一个立空是他不选择不提供2026才年的前瞻指引因為為什麼是26才年的因為他的材料結局是3月剛剛結束的是25才年3月份的這個材料所以他現在是26年3月新的一個材料開始了材料也開始了那麼他不提供指引主要是首席财务官说市场的现在有一些不可预测的信号因为他的合作伙伴非常的谨慎认为现在的潜在的无关经济干扰是主要的原因他的合作伙伴里边几乎没有提供全年之一的所以到他手里边他就更加没有办法预估了他说特别是与关税相关的不确定性增加了另一个不可预测的因素熟悉财务官表示说如果我们提供了一个直引区间那就必须给出一个比去年更广泛的区间他说这个不知道是否会有帮助既然没有帮助他就选择不提供这也是昨天的 这些是先跌然后市场后来回过味来了也不是他自己的原因整个市场现在都面临不缺电信那大家就以不变应万变的然后就选择了在市场收负了跌幅之后的一个横盘好 这个是阿们的情况那么阿们的前张估值呢 继于高倍的参考40到60倍80到120下个才年27年是108到163中卫是136从他的前站批上来看 市价在155块钱已经是前站批高达了接近60倍这并不是一个很便宜的估值所以说暗其实已经蛮打满算的既嫁了它的增长而且这个增长这边我现在是把它给拿掉了暂时增长率预计后面会有调整的目前是基于共时得出来的一个前占估值的情况所以暗之前其实跑到什么180多块钱的很显然是明显高估的现在是逐渐的回归到基本面但是基本上也是把未来两年的增长的价格全部打进去了所以你要说一定要在这个地方要去强行上车那只能说你可能看得更远就是往后再看个三年四年就可以紧从最近两年的情况来看价格至少在一年之内肯定不算便宜 放到明年还可以 放到再过一年 但现在新的财链才刚刚开始 还有整整两年时间好 他的情况目前是一个宽的震荡区间就是上方是12到136压的下方是68.6到80.4就是上次的低点位置顶着这两个区间是他最近的正当区间他只有突破120到136才能确定结束这个正当区域只有突破148才能确定重回上行区间所以它的价格非常的宽也是一支高波動的股票接下來我想說一下英偉達有两位消息是因为达已经通知了包括头部云服务商灾内的中国的主要客户目标是在7月份发布改200的H20芯片可能会避开美国的限制谈到这件事我就开个玩笑多调侃两句我觉得吧这个芯片这事真的是替老黄为难这个事成了一个死循环为什么你看美国政府说老黄高兴能的芯片要限制因为大家说好我修改后降低性能的我们自己有长得不太一样而已。最后是任天堂结化了,说老黄你这个行,未来的Switch3游戏机我们正好能用上。老黄是不是一口劳学得喷下来不断的去降低性能配合出口的要求但是又面临着中国的竞争对手的竞争本来是高性能的领先的产品高利润毛利率的产品一定要做成低利润低毛利的产品而且本来是一片南海市场的非要跑到红海市场里边去抢夺所以有时候我们说生意归生意其实这波许可症的限制英伟达是产生了额外55亿的费用损失市场预计如果加上赢收的损失可能高达一百亿美元这个是实实在在的损失这个和鼓励美国企业创新支持美国制造的大的思路它是不相符的美国政府必须得拿出细节方案就是到底怎么在保护美国的国家安全还有保护美国企业之间找到一个平衡才行 对不对所以咱们耐心等待下一步美国政府对于芯片关税出口的新的政策细节因为之前不是说要拿掉拜登的三级分类管制嘛那可能要推出一些新的政策咱们看看后面会怎么办这是因为达价格方面就不多说了突破125他才能够确认指跌突破125例的不远还有机会别看今天下跌了实际上今天是个缩量问题不大好来看一下XP的我们在线预定商的财务信息它是第一财纪的财报非常的糟糕盘后其实今天还收服了不少的跌幅之前跌得更多由于公司在一季度财报中描绘了美国境内还有入境旅游需求的案弹前景所以这是股价大跌最主要的原因由需求弱于预期的局面前占给的更差所以优在公司的财报会议上说4月份的业级是略训于3月份而且下条了全年的预定量和收入预期他说目前预计这两项指标的增长幅度只在2%到4%之间之前给的前卵是4%到6%所以也是差不多腰展所以他的錢債估值給大家做完更新是這樣16.5倍到30.8倍的歷數博動25年的錢債是166到310大家看中位高位太高了166到23826年是199到286增速我这里没有写因为市场与记以后面面临的红关风险有可能会让他继续的下条前站这是目前看到的在这个行业里边由于EXP的生意模式经常会有朋友会把它和BKNG来做比较为什么BKNG的价格会好一点然后EXP的价格就比较皮软最主要的原因是两边的生意模式的主营队项不一样EXP的对企业的就是B2B的这个客户一层度非常的高另外BKNG它是B2C比较高所以红关经济的影响影响到企业的支出你想想如果经济大环节不好企業在支出上會稍微的請深一些那你猜旅、住宿、預定你可能都會降下來包括我們現在看到影響到了航空業也是這個原因就是因為大的經濟環境的不穩定企業其實也在減少贏的支出希望能夠保持更多的利潤所以以前可能你出差一年得七八四五六四的朋友现在可能你一年也就出去一次以前可能让你出去住非常好的酒店的朋友现在告诉你你就FBNB湊回一下得了所以这个就不一样这是宏观大经济环境对于这个在线的包括预定 旅行等等企业类要省钱这是他的目前的情况不过好的是下方的几个强制生比较的强从132到154是他比较不错的就是上次的低点到现在的强制生区域如果这个地方能盘出一个底来这个地方还行这个地方还是长线还是因为属于低估的位置还是相对可以的但是你要做好前站继续下条的准备取决于能下条多少如果它从增长转入摔退那就是另外一个故事了好吧好然后我们来看一下另外两个医药相关的一个U and H一个是理来首先说一下U and HU and H最近是麻烦不断一个是业绩成压 第二个是集体诉讼第三个是可能还会面临着依保药费用的改革问题今天是已经跌破了389块钱UH咱们上次讲过一次因为它的前脏孤之的下线目前是400它不应该跌破400就是这个389到426本来是非常强的一个支撑位置也是前章估值的下显位置他不应该跌破而一旦跌破进入低估区域同时失手了最近的强制称代表着机构也正在失去信心风险还在放大所以现在英文史的位置是先寻求指跌为主尽管可能会在下方的370到3701这一线有所反弹但是反弹的目标也只能再是看到389到426因为这是一个关键位置现在是滴破位了如果还没有持有的朋友那么最好的先不要早期进场什么时候能指跌能衡处一个底来再说如果已经持有的朋友要么跌破之后其实你可能已经做过处理了要么你就是没做处理的等反弹之后也得思考一下还值不值得继续冒险因为现在美国的要行业这边也正在面临着一些变化我们就要讲这个变化是什么现在的智要行业要行业面临着来自于政策方面的有三个可能会重大的调整这些东西这个信息有可能在下个星期会有初步的信息出来第一个是关税的调整这是一直在谈的因为有一些药品涉及到关税的问题第二美国药品定价的威胁有可能会把药品的价格给打下来第三就是对药�品送達美國患者的速度的威脅就是有要求對於送貨給藥物送到美國患者身上其實這幾個東西他們都是一個東西就是對於醫藥行業進行改革那麼每個中央的川普表示說藥品定價的相关消息即将到来我们下个星期就会公布其中的78倍政府很可能会限制药价限制药价比如很多的药期对吧像李莱他的�价是不是比较高啊为什么下跌也是因为这些利空市场的现在有点害怕不知道会怎么去限制李莱公司对于下条要价他在给媒体的电子油件回复中是这么说的啊说最会国定价是一种误导性的要品价格调整常试它对患者毫无意处同时还会危急生物质药公司进其宣布的近2,000亿美元的美国的新投资其他的公司没有立即回应智平请求那么李来回应了说明什么说明它很害怕因为它的药价高如果真的限制对他的利润是严重的打击尽管他的药效会好一些但他的药价也会更高的咱们之前还做过一个调查就是在李莱和MGO之间你会选择谁就是如果你能负担的起的情况下很多朋友还是选择能负担的起的情況下選擇要效較好的但現在如果價格被打下來那就會存在一個問題就是毛利潤會下來但是可能銷量會上去就看這裡邊兩邊的拉扯怎麼辦但對於公司來講他們總體上是利空所以下個星期我是建議手上持有要起的朋友要注意一下如果政策真的要求大幅降低要价一定会影响到公司的业绩和持有的信心特别是相对有高估部分的一些要起大家千万要注意不能再追了而且你要做好一定的防御的心态如果你是正在等待做要起比如像李萊这样的对吧711到791是激进的长现为什么是激进的因为你可以看一下他现在25年的前瞻本身就是基于30到40倍的高参考是64 4到859中卫是751那么如果不是基于这么高的增长他的利润下来了呢是不是有这么高的倍数增长呢这是值得去思考的问题所以我才说这个地方是激进的啊如果真的要加下来他也跌破了711会直接下看650的下方代表着前南固执已经市场的从机构层面已经是做出了一些调整好吧所以希望大家下个星期关注一下要起相关的信息生物质药最近很多的公司走得都非常差也主要是受到这些相关的药物改革医疗改革相关信息的影响好这个就是今天带给大家的關於市場的一些個股的更新和解讀在州務的時候那給大家也都講了不少相信大家週末的時候如果拿出來看一看應該還是會有一些幫助的那麼本週末最大的消息我們就是耐心的去等待中美的關稅的第一次談判看看大家能不能吧至少有一個相对友好的氛围吧咱们不说第一次能谈出个什么结果来至少双方谈完之后出来以后都不是怒气冲天对吧都不是互相扯皮而是以一种比较友好的态度共同发表了一些声明一些框架这个就是好消息大家不要对细节暂时抱有太大的希望没有这么快我们通过美国和其他国家的谈判的周期来看不可能有这么快得出结果你再快的话一个一个星期你稍微卖一点一个月两个月都有可能的但是开始谈了这个就是好消息啊然后到了周日的时候呢 仍舊会去更新这个打一体就是在社区下面你加入这个级别之后啊 让我打一级别你会到社区下面载一个带有QA和时间图片的铁字 你在评论区提问每天呢 我的会抽供回答周末的时候会稍微挤压一下好 这个就是咱们今天节目的全部内容希望大家周末呢 也好好的养经序内吧预计呢 計因為下個星期還有月期全的結算再加上中美關稅本週末的消息還有要起的改革的一些消息還有可能會有半導體關稅的一些消息總之一堆亂麻結合到一塊市場也不會太太平今天節目我们今天节目到这非常感谢大家持续不断的点赞评论 准发那我们就下个星期一的同一时间 不见 不散'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0821e47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs\\\\youtube\\\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "183722da",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=x8FASlLf5ls\"\n",
    "metadata = fetch_youtube_metadata(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62bb8261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！',\n",
       " 'description': '加会员前必读！\\n\\n大家好，视野环球财经的会员功能开通了。\\n\\n【如何加入会员？】\\n在你手机或电脑端，打开视野环球财经栏目，在订阅旁，有一个“加入/Join”按钮，点击加入即可。或点击链接：https://www.youtube.com/channel/UCFQsi7WaF5X41tcuOryDk8w/join\\n\\n【看不到“加入/Join”怎么办？】\\n如果你所在的地区，没有任何限制，比如美、加、澳洲、欧洲都没有限制，但还是看不到“加入/Join”按钮怎么办？\\n\\n建议使用非苹果系统，用电脑端、手机端，浏览器或者App打开YouTube，就能看到“加入/Join”按钮。苹果系统，有时候看不到“加入/Join”按钮，你可以尝试在Ipad或Mac上，使用Safari 或者Chrome浏览器登陆YouTube（不要使用YouTube App），就能看到加入按钮。加入成功后，可以正常使用YouTube App观看节目。\\n\\n如果你的地区受到YouTube限制，不支持加会员，使用上述方法，依旧无法加入YouTube会员，可以选择替代方案，订阅我的Patreon会员，会同步更新YouTube会员视频。https://www.patreon.com/RhinoBull\\n\\n【免费视频的更新受影响吗？】 \\n\\n免费视频的更新不受任何影响，目前免费视频的更新频率为，每个交易日的盘后更新，周末的视频，根据行情的重要程度确定是否更新，未来免费视频也会维持这个更新节奏。\\n\\n【会员功能和免费视频的区别是什么呢？】\\n\\n首先强调，如果你觉得目前的免费视频，对你来说信息量足够用，你完全不必花钱购买会员功能！毕竟再小的钱也是钱，我一直倡导理性投资，理性消费。\\n\\n付费会员功能，是针对极少数观众提出的需求开通的，是免费节目的延伸和补充！会涉及更多的细节层面！\\n\\n【加入会员到底能看到什么？】\\n\\n会员有专属的视频和帖子，内容包括：我的个股、行业研究；潜在的短线、中线、长线投资机会、策略分享；投资心理、实用交易技巧；会员优先答疑。\\n\\n【三个级别会员级别有什么区别？】\\n\\n“每周一杯咖啡学投资”会员级别：提供会员视频，每周至少更新一次（遇到长周末，比如周五或者周一公共假期，加上周六、周日，连续放假三天的情况，会员节目不更新），内容目录可查看：频道首页-播放列表-会员专享播放列表，加入会员后，之前旧视频也可查看。\\n\\n“Rhino 答疑”会员级别：“每周一杯咖啡学投资”级别内容+专属答疑帖子（回答包括个股估值、支撑、压力、趋势、行情趋势、版块、投资机会、被套怎办等各种问题。）\\n\\n“感谢你，朋友！”会员级别：如果你想表达对我的感谢，可以加入该级别，目前和“Rhino 答疑”提供的内容一样，未来如果要分享我的个人核心数据，会优先分享至该级别会员中。\\n\\n【更新频率】\\n\\n会员视频不是每天更新，频率为不定期更新，我尽量确保每周至少更新1个视频，帖子数量不限。\\n\\n【为了避免大家失望，引不必要的争议，接下来是重要提示：会员不保证什么？】\\n\\n会员视频不保证一夜暴富，不喊单、不带单，但我会分享赢面较大的个人操作点位，供大家参考，只分享个人认知，大家独立决策，自负盈亏；\\n\\n也不提供任何微信、电报群组，因为YouTube会员社区帖子就可以交流；\\n\\n最后，会员社区的内容，我只提供碎片化的重点和细节，不承诺提供任何成套的技术教学，比如课时较长、较复杂的，如K线技术教学、期权技术教学等，如果部分会员有强烈系统学习的需求，而且咱们在会员专区相处得不错，条件允许的情况下可以考虑小班系统授课，并不包含在会员视频服务内。\\n\\n【如何加入会员？】\\n\\n在你手机或电脑端，打开视野环球财经栏目，在订阅旁，有一个“加入”按钮，点击加入即可。或点击链接：https://www.youtube.com/channel/UCFQsi7WaF5X41tcuOryDk8w/join\\n\\n最好使用非苹果系统，如果你看不到“加入”按钮，说明你所在的国家或地区，不支持开通会员服务，请上网搜索解决方法，或者尝试使用非苹果系统的电脑端查看。\\n\\n以上就是大家在加入会员前，需要了解的全部内容！\\n\\n最后，不管大家是否加入会员，都祝大家投资成功！期待大家的加入！我在会员专区等你，期待咱们互利共赢！\\n\\n#药企小心 #UNH #LLY #TSLA #AMZN #NVDA #TSM #ARM',\n",
       " 'upload_date': '20250510',\n",
       " 'duration': 1495,\n",
       " 'view_count': 49112,\n",
       " 'like_count': 3249,\n",
       " 'channel': '视野环球财经',\n",
       " 'channel_url': 'https://www.youtube.com/@RhinoFinance',\n",
       " 'tags': ['UNH', 'LLY', 'TSLA', 'AMZN', 'TSM', 'ARM', 'NVDA'],\n",
       " 'categories': ['People & Blogs'],\n",
       " 'thumbnail': 'https://i.ytimg.com/vi/x8FASlLf5ls/maxresdefault.jpg',\n",
       " 'webpage_url': 'https://www.youtube.com/watch?v=x8FASlLf5ls'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca7f4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1].metadata.update(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05eaf9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs\\\\youtube\\\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a',\n",
       " 'title': '美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！',\n",
       " 'description': '加会员前必读！\\n\\n大家好，视野环球财经的会员功能开通了。\\n\\n【如何加入会员？】\\n在你手机或电脑端，打开视野环球财经栏目，在订阅旁，有一个“加入/Join”按钮，点击加入即可。或点击链接：https://www.youtube.com/channel/UCFQsi7WaF5X41tcuOryDk8w/join\\n\\n【看不到“加入/Join”怎么办？】\\n如果你所在的地区，没有任何限制，比如美、加、澳洲、欧洲都没有限制，但还是看不到“加入/Join”按钮怎么办？\\n\\n建议使用非苹果系统，用电脑端、手机端，浏览器或者App打开YouTube，就能看到“加入/Join”按钮。苹果系统，有时候看不到“加入/Join”按钮，你可以尝试在Ipad或Mac上，使用Safari 或者Chrome浏览器登陆YouTube（不要使用YouTube App），就能看到加入按钮。加入成功后，可以正常使用YouTube App观看节目。\\n\\n如果你的地区受到YouTube限制，不支持加会员，使用上述方法，依旧无法加入YouTube会员，可以选择替代方案，订阅我的Patreon会员，会同步更新YouTube会员视频。https://www.patreon.com/RhinoBull\\n\\n【免费视频的更新受影响吗？】 \\n\\n免费视频的更新不受任何影响，目前免费视频的更新频率为，每个交易日的盘后更新，周末的视频，根据行情的重要程度确定是否更新，未来免费视频也会维持这个更新节奏。\\n\\n【会员功能和免费视频的区别是什么呢？】\\n\\n首先强调，如果你觉得目前的免费视频，对你来说信息量足够用，你完全不必花钱购买会员功能！毕竟再小的钱也是钱，我一直倡导理性投资，理性消费。\\n\\n付费会员功能，是针对极少数观众提出的需求开通的，是免费节目的延伸和补充！会涉及更多的细节层面！\\n\\n【加入会员到底能看到什么？】\\n\\n会员有专属的视频和帖子，内容包括：我的个股、行业研究；潜在的短线、中线、长线投资机会、策略分享；投资心理、实用交易技巧；会员优先答疑。\\n\\n【三个级别会员级别有什么区别？】\\n\\n“每周一杯咖啡学投资”会员级别：提供会员视频，每周至少更新一次（遇到长周末，比如周五或者周一公共假期，加上周六、周日，连续放假三天的情况，会员节目不更新），内容目录可查看：频道首页-播放列表-会员专享播放列表，加入会员后，之前旧视频也可查看。\\n\\n“Rhino 答疑”会员级别：“每周一杯咖啡学投资”级别内容+专属答疑帖子（回答包括个股估值、支撑、压力、趋势、行情趋势、版块、投资机会、被套怎办等各种问题。）\\n\\n“感谢你，朋友！”会员级别：如果你想表达对我的感谢，可以加入该级别，目前和“Rhino 答疑”提供的内容一样，未来如果要分享我的个人核心数据，会优先分享至该级别会员中。\\n\\n【更新频率】\\n\\n会员视频不是每天更新，频率为不定期更新，我尽量确保每周至少更新1个视频，帖子数量不限。\\n\\n【为了避免大家失望，引不必要的争议，接下来是重要提示：会员不保证什么？】\\n\\n会员视频不保证一夜暴富，不喊单、不带单，但我会分享赢面较大的个人操作点位，供大家参考，只分享个人认知，大家独立决策，自负盈亏；\\n\\n也不提供任何微信、电报群组，因为YouTube会员社区帖子就可以交流；\\n\\n最后，会员社区的内容，我只提供碎片化的重点和细节，不承诺提供任何成套的技术教学，比如课时较长、较复杂的，如K线技术教学、期权技术教学等，如果部分会员有强烈系统学习的需求，而且咱们在会员专区相处得不错，条件允许的情况下可以考虑小班系统授课，并不包含在会员视频服务内。\\n\\n【如何加入会员？】\\n\\n在你手机或电脑端，打开视野环球财经栏目，在订阅旁，有一个“加入”按钮，点击加入即可。或点击链接：https://www.youtube.com/channel/UCFQsi7WaF5X41tcuOryDk8w/join\\n\\n最好使用非苹果系统，如果你看不到“加入”按钮，说明你所在的国家或地区，不支持开通会员服务，请上网搜索解决方法，或者尝试使用非苹果系统的电脑端查看。\\n\\n以上就是大家在加入会员前，需要了解的全部内容！\\n\\n最后，不管大家是否加入会员，都祝大家投资成功！期待大家的加入！我在会员专区等你，期待咱们互利共赢！\\n\\n#药企小心 #UNH #LLY #TSLA #AMZN #NVDA #TSM #ARM',\n",
       " 'upload_date': '20250510',\n",
       " 'duration': 1495,\n",
       " 'view_count': 49112,\n",
       " 'like_count': 3249,\n",
       " 'channel': '视野环球财经',\n",
       " 'channel_url': 'https://www.youtube.com/@RhinoFinance',\n",
       " 'tags': ['UNH', 'LLY', 'TSLA', 'AMZN', 'TSM', 'ARM', 'NVDA'],\n",
       " 'categories': ['People & Blogs'],\n",
       " 'thumbnail': 'https://i.ytimg.com/vi/x8FASlLf5ls/maxresdefault.jpg',\n",
       " 'webpage_url': 'https://www.youtube.com/watch?v=x8FASlLf5ls'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_youtube_document(\n",
    "    url=\"https://www.youtube.com/watch?v=x8FASlLf5ls\",\n",
    "    save_dir=\"docs/youtube/\",\n",
    "    local=True,\n",
    "    language=\"zh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f61d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     ------------------------------ ------- 786.4/981.5 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 2.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: six in d:\\superengineer\\training\\cousera\\langchain-chat-with-your-data\\.venv\\lib\\site-packages (from langdetect) (1.17.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml): started\n",
      "  Building wheel for langdetect (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993363 sha256=ac3bc936df2544609a23432b0f3a627d6943c44a04816e9f2a3ea757186be100\n",
      "  Stored in directory: c:\\users\\owner\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c73edeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import re\n",
    "\n",
    "def detect_lang_from_text(text: str) -> str:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang == \"zh-cn\" or lang == \"zh-tw\":\n",
    "            return \"zh\"\n",
    "        return lang\n",
    "    except:\n",
    "        return \"en\"  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb4b6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=bSKX_PPflsk\"\n",
    "# Detect language from title + description\n",
    "metadata = fetch_youtube_metadata(url)\n",
    "combined_text = f\"{metadata.get('title', '')} {metadata.get('description', '')}\"\n",
    "detected_language = detect_lang_from_text(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e558758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zh'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97904ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers.audio import (\n",
    "    OpenAIWhisperParser,\n",
    "    OpenAIWhisperParserLocal,\n",
    ")\n",
    "from langchain_community.document_loaders.blob_loaders import YoutubeAudioLoader\n",
    "import yt_dlp\n",
    "import os\n",
    "from langdetect import detect\n",
    "import re\n",
    "\n",
    "# Optional: Suppress Hugging Face symlink warning on Windows\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "def fetch_youtube_metadata(url: str) -> dict:\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'skip_download': True,\n",
    "        'extract_flat': False,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "        return {\n",
    "            \"title\": info.get(\"title\"),\n",
    "            \"description\": info.get(\"description\"),\n",
    "            \"upload_date\": info.get(\"upload_date\"),\n",
    "            \"duration\": info.get(\"duration\"),\n",
    "            \"view_count\": info.get(\"view_count\"),\n",
    "            \"like_count\": info.get(\"like_count\"),\n",
    "            \"channel\": info.get(\"uploader\"),\n",
    "            \"channel_url\": info.get(\"uploader_url\"),\n",
    "            \"tags\": info.get(\"tags\"),\n",
    "            \"categories\": info.get(\"categories\"),\n",
    "            \"thumbnail\": info.get(\"thumbnail\"),\n",
    "            \"webpage_url\": info.get(\"webpage_url\"),\n",
    "        }\n",
    "    \n",
    "def detect_lang_from_text(text: str) -> str:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang == \"zh-cn\" or lang == \"zh-tw\":\n",
    "            return \"zh\"\n",
    "        return lang\n",
    "    except:\n",
    "        return \"en\"  # fallback\n",
    "    \n",
    "def load_youtube_document(\n",
    "    url: str,\n",
    "    save_dir: str = \"docs/youtube\",\n",
    "    local: bool = True,\n",
    "    language: str = None\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Loads transcript from YouTube if available, otherwise transcribes from audio.\n",
    "    Returns enriched LangChain Document(s).\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "\n",
    "    # Enrich with metadata and detecting language if needed\n",
    "    metadata = fetch_youtube_metadata(url)\n",
    "    if language is None: # if no language specified, it will be detected based on meta info\n",
    "        print(\"[Language Detection] Language not specified, detecting...\")\n",
    "        combined_text = f\"{metadata.get('title', '')} {metadata.get('description', '')}\"\n",
    "        language = detect_lang_from_text(combined_text)\n",
    "\n",
    "    # Try loading transcript\n",
    "    try:\n",
    "        loader = YoutubeLoader.from_youtube_url(\n",
    "            url,\n",
    "            add_video_info=False,\n",
    "            language=[language],\n",
    "            translation=language\n",
    "        )\n",
    "        docs = loader.load()\n",
    "    except Exception as e:\n",
    "        print(f\"[Transcript Loader] Warning: {e}\")\n",
    "\n",
    "    # If no transcript, fall back to Whisper transcription\n",
    "    if not docs:\n",
    "        print(\"[Fallback] No transcript found. Using Whisper transcription.\")\n",
    "        parser = (\n",
    "            OpenAIWhisperParserLocal()\n",
    "            if local\n",
    "            else OpenAIWhisperParser(language=language)\n",
    "        )\n",
    "        audio_loader = GenericLoader(YoutubeAudioLoader([url], save_dir), parser)\n",
    "        docs = audio_loader.load()\n",
    "\n",
    "\n",
    "    for doc in docs:\n",
    "        doc.metadata.update(metadata)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05ef04ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Language Detection] Language not specified, detecting...\n",
      "[Fallback] No transcript found. Using Whisper transcription.\n",
      "Using the following model:  openai/whisper-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tkFDeadKz2I\n",
      "[youtube] tkFDeadKz2I: Downloading webpage\n",
      "[youtube] tkFDeadKz2I: Downloading tv client config\n",
      "[youtube] tkFDeadKz2I: Downloading tv player API JSON\n",
      "[youtube] tkFDeadKz2I: Downloading ios player API JSON\n",
      "[youtube] tkFDeadKz2I: Downloading m3u8 information\n",
      "[info] tkFDeadKz2I: Downloading 1 format(s): 140\n",
      "[download] docs\\youtube\\特斯拉为何突然上涨？【2025-05-09】.m4a has already been downloaded\n",
      "[download] 100% of   10.98MiB\n",
      "[ExtractAudio] Not converting audio docs\\youtube\\特斯拉为何突然上涨？【2025-05-09】.m4a; file is already in target format m4a\n",
      "Transcribing part docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SuperEngineer\\Training\\Cousera\\LangChain-Chat-with-Your-Data\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing part docs\\youtube\\特斯拉为何突然上涨？【2025-05-09】.m4a!\n",
      "Transcribing part docs\\youtube\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a!\n"
     ]
    }
   ],
   "source": [
    "docs=load_youtube_document(\n",
    "      url=\"https://www.youtube.com/watch?v=tkFDeadKz2I\",\n",
    "      save_dir=\"docs/youtube\",\n",
    "      local=True,\n",
    "      language=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3131b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs\\\\youtube\\\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a', 'title': '特斯拉为何突然上涨？【2025-05-09】', 'description': '加入阳光财经会员，查看及时成交记录，完整连续。每个月还会定期推出会员视频，解答会员提问。https://www.youtube.com/channel/UC2I5em6UyBpQiO-8ZW0nV3w/join\\nIBKR不止是大券商，还免费提供分析师TIPRANKS一致数据。\\nhttps://www.interactivebrokers.com/mkt/?src=sunnyfinance6&url=%2Fcn%2Fwhyib%2Foverview.php\\n\\n\\n\\n……………………………………………….……………………………………………….\\n声明\\n本人及团队不是Financial Advisor，本节目以过往历史视频均仅供信息参考，不构成投资建议。据本频道提供的信息买卖证券，风险自负，与本节目无关。本人节目中涉及的股票均不存在与任何第三方的利益相关联，但本人可能持有或将来可能买卖相关证券。谢谢您的支持！', 'upload_date': '20250509', 'duration': 712, 'view_count': 55442, 'like_count': 2514, 'channel': '阳光财经', 'channel_url': 'https://www.youtube.com/@SUNNYFINANCE', 'tags': ['美股', '美股分析', '技术分析', '阳光财经', 'Sunny', '中概股', '大盘', '美股大盘', '股息', '被动收入', '大盘分析', '特斯拉', 'saham AS', 'Kewangan Sunshine', '陽光財經'], 'categories': ['People & Blogs'], 'thumbnail': 'https://i.ytimg.com/vi/tkFDeadKz2I/maxresdefault.jpg', 'webpage_url': 'https://www.youtube.com/watch?v=tkFDeadKz2I'}, page_content=\" Welcome to CS229 Machine Learning. Some of you know that this class is for this Stanford for a long time. And this is often the class that I most look forward to teaching each year because this is where we've helped, I think several generations of Stanford students become experts in machine learning, got built many of their products and services and startups that I'm sure many of you, all of you are using today. So what I want to do today was spend some time talking over logistics and then spend some time giving you a beginning of an intro, talk a little bit about machine learning. So about two, three, nine. You know, all of you have been reading about AI in the news, about machine learning in the news. And you've pretty heard me or they say AI is a new electricity. Much less a rise of electricity about a hundred years ago, transform every major industry. I think AI, or really, we call it machine learning, but the rest of the world seems to call it AI. Machine learning and AI and deep learning will change the world. And I hope that through 2.29 we'll give you the tools you need so that you can be many of these future titans of industries, that you can be one, the girl that built, you know, hope the large tech companies do the amazing things they do, or build your own startup, or go into some other industry, go transform healthcare, or go transform transportation, or go build a self-driving car, and do all of these things that after this class, I think you'd be able to do. You know, the majority of students applying, the demand for AI skills, the demand for machine learning skills is so vast. I think you all know that. And I think it's because machine learning has advanced so rapidly in the last few years that there are so many opportunities to apply learning algorithms, right? Both in industry as well as in academia. I think today we have the English department professors trying to apply learning algorithms to understand history better. We have lawyers trying to apply machine learning to process legal documents and off campus, every company, both the tech companies as well as a lot of companies that you wouldn't consider tech companies, everything from manufacturing companies, the healthcare companies, the logistics companies are also trying to apply machine learning. So I think that if you look at it on a factual basis, the number of people doing very valuable machine learning projects today is much greater than it was six months ago, and six months ago, it's much greater than it was 12 months ago. And the amount of value, the amount of exciting meaningful work being done in machine learning is very strongly going up. And I think that given the rise of the amount of data we have, as well as the new machine learning tools that we have, it would be a long time before we run out of opportunities, before society as a whole has enough people with the machine learning skillset. So just as maybe 20 years ago was a good time to start working on this internet thing. A lot of people that started working on the internet like 20 years ago at fantastic careers, I think today is a wonderful time to jump to machine learning and the number of, and the opportunities for you to do unique things that no one is, no one else is doing, right? The opportunity for you to go to logistics company and find an exciting way to apply machine learning will be very high because chances are that logistics company has no one else even working on this because they probably can't, they may not be able to hire a fantastic Stanford student as a graduate CS239, right? Because they're just on the law of CS239 graduates around. So what I want to do today is do a quick intro, talk a little bit about logistics, and then we'll spend a second half of the day giving an overview and talk a little bit more about machine learning. And I apologize. I think that this room, according to that sign there, seats, what 300 something students? We have not quite 800 people enrolled in this class. So So if there are people outside and all of the classes are recorded, broadcast on the SPD, they usually, the videos usually made available same day. So for those of you that can't get into the room, my apologies. There were some years where even I had trouble getting into the room, but I'm glad you left me in. But hopefully you can watch, hopefully you can watch all of these things online shortly. Oh, I see, yes. Yeah. I don't know. It's a bit complicated. Yeah. Thank you. I think it's okay. Yeah. Next few classes, if you can squeeze in and use the D NTC. So for now, it might be too complicated. Okay. So quick and chose. Oh, I'm sorry, I should have introduced myself. My name is Andrew. And I want to introduce some of the rest of the teaching team as well. There's a class coordinator. She has been playing this role for many years now and helps keep the trains run on time and make sure that everything in class happens when it's supposed to. So, so, so should be a, and then what's real to have? Do you guys want to stand up? Be the co-head TA. So, our respective, theC students working with me. And so, bring a lot of technical experience, technical experience in machine learning as well as practical know-how on how to actually make these things work. And with the large class that we have, we have a large TA team. Maybe I won't introduce all of the TA's here today, but you meet many of them throughout the school. But the TAs expertise span everything from confusion to natural language processing, to computer biology, to robotics. And so through this quarter, as you work on your class projects, I hope that you get a lot of hope and advice and mentoring from the TAs, all of which all of whom have deep expertise, not just in machine learning, will often in a specific vertical application area of machine learning. So depending on what your project would try to match you to a TAs that can give you advice that's most relevant to whatever project you end up working on. So go out this class. I hope that after the next 10 weeks, you will be an expert in machine learning. It turns out that, you know, and I hope that after this class, you'll be able to go out and build very meaningful machine learning applications, either in an academic setting where hopefully you can apply it to your problems in mechanical engineering, electrical engineering, and English, and law, and education. All of this wonderful work that happens on campus, as well as after you graduate from Stanford to be able to apply it to whatever jobs you find. One of the things I find very exciting about machine learning is that it's no longer a pure tech company only kind of thing. I think that many years ago machine learning was like a thing that computer science department would do and that the elite AI companies like Google and Facebook and by-do and Microsoft would do. But now it is so pervasive that even companies that are not traditional tech companies see a huge need to apply these tools. And I find a lot of the most exciting work these days. And maybe some of you guys know my history, some of the buy-dates. I let the Google Brain team, which helped Google transform from what was already a great company 10 years ago to today, which is a great AI company and then I also let the AI group that I do and you know let the companies technology strategy to help by do also transform from what was already a great company many years ago to today arguably China's greatest AI company so having let the you know build the teams that let the AI transformations of two large tech companies I feel like that's a great thing to do but even beyond tech I think that there's a lot of exciting work to do as well to help other industries to help other sectors Embrace machine learning and use these tools effectively But after this class, I hope that each one of you will be well qualified to get a job at Shiny tech Company and do machine learning there or go into one of these industries and do very valuable machine learning projects there. And in addition, if any of you are taking this class with the primary goal of being able to do research in machine learning, you know, so actually some of you I our PhD students, I hope that this class will also leave you well equipped to really read and understand research papers as well as be qualified to start pushing forward the state of the art. So let's see. So today, so just as machine learning is evolving rapidly, the whole teaching team would be constantly updating CS222.9 as well. So it's actually very interesting. I feel like the pace of progress in machine learning has accelerated. So it actually feels like that the amount we changed the class year over year has been increasing over time. So if your friends took the class last year, things are a little bit different this year because we're constantly updating the class to keep up with what feels like still accelerating progress in the whole future machine learning. So there are some logistical changes. For example, we've gone from a, we used to hand out paper copies of handouts that we're trying to make this class digital only. But let me talk a little bit about prerequisites as well as in case your friends have taken this class before, some of the differences for this year. So prerequisites, We are going to assume that all of you have a knowledge of basic computer skills and principles. So, you know, big old notation, Q, Starrings, binary trees, hopefully you understand what all of those concepts are. And assume that all of you have a basic familiarity with probability, right? That hopefully, you know, what's the random variable, what's the expected value of a random variable, what's the variance of a random variable. And if, for some of you, maybe especially the SCP-D students taking turns in early, if it's been, you know, some number of years since you lost at a probability of statistics loss, we will have review sessions on Fridays where we'll go over some of these prerequisite materials as well. So hopefully you know what the random variables, what the expected value is, but if you're a little bit fuzzy on those concepts, we'll go over them again at a discussion section on Friday. Also assume the familiar basic linear algebra. So hopefully that you know what's the matrix, what's the vector, how to multiply two matrices, or multiply a matrix in a vector. If you know what an eigenvector, then that's even better. If you're not quite sure what an eigenvector is, we'll go over it. And then a large part of this class is having you practice these ideas through the homeworks as well as I mentioned later, an open-ended project. And so, one, we've actually, until now, we used to use MATLAB and ARCTI for the Fermi assignments. But this year we're trying to shift the programming assignments to Python. And so I think for a long time, even today, I sometimes use Octave to prototype because the syntax for Octave is so nice and just run very simple experiments very quickly. But I think the machine learning world is really migrating, I think, from Matt that Python world to increasing, excuse me, Matt that octave world to increasingly a Python maybe an then eventually for production in Java, C++ kind of world. And so we're rewriting a lot of the assignments that this causes quarter. Having driving that process so that this course that you could do more of the assignments, maybe all of the assignments in Python numpy instead. Now, note on the honor codes, we actually encourage you to form study groups. So up and fascinated by I've been fascinated by education for a long time. So, in a long time, studying education and pedagogy and how instructors like us can help support you to learn more efficiently. And one of the lessons I've learned from the educational research literature is that for highly technical classes like this, if you form study groups, you will probably have an easier time, right? So, CSU's denying we go for the highly technical material. There's a lot of math, some of the programs are hard, and if you have a group of friends to study with, you probably have an easier time because you can ask each other questions and work together to help each other. When we ask you to draw the line, or what we ask you to do relative to the standards on the code is We ask that you do the homework problems by yourself, right? And and and more specifically is okay to discuss the homework problems of friends, but if you But after discussing homework problems of friends, we ask you to go back and write up the solutions by yourself without referring to notes that you and your friends had developed together. The classes on the code is written clearly on the class on Handel's Posted digitally on the website. So if you ever have any questions about what is the log collaboration and what isn't allowed, please refer to that written document on the course website where we described it more clearly. But all the respect for the San Philanical as well as for students kind of doing their own work, we ask you to basically do your own work for the Zokid discuss it, but after discussing home problems with friends ultimately we ask you to write up your problems by yourself so that the whole world submissions reflect your own work, right? And I care about this because it turns out that having CS239, you know, CS239 is one of those classes that employers recognize. I don't know if you guys know, but there have been companies that have put up job ads that say stuff like, so long as you've got, so long as you complete a CS239, we guarantee you get an interview, right? I've seen stuff like that. And so I think, you know, in order to maintain that sanctity of what it means to be a CS239 competitor, I think, I asked it all of you, sort of really do your own work, or stay within the bounds of a set of collaboration relative to the on the code. Let's see. And I think that if, you know what, this is, and I think that one of the best parts of CS239, it turns out is, excuse me. So, sorry, I'm awkward. So one of the best parts of the class is, oh shoot, sorry about that. All right, no mind, I won't do this. You could do it on, you could do it yourself online later. Yeah, I started using Firefox recently in addition to Chrome. One of the best parts of the class is the class project. One of the goals of the class is to leave you well-qualified to do a meaningful machine learning project. One so one of the best ways to make sure you have that skillset is through this class and hopefully with the help of some of the T8, we want to support you to work on a small group to complete a meaningful machine learning project. And so one thing I hope you start doing later today is to start brainstorming maybe of your friends some of the class projects you might work on. And the most common class project that people do in CS2.9 is to pick an application that excites you and to apply machine learning to it and see if you can build a good machine learning system for some application in the area. And so if you go to the course website, you know, cs229.stamp.edu and look at previous years projects, you see machine learning projects applied to pretty much every imaginable application under the sun. Everything from, you know, diagnosed in cancer, to creating art, to lots of projects applied to other areas of engineering, applying to application areas in double E or mechanical engineering or so on, to applying it to understand literature, to applying it to, I don't know, and so if you look at the previous years projects, many of which are posted on the course website, you can use that as inspiration to see the types of projects students completing those classes are able to do and I also encourage you to, you can look at that for inspiration, to get a sense of what you'll be able to do at the conclusion of this class and also see if looking at previous years projects gives you inspiration for what you might do yourself. So we invite you, I guess, to do class projects in small groups. And so after class today, I also encourage you to start making friends in the class, both for the purpose of forming study groups as well as for the purpose of maybe finding a small group to do a class project with. We ask you the form project groups of up to size three, most project groups end up being size two or three. If you insist on doing it by yourself, right, without any partners, that's actually okay too, you're welcome to do that. But I think often, you know, having one or two others to work with may give you an easier time. And for projects of exceptional scope, if you have a very, very large project, they just cannot be done by three people. Sometimes, you know, let us know and we're open to some project groups of size four, but our expectation, but we do hold projects, you know, with a group of four to a higher standard than projects of size one to three. So what that means is that if your project team size is one, two, or three persons, the grading is one criteria. If your project group is bigger than three persons, we use a strict criteria when it comes to grading class projects. Oh, and that reminds me. I know that, let's see, so for most of you, since this started 9.30 AM on the first day of the quarter, for many of you, this may be, this probably your very first class at Stanford. How many of you, this is your very first class at Stanford? Wow, cool. Okay, awesome. Great. Welcome to Stanford. And if someone makes you just raise their hand, actually raise your hand again. So I hope that maybe after class today, if someone makes you raise your hand, I hope welcome them to Stanford and then say hi and she's so big friends after that. Cool, let's see, in addition to the main lectures that we'll have here on Mondays and Wednesdays, CS3.9 also has discussion sections on held on Fridays that are, and everything we do, including all the lectures and discussion sections that recorded and broadcast through SCPD, through the online website. And one of the discussion sections are taught usually by the TAs on Fridays and attendance at discussion sections is optional. And what I mean is that you know, you know, you're 100% promise there won't be material on the midterm that was sneakin' from the discussion section. So it's 100% optional. And you will be able to do all the homeworks and the projects without attending the discussion section. But what we're used to discussion section for, for the first V discussion sections. So, you know, this week, next week, week after that, we'll use the discussion sections to go over prerequisite material and greater depth. So, go over linear algebra, basic problem statistics, teach you a little bit about Python numpy in case you're less familiar with those programming frameworks. So, do that for the first few weeks. And then for the discussion sections that are held later this quarter, we'll usually use them to go over more advanced optional material. For example, CS239, a lot of the learning algorithms you hear about in the class rely on convex optimization algorithms. But we want to focus the class on the learning algorithms and spend less time on convex optimization. So if you want to come in here about more advanced concepts and convex optimization, we'll defer that to discussion section. And then there are a few other advanced topics, hidden markup models, time series that we're planning to defer to the Friday discussion sections. Okay. So let's see. Cool. And final bit of logistics for there are digital tools that some of you have seen. But for this class, we'll drive a lot of the discussion through the online website Piazza. How many of you have used Piazza before? Okay, cool, most of all of you, that's amazing. Good, so online discussion board for those of you that haven't seen it before but definitely encourage you to participate actively on Piazza and also to answer other students' questions. I think that one of the best ways to learn, as well as contribute back to the causes of ho is if you see someone else ask a question on Piazza, if you jump in and help answer that, that often helps you and helps your classmates. So I strongly encourage you to do that. For those of you that have a private question, sometimes we have students reaching out to us with a personal matter or something that is not appropriate to share on the public forum, in which case you're welcome to email us at the email address as well. And we also, and the cost email address, the teaching slots email address on the course website. You can find it there in contact us. But for anything technical or anything reasonable to share the cost, which includes most technical questions and most logistical questions, right? Questions like, you know, can you confirm what data is in the term or what happens? Can you confirm when's the handout for this going on and so on? For questions that are not personal or private in nature, strongly encourage you to post on P-Onswer rather than emailing us because statistically, you actually get a faster answer posting on P-Onswer than if you wait for one of us to respond to you. And we'll be using great scope as well for online grading. If you don't know what great scope is, don't worry about it. We'll send you links and show you how to use it later. And again, relative to one last logistical thing to plan for, unlike previous years where we taught CS229, so we're constantly updating the syllabus right the technical content to try to show you the latest when she learning algorithms and the two big little changes we're making this year I guess one is a Python instead of MATLAB and the other one is instead of having a midterm exam, you know, there's a timed midterm, we're planning to have a take-home midterm, the squatter, this day. So, I don't know. Some people just breathed in sharply when I said that. I don't know what that means. Was that shock or happiness? Okay. Don't worry, midterm's a fun. You love it. All right, so that's it for the logistical aspects. Let me check the, and so let me check there any questions. Oh yeah, go ahead. Oh, yeah, so that's interesting. Let's see, I think it's offered in spring and one other person. Oh, yes, and teaching it. So someone else is teaching it in spring quarter. I actually did not know it was going to be offered in winter. Yeah. Yeah, right. Yeah. Yeah. So I think I'm a great guy and teaching it. Sorry, you can go for a minute. Teaching it in a screen and I don't think it's offered in Windows. Well, this one section if you record it, yes, it will be. By the way, if you wonder why I'm repeating the question, I know it feels weird. I'm recording for the microphone so that people watching this can hear the question. But both the lectures and the discussion sections will be recorded and put on the website. Maybe the one thing we do that's not recorded and broadcast the office hours, right? Is that right? Oh, but I think this year we have a 60 hour, how many hours? 60 office hours per week. Right? Yeah. So, so hopefully, again, what constantly trying to improve the cause in previous years, one of the feedback we got was that the office hours are really crowded. So, we have 60 slots per week this year. That seems like a lot. So hopefully if you need to track down one of us, track down the tier to get help. Hopefully that'll make it easier for you to do so. Go ahead. Say the game. Well. Oh, well, it just go to the course website and click on the syllabus link, that has a calendar with when each homework assignment is called and when OP-DU. So full homeworks and a project proposal do a few weeks from now and then final projects do at the end of the quarter. But all the exact dates are listed on the course website. Thank you. Sure, yes. Difference between this class and 239A. Let me think how to answer that. Yes. So, yeah, I know I was debating earlier this morning how to answer that, because I've asked that a few times. So I think that what has happened at Stanford is that the volume of demand for machine learning education is just skyrocketing because everyone sees, everyone wants to learn this stuff. And so the computer science department has been trying to grow the number of machine learning offerings we have. We actually kept the enrollment of CS239A at a relatively low number at 100 students. So I actually don't want to encourage too many of you to sign up because I think we might be hitting the enrollment cap already. So please don't all sign up for CS239A because CS239A does not have the capacity to score. But CS239A is a much less mathematical and much more quite relatively more applied version of machine learning. And so I guess I'm teaching CS229, CS229, CS229 Discordero. Of the three, CS229 is the most mathematical. It is a little bit less applied than CS229, which is more applied machine learning and CS230, which is deep learning. My advice to students is that CS229A, let me write this down. I think I'm right. So CS229A is taught in the flip classroom format, which means that students taking it will mainly watch videos on the course of our website and do a lot of programming exercises and then meet for weekly discussion sections. But it's a smaller class with captain enrollment. I would advise you that if you feel ready for CS229 and CS233 to do those, but CS229, you know, because of the map we do, this is a very heavy workload and pretty challenging class, and so if you're not sure if you're ready for CS229A, maybe a good thing to take first. And then CS229, CS229A cover a broader range of machine learning algorithms and CS230 is more focused on deep learning algorithms specifically, which is a much narrower set of algorithms, but it is one of the hottest areas of deep learning. There is not that much overlap in content between the three classes. So if you actually take all three, you learn relatively different things from all of them. In the past, we've had students simultaneously take 229 and 229.8, and there is a little bit of overlap. They do kind of cover related algorithms, but from different points of view. So some people actually take multiple of these causes at the same time. But Studio 9A is more applied, a bit more practical, know how hands on and so on, and much less mathematical. And CS230 is also less mathematical, more applied, more about coming, getting to work, where CS290, we do much more mathematical derivations in CS290. Any other questions? Yes. Someone had a hand. So why don't you say that what I would generally prefer students not do that in the interest of time, but what do you want? Oh, I see. Show a go for it. Who's enrolled in 2009-2030? Oh, not that many of you. Interesting. Oh, that's actually really interesting. Cool. Yeah. Thank you. Yeah. I just didn't want to set a presence of students using this as a forum to run surveys. So that was a interesting question. So thank you. Cool. All right. And by the way, I think just one thing about just one thing about Stanford is the AI world, machine learning world, AI has begun the machine learning, right? And machine learning has begun the deep learning. One of the great things about being a Stanford student is you can, and I think should take multiple classes, right? I think that, you know, CS239 has for many years been the core of the machine learning world at Stanford. But even beyond CS239 is worth your while to take multiple classes and give multiple perspectives. So if you want to be really effective, you know, after you've dragged from Stanford, you do want to be an expert in machine learning. You do want to be an expert in deep learning. And you probably want to know probably some statistics, maybe want to know a bit of confidence optimization, maybe want to know a bit more about reinforcement learning, know a little bit about planning, know a bit about lots of things. So I actually encourage you to take multiple classes, I guess. Cool. All right, good. If there are no more questions, let's go on to talk a bit about machine learning. All right, so the remainder of this class, what I'd like to do is give a quick overview of the major areas of machine learning and also give you an overview of the things you learn in the next 10 weeks. So what is machine learning? It seems to be everywhere these days and it's useful for so many places. that's um and you know and I feel like I'm just a share of my personal bias right you read the news about these people making so much money building learning algorithms I think that's great I hope I hope all of you go make a lot of money but the thing I find even more exciting is the meaningful work we could do right I think that every time there's a major technological disruption, which there is now through machine learning, it gives us an opportunity to remake launch paths of the world. And if we behave ethically in a principal way and use the superpowers of machine learning to do things that helps people's lives. Maybe you can improve the healthcare system, maybe you can improve, give every child a personalized tutor, maybe you can make a democracy run better rather than make it run worse. But I think that the meaning I find in machine learning is that there's so many people that are so eager for us to go in and help them with these tools that if you become good at these tools, it gives you an opportunity to really remake some piece, some meaningful piece of the world, hopefully in a way that helps other people and makes the world kind of, makes the world a better place, is very appreciated in Silicon Valley. But I think with these tools, you actually have the power to do that. And if you go make a ton of money, that's great too. But I find the much greater meaning of the work we could do. It gives us a unique opportunity to do these things. But all the excitement of machine learning, what is machine learning? So let me give you a couple definitions of machine learning. Autosamil, whose claim to fame was building a checklist playing program, defined it as follows. Field study gives computer belief, learn about being a specific program. And, you know, interesting, when Arthur Samuel many, many decades ago wrote a checklist playing program, the debate of the day was, can a computer ever do something that it wasn't explicitly told to do? And Arthur Samuel wrote, Czechoslovakian program, that through self play learned what are the patterns of Czechovo that are more likely to lead to win versus more likely to lose and learn to be even better than Arthur Samuel, the author himself, at playing checkers. So back then, there was this view as a remarkable result that the computer programmer could write a piece of software to do something that the computer programmer himself could not do, right? Because this program became better at Arthur Samuel at the toss of play checkers. And I think today we used computers or machine learning algorithms outperforming humans on so many toss. But it turns out that when you choose a narrow toss, like speech recognition on a certain type of toss, you can maybe surpass human level performance, if you choose a narrow toss like playing the game of Go, then by throwing really tons of accomplished power at it and self-play, you can have a computer, you know, become very good at these narrow toss, but this was maybe one of the first such examples in history of computing. And I think this is the one of the most widely cited definitions, right? Just compute disability learning while being explicitly programmed. My friend Tom Mitchell in his textbook defined this as a well-pulled learning problem. Program set to learn from experience e-respect a TAST on some performance major P, P is measured by P improves experience E. I asked Tom this. I asked Tom if he wrote this definition just because he wanted it to rhyme. He did not say yes, but I don't know. But in this definition, the experience E, in the case of playing checkers, the experience E would be the experience of having a checker's program play tons of games against itself. So computers, lots of patients, and sit there for days playing games of checkers against itself. So that's the experience E. The task T is the task of playing checkers. The performance measure P maybe was the chance of this program winning the next game of checkers at plays against the next opponent. So we say that this is a well-posed learning problem learning thing. Checkers. Now within this set of ideas of machine learning, there are many different tools we use in machine learning. And so in the next 10 weeks, you learn about a variety of these different tools. And so the first of them, and the most widely used one, is supervised learning. Let's see, I want to switch to the white board. Do you guys know how that erase the screen? Oh, look at that. Okay. All right, good. So what I want to do today is really go over some of the major categories of machine learning tools and and and so what you learn in the next by the end of the quarter. So the most widely used machine learning tool is today is supervised learning. Actually, let me check how many many of you know what supervised learning is? Like a two-thirds, half of you maybe? Okay, cool. Let me just briefly define it. Here's one example. Let's say you have a database of housing prices. And so I'm going to plot your data set where on the horizontal axis, I'm going to plot the size of the house in square feet. And then the vertical axis will plot the price of the house. And maybe your data set looks like that. And so horizontal axis, I guess we call this x, and the vertical axis will call that y. So the supervised learning problem is, given the data set like this, the value of the value of the value of the value of the value of the value of say you have a, let's say you're fortunate enough to own a house in Palo Alto, right? And you're trying to sell it, and you want to know how to price the hulls. So maybe your hulls has a size of that amount on the horizontal axis. I don't know, maybe this is a five-inch square feet, 1,000 square feet, 1,500 square feet. So your hulls is 1250 square feet, right? And you want to know, how do you price this hulls? So given data set, one thing you can do is fill the straight line to it. And then you could estimate or predict the price to be whatever value you read off on the vertical axis. So in supervised learning, you are given a data set with imposex and labels y, and your goal is to learn a mapping from x to y. Now, for the straight line to data is maybe the simplest possible learning algorithm, maybe one of the simplest learning algorithms. Given the data set, there's many possible ways to learn and mapping, to learn a function, mapping from the input size to the estimated price. And so maybe you want to fit a quadratic function instead. Maybe that actually fits the data a little bit better. And so how do you choose among different models will be either automatically or manual intervention will be something we'll spend a lot of time talking about. Now to give a little bit more, to define a few more things, this particular example is a problem called a regression problem. And the term regression refers to that the value why you're trying to predict is continuous. In contrast, here is a different type of problem. So a problem that some of my friends were working on and I'll simplify it was a healthcare problem where they were looking at breast cancer, breast tumors, and trying to decide if a tumor is benign or malignant.? So tumor, you know, is of a lump in a woman's breast, can be malign or cancerous or benign, meaning, you have roughly, there's not that harmful. And so if on the horizontal axis, you plot the size of a tumor and on the vertical axis, you plot, is it malignant or not? So malignant means harmful, right? And some tumors are harmful some or not. And so whether it's malignant or not, it takes only two values, one or zero. And so you may have a data set like that. And given this, can you learn a mapping from X to Y so that if a new patient walks into your office, walks into the doctor's office and the tumor sizes, you know, say this. Can you learn the algorithm to figure out from this data? That, you know, it's probably, well, based on this data set, it looks like there's a high chance that that tumor is malignant. So, this is an example of a classification problem. And deterrent classification refers to that why here takes on a discrete number of variables. So for regression problem, why is a real number? I guess technically prices can be rounded off to the nearest dollar and cents. So prices aren't really real numbers. Because you probably not price a house at like pi times 1 million or whatever. But for all practical purposes, prices are continuous. So we call them housing price prediction to be a regression problem, whereas if you have two values, the possible output is 0, 1, call that classification problem. If you have K, the street outputs. So if the two may be malignant, or if they have k-dustreet outputs, so if the two may can be malignant, or if they're five types of cancer, right? So you have one of five possible outputs, then that's also a classification problem. If the output is discrete. Now, I want to find a different way to visualize this data set, which is, let me draw a line on top. And I'm just going to, you know, map all this data on horizontal axis, up, width, onto a line. But, well, let me show you what I'm going to do. I'm going to use a symbol all to denote, right? I hope what I did was clear. So I took the two sets of examples, the positive and negative examples. Positive examples is one, negative examples is zero. And I took all of these examples and kind of pushed them up onto straight line. And I used two symbols, I used O's to denote negative examples. And I use crosses to denote positive examples. So this is just a different way of visualizing the same data, but drawing it on a line and using two symbols to denote the two discrete values around one. So it turns out that in both of these examples, the input x was one dimensional. It was a single row number. For most of the machine learning applications to work with, the input x will be multi-dimensional. You won't be given just one number and also predict another number. Instead, you often be given multiple features and multiple numbers, so predict another number. So for example, instead of just using tumor size to predict, to estimate malignant versus benign tumors, you may instead have two features where one is tumor size and the second is age of the patient and be given the data set. And be given the data set that looks like that. Right? Right? Right now your task is given two input features. So X is tumor size and age, you know, like a two dimensional vector. And your task is given these two input features to predict whether a given tumor is molecular and lupinine. So the new patient walks in the doctor's office and the tumor size is here and the age is here. So that point there, then hopefully you can conclude that this patient's tumor is probably benign, right? Cosfunding is a negative example. And so one thing you learn next week is a learning algorithm that can fit a straight line to the data as follows, kind of like that to separate out the positive and negative examples, separate out the holes in the crosses. And so next week you learn about the logistic regression algorithm, which can do that. Okay. So one of the most interesting things you learn about is, let's see. So, in this example, I drew this set with two input features. When, so I have friends that actually worked on the breast cancer prediction problem, and in practice, you usually have a lot more than one or two features, and usually you have so many features you can't plot them in the board. And so for an actual breast cancer prediction problem, my friends are working on this. We're using many other features, such as, don't worry about what these mean. I guess clump thickness, your uniformity of cell size, uniformity of cell shape, right? At Heejin, how will the cells stick together? Don't worry about what these means, but if you're actually doing this in an actual medical application, there's a good chance that you'll be using a lot more features than just two. And this means that you actually can't plot this data, right. It's too high dimensional. You can't plot things higher than three dimensional, or maybe four dimensional, or something. We have a lot of features, actually difficult to plot this data. I'll come back to this in a second in learning theory. And one of the things you learn about, so as we develop learning algorithms, you learn how to build regression algorithms or classification algorithms that can deal with these relatively larger number of features. One of the most fascinating results you learn is that you also learn about an algorithm called support vector machine, which uses not one or two or three or ten or a hundred or a million input features, but uses an infinite number of input features. So just to clear, in this example, the state of a patient represents this one number, two size. In this example, we get two features. So the state of a patient would represented using two numbers, two size in the age. If you use this list of features, maybe it's a patient that would have represented five or six numbers. But there's an algorithm called the support vector machine that allows you to use an infinite dimensional vector to represent a patient. And how do you deal with that and how can a computer even store an infinite dimensional vector? Computer memory, you can store one row number, two row numbers, but you can't store an infinite number of real numbers in a computer without running out of memory or process speed or whatever. So how do you do that? So we talk about support vector machines and specifically the technical method called kernels, you learn how to build learning algorithms that work with an infinitely long list of features. An infinitely long list of features for which you can imagine that if you have an infinitely long list of numbers to represent a patient, that might give you a lot of information about that patient. And so that is one of the relatively effective learning algorithms to send problems. Okay. So that's supervised learning. And you know, let me just play a video. Show you a fun, slightly older example of supervised learning. It gives you a sense of what this means. But at the heart of supervised learning is the idea that during training, you are given inputs x together with the labels y, and you're given both at the same time. And the job of your learning algorithm is to find a mapping so that given a new x, you can map it to the most appropriate output Y. So this is a very old video made by Dean Palmondo, known for a long time as well, using supervised learning for autonomous driving. This is not stay the art for autonomous driving anymore, but it actually does remarkable to you well. Oh, and as you hear a few technical terms, like back propagation, you learn all those techniques in disk class. And by the end of the class, you will have been learning a very much more effective than what you see here. But let's see this application. Could you turn up the volume? that was built at Carnegie Mellon University many years ago. And what happens is during training, it watches the human drive the vehicle, and I think 10 times a second, it digitizes the image in front of the vehicle. And so that's the picture taken by a front facing camera. And what it does is in order to collect label data, the car, while the human is driving it, records both the image, such as the scene here, as well as the steering direction that was chosen by human. So at the bottom here is the image turned to the gray scale and lower res. And on top, let me pause this for a second, this is the driver direction, the font's kind of blurry, but this text says driver direction. So this is the Y label, the label Y, that the human driver chose. And so the position of this white bar, of this white blob, shows how the human is choosing to steer the car. So in this image, the white blob is a little bit to the left of center, so the human is steering just a little bit to the left. This second line here is the output of the neural network. And initially, the neural network doesn't know how to drive, and so it's just outputting this white smear everywhere. I don't know, did I drive left, right center? I don't know. So I'll put in this gray blur everywhere. And as the algorithm learns using the back propagation learning algorithm or gradient descent, which you learn about, you actually learn about gradient descent this Wednesday. You see that the neural networks outputs becomes less and less of this white smear of supervised learning because the human driver demonstrates inputs x and outputs y. If you see this in front of the car, steer like that, so that's x and y. And after the learning algorithm has learned, you can then, well, he pushes the button, takes a hand off the steering wheel, and then it's using this neural network to drive itself, right? Digitizing the image in front of the load, taking this image and passing it through the learning algorithm through the train neural network, letting the neural network select the steering direction and then using a little motor to turn the wheel. This is slightly more advanced version, which has trained two separate models. One for, I think, a two-lane road, one for a four-lane road. So that's the second and third lines. This is for a two-lane road, this is a four-lane road, and the arbitrator is another algorithm that tries to decide whether the two-lane or the four-lane road model is layer network, and one will see you soon. All right. Oh, all right, fine. We just see the final dramatic moment of switching from one narrow to two narrow. All right. And I think, you know, so this is just using supervised learning to take us input what's in to decide on steering direction. This is not so the art for how self-driving cars are built today, but you know, it could do some things in some limited context. And I think in several weeks you actually be able to build something that is more sophisticated than this. So after supervised learning, we will in this class of spend a bit of time talking about machine learning strategy. I think on the class notes, we annotate this as a learning theory. But what that means is I want to give you the tools to go out and apply learning algorithms effectively. And I think I've been fortunate to have, you know, to know a lot of, I think that I've been fortunate to have, you know, over the years constantly visited lots of great tech companies, more than ones that I've been publicly associated with, right? But often, just to help friends out, I visit various tech companies of the sort of whose products I'm sure are installing on your cell phone. But I often visit tech companies and talk to them, see what they're doing, see if I can help them out. And what I see is that there's a huge difference in the effectiveness of how two different teams could apply the exact same learning algorithm. And I think that what I've seen sadly is that sometimes there will be a team, even in some of the best tech companies, right, the elite AI companies, right, in multiple of them, where you go talk to a team and they'll tell you about something they've been working on for six months and then you can quickly take a look at the data and hear that they're not, they're everything quite working and sometimes you can look at what they're doing and go, yeah, you know, I could have told you six months ago that this approach is never going to work, right? And what I find is that the most skilled machine learning practitioners are very strategic by which I mean that your skill at deciding when you work on the machine learning project, you have a lot of decisions to make, right? Do you collect more data? Do you try a different learning algorithm? Do you rent faster GPUs to train your learning algorithm for longer? Or if you collect more data, what type of data do you collect? Or for all of these architecture choices, using neural networks, well, that's machine-led, just regression, which one do you pick? But there are a lot of decisions you need to make when building these learning algorithms. So one thing that's quite unique to the way we teach is we want to help you become more systematic in driving machine learning as a systematic engineering discipline. So that when one day you are working on machine learning project, you can efficiently figure out what to do next. And I sometimes make an analogy to software engineering. You know, many years ago, I had a friend that would debug code by compiling it, and then this friend would look at all these syntax errors, right, that C++ is compiler outputs, and they thought that the best way to eliminate the errors is to delete all the lines of code with syntax errors, and that was their first seriously. So that did not go well, right? Took me a while to persuade them to start doing that. But so it turns out that when you run a learning algorithm, you know, it almost never works the first time. All right, that's just life. And the way you go about debugging the learning algorithm, we have a huge impact on your efficiency on how quickly you can build effective learning systems. And I think until now, too much of this process of making your learning arborist work well has been a black magic kind of process where you know, has worked on this for decades. So when you run something, you don't know why it's not working well. Hey, what do I do? And what does it say? Oh, yeah I do that. And then because he's so experienced, it works. But I think what we're trying to do with the discipline of machine learning is to evolve it from a black magic tribal knowledge experience-based thing to a systematic engineering process. And so later the squatter, as we talk about machine learning strategy, or talk about learning theory, you try to systematically give you tools on how to go about strategizing. So it can be very efficient in how you yourself, how you can lead a team to build an effective learning system. Because I don't want you to be one of those people that, you know, waste six months on some direction that maybe could have relatively quickly figured out what's not promising. Well, maybe one last analogy, if you're used to optimizing code, right, making code run faster, not Xiaomi have you done that. Less experience software engineers will just dive in and optimize the code to try to make it run faster, right? Let's take the C++ and code and assemble assembly or something. But more experienced people will run a profiler to try to figure out what part of your code is actually the blah blah and act and then just focus on the engine on that. So one of the things hope to do this quarter is convey to you some of these more systematic engineering principles. And actually, very interesting. Actually, I've been writing some of the, how many of you have heard of machine learning you're earning? Oh, just a few of you, interesting. So actually, if any of you are interested, just in my spare time, I've been writing a book to try to codify systematic engineering principles for machine learning. And so if you want to, you know, free draft copy of the book, sign up for a mailing list here. I tend to just write stuff and put it on the internet for free. So if you want to free draft copy of the book, you know, go to this website, enter your email address and the website will send you a copy of the book. Go to this website, enter your email address, and the website will send you a copy of the book. I'll talk a little bit about these engineering principles as well. All right. So first subject, machine learning, second subject, learning theory. And the third major subject we'll talk about is deep learning. And so, you know, the lot of tools in machine learning and many of them are worth learning about. And I use many different tools in machine learning, you know, for many different applications. There's one subset of machine learning that's really hot right now because it's just advancing very rapidly, which is deep learning. And so we'll spend a bit of time talking about deep learning so that you can understand the basics of how to train a neural network as well. But I think that whereas 2.39 covers a much broader set of algorithms which are all useful, CS230 more narrowly covers just deep learning. So other than deep learning, after deep learning, new networks, the fourth of the five major topics we'll cover will be unsupervised learning. So what is unsupervised learning? So you saw me draw a picture like this just now, right? And this would be a classification problem, like the tumor and the ligament benign problem, this is a classification problem. And that was a supervised learning problem because you had to learn a function mapping from x to y. Unsupervised learning would be if I give you a data set like this with no labels. So you just give inputs x and no y. And you're asked to find me something interesting in this data. Figure out interesting structure in this data. And so in this data set, it looks like there are two clusters. And then unsupervised learning algorithm, which you'll learn about called K-means Clustering, would discover this structure in the data. Other examples on supervised learning, you know, if you, actually Google News is a very interesting website. Sometimes I use it to look up latest news. This is an old example. But Google News every day crawls or leads many, many thousands or tens of thousands of news articles on the internet and groups them together. For example, this is a set of articles on the BPR well spill and it has taken a lot of the articles written by different reporters and grouped them together. So you can figure out that with BP, Macondo Oilwell, right, that this is a CNN article about the Oilwell spill, there's a Guardian article about Oilwell spill, and this is an example of a clustering algorithm, where it's taking these different new sources and figuring out that these are all stories kind of about the same thing. And other examples of clustering, just getting data and figuring out what groups belong together. A lot of work on genetic data, this is a visualization of genetic microwave data where given data like this, you can group individuals into different types of individuals, different characteristics. Clustering algorithms grouping the stuff that data is together is used to organize computing clusters, figure out what machines work those are more related to each other and all of those community costs appropriately. So, to take a social network like LinkedIn or Facebook or other social networks and figure out which other groups are friends or which are the cohesive communities within a social network or market segmentation. Actually, many companies have worked with local customer database and cluster the users together. So, you can say that, looks like we're four types of users. You know, looks like that there are the young professionals learning brought the concept of using unlabeled data. So just X and finding interesting things about it. So for example, actually here's shoot. This won't work without audio. We'll do this later in the class, I guess. Maybe I'll see you and do this later. Cartel party problem is another unsuathized learning problem problem really need audio for this to explain this though Everything how to explain this you know, Cartel party problems I'll try to do the demo when we can get all your work on this laptop is a problem where if you have a noisy room and you stick multiple microphones in the room and record overlapping voices, so there are no labels. There are multiple microphones in the room with lots of people talking. How can you have the algorithm separate out the people's voices? That's a non-sue as learning problem because there are no labels. You just stick microphones in the room and have every court different people's voices, overlapping voices, you on the same time and then have it try to separate out people's voices and one of the primary exercises you do later is if we have you know five people talking So each microphone records five people's overlapping voices right because you know each microphone here's five people at the same time How can you have an algorithm separate out these voices so you can clean recordings of just one voice at a time So that's called a cocktail party problem and the algorithm you used to do this is called ICA independent components analysis and that's something you implement in one of the latest homework exercises And there are other examples of us who are learning as well The internet has has tons of unlabeled text data. You just suck down data from the internet. There are no labels necessarily. But can you learn interesting things about language? Figure out one of the best cited results recently was learning analogies like, you know, Manus, the woman is King of the Queen, right? Or what's a Tokyo is to Japan as Washington DC is the United States, right? To learn analogies like that. To say you can learn analogies like that from unlabeled data, just from text on the internet. So there's also unsupervised learning, okay? So after unsupervised learning, oh, and unsupervised learning, so machine learning is very useful today. It turns out that most of the recent wave of economic value created by machine learning is through supervised learning. But there are important use cases for unsupervised learning as well. So I use them in my work occasionally. And it's also a beating edge for a lot of exciting research. And then the final topic, final of the five topics we cover. So talk about supervised learning, machine learning strategy, deep learning, unsupervised learning, and then the fifth one is reinforcement learning is this, which is, let's say I give you the keys to Stanford, Latana, Telecopter. This helicopter is actually studying actually sitting in my office and trying to figure out how to get rid of it. And I'll see the right program to make it fly, right? So how do you do that? So this is a video of a helicopter flying. The audio is just a lot of helicopter noise, so that's not important. But we'll zoom out the video, you can see three sponge in the sky. But so you can use learning algorithms to get robots to do pretty interesting things like this. And it turns out that a good way to do this is through reinforcement learning. So what's reinforcement learning? It turns out that no one knows what's the optimal way to fly a helicopter. If you fly a helicopter, you have two control sticks that you're moving, but no one knows what's the optimal way to move the control sticks. So the way you can get a helicopter fly itself is let the helicopter do whatever. Think of it as training a dog, right? Like how, you can't teach a dog the optimal way to behave, but actually, how many of you have a pet dog or pet cat before? Not that many, that's fascinating. Okay, so I had a pet dog when I was a kid and my family made it my job to train the dog, so I'll be training the dog. You let the dog do whatever it wants and then whenever it behaves well, you go, oh, good dog. And when it misbehaves, you go bad dog. And then over time, the dog learns to do more of the good dog things and fear of the bad dog things. And so reinforcement learning is a bit like that, right? I don't know what's the awful way to fly a helicopter. So you let the helicopter do whatever it wants and then whenever it flies well, you know, does the maneuver you winds or flies accurately without jitting around too much, you go, oh, good helicopter. And when it crashes, you go bad helicopter. And it's the job of the reinforcement learning algorithms to figure out how to control it over time so as to get more of the good helicopter things and feel the bad helicopter things. And I think, well, just one more video. Oh. Interesting. Yeah, all right. And so again, give me the robot like this. I actually don't know how the programmer, actually, you know, the robot like this has a lot of joints, right? So how do you get a robot like this to climb or obstacles? So, well, this is actually a robot dog, so you can actually say good dog or bad dog. But by giving those signals called a reward signal, you can have a learning algorithm figured out by itself how to optimize the reward. Climb over these types of obstacles. And I think recently the most famous application is a reinforcement learning happen for game playing. Playing Atari games or playing game of Go, I think that's a, I think that's a game playing has made for some remarkable stunts, a remarkable PR, but I'm also equally excited, or maybe even more excited about the in-rolls. The reinforcement learning is making it to robot applications. So I think, yeah, reinforcement has been proven to be fantastic for playing games. It's also making road traction in optimizing robots and optimizing the logistics system and things like that. So you learn about all these things. Last thing for today, I hope that you will start to talk, meet people in the class, meet friends, phone project partners and study groups. And if you have any questions, you know, dive on the P out, there are also questions that will help others answer the questions. So let's break for today and look forward to seeing you on Wednesday. Welcome to Tutorial.\"),\n",
       " Document(metadata={'source': 'docs\\\\youtube\\\\特斯拉为何突然上涨？【2025-05-09】.m4a', 'title': '特斯拉为何突然上涨？【2025-05-09】', 'description': '加入阳光财经会员，查看及时成交记录，完整连续。每个月还会定期推出会员视频，解答会员提问。https://www.youtube.com/channel/UC2I5em6UyBpQiO-8ZW0nV3w/join\\nIBKR不止是大券商，还免费提供分析师TIPRANKS一致数据。\\nhttps://www.interactivebrokers.com/mkt/?src=sunnyfinance6&url=%2Fcn%2Fwhyib%2Foverview.php\\n\\n\\n\\n……………………………………………….……………………………………………….\\n声明\\n本人及团队不是Financial Advisor，本节目以过往历史视频均仅供信息参考，不构成投资建议。据本频道提供的信息买卖证券，风险自负，与本节目无关。本人节目中涉及的股票均不存在与任何第三方的利益相关联，但本人可能持有或将来可能买卖相关证券。谢谢您的支持！', 'upload_date': '20250509', 'duration': 712, 'view_count': 55442, 'like_count': 2514, 'channel': '阳光财经', 'channel_url': 'https://www.youtube.com/@SUNNYFINANCE', 'tags': ['美股', '美股分析', '技术分析', '阳光财经', 'Sunny', '中概股', '大盘', '美股大盘', '股息', '被动收入', '大盘分析', '特斯拉', 'saham AS', 'Kewangan Sunshine', '陽光財經'], 'categories': ['People & Blogs'], 'thumbnail': 'https://i.ytimg.com/vi/tkFDeadKz2I/maxresdefault.jpg', 'webpage_url': 'https://www.youtube.com/watch?v=tkFDeadKz2I'}, page_content='Hello 大家好 歡迎回到陽光財經週末點會有重大的變數多頭也不敢在今天輕易發動公視空頭也擔心週末突然有什麼大消息輕易也不敢做空這個可能是大戰前夕市場安靜的下人的表現成交量注撞途尾縮也體現了交投活躍度下降多空雙方圍繞年限的爭奪中多頭掠插一籌一直上不去變盤遲遲不能發動預計下週在週末消息面刺激下將會改變遲遲橫盤趨勢納斯達克指數今天上漲了0.78點保持於昨天收盤基本無辨年限今天人對納指構成壓力與標不相比納指的多頭更蔡了整理了多天人不見一次突破年限若是整理的感覺較為明顯市場急需要一技強新增不然年限下方就是這一年裡買入的籌碼平均是虧損的 彈久避跌週末中美談判會不會成為市場�判的大陆中美双方谈判代表抵达瑞士这是本次贸易战以来的首次接触被媒体称为破冰瑞士日内瓦长期以来被视为中立国和国际外交中心拥有联合国事件贸易组织等众多等眾多國際組織的總部貿易戰開始後中美雙方即使是誰先請求開始談判都存在最大的分歧將持不下終於5月10號兩國代表將進行首次會誤這次的日內瓦破冰到底是誰求誰見面中方外交部發言人表示瑞士会谈是印美方请求举行的而加拿大青总理卡尼和川普见面之后说瑞士会谈是中方要求与美方见面谁在谈判开始实现扶软似乎在整个过程中都会被动所以基于谈判策略谁也不承认是自己要发挤谈樣是貿易戰的談判七年前中美雙方也有一站七年前的中方談判代表是劉鶴現在是何麗峰官職都是副總理主管經濟何麗峰於1955年生於福建龍研夏門大學財政金融系畢業經濟學博士學位他在夏門大學讀了四年的本科六年的说事和博士中国财政学态斗 邓子基是他的老师和立风能不入官场正式邓子基推荐的他的试图也是从福建省开始一路屏幕清雲成为习近平重要习近之一贸易战2.0是一場硬碰硬的較量從一開始我們就感受到了這跟七年前的氛圍完全不同七年前�方援手之間的緩衝地帶與如何相比和利風更像是一個政策的執行者在1991年加入索洛斯基金索洛斯基金在1992年GG陰邦撞了十個億在1991年又GG馬避印尼頓韓園等亞洲貨幣引發亞洲金融風暴貝森特在匯率市場博弈方面戰技輝煌2022年貝森特成功壓住包園會延誏 脱脱拉拉通脚将更为持久双方都需要找台阶下的重要步驟在首次接触破冰前川普提议在谈判前降低对华关税到80%川普的对华关税你看145%80%60%这些数字都出现过竞选时他提的是60%现在是145%即使降到80%人高于竞选时设置的承诺那么在过去两个月中国的出口不降反增數據令人意外中國對美出口大幅下滑但對亞洲和歐洲出口跡增總量居然還是增長的8.1%中國海關數據顯示4月加重關稅以來中國對美國的出口同比下降21%中國進口下降了14%但中國企業通過其他市場增加銷售以彌補對美國出口的下降上個月出口總量增長了8.1%遠高於經濟學家的預測中國對印度和東盟時國的出口飆升20%對歐盟的出口增長了8%貿易從美國轉移到南亞、東南亞和歐洲這樣的數據其實是在告訴美國是你美國需要中國的產品而中國的產品並不缺市場4月出口數據對中方在談判中保持強勢力位有重要的支撐作用80%的关税事实上也是阻碍贸易的开展加剧通脏预期本质上说80%的关税和145%也没有太大的区别但市场会因为看到关税下降而压住做多只要周末有降低关税的新闻下周开盘跳空高快的可能性存在而如果双方什么也没有谈也不会给市場更大的打擊因為之前打擊已經夠大的了特斯拉正在技術助理過程中突破了這條白色線就是底部可能形成的標誌如果能突破300就更好今天的突破有成效量放大因此更為可信那麼為什麼特斯拉突然走牆呢我想股價上漲的原因可能是中美談判和馬斯克回歸中美貿易談判開始在中國有上百萬輛產能的特斯拉率先感受到了利好上海工廠已經成為特斯拉全球最大的出口中心但出口的方向主要是歐洲亞洲和澳大利亞另一個利好是5月份馬斯克逐漸彈出政府效率部將會更多的關注特斯拉這一承諾讓投資者放心馬斯克將優先考慮公司的运营但是特斯拉的业绩不好最新财报各项指标都是亮红灯的所以基本面是无法支撑股价大幅上涨但话说吵特斯拉的人可能也不在乎业绩他们觉得不到1万亿美元投资一个未来可能是机器人巨头和自动价值巨头是有长远潜力的本周被川普罵成是笨蛋的包裕尔也没有在发声到时每年处理事巴尔今天发表讲话称川普将是每年处陷入困境每年处的双重政策目标是充分就业和误价稳定关税将导致两个目标存在冲突关税提升通仗预期并且也增加失业率的风险巴尔说如果关税导致兩個目標存在衝突關稅提升通脹預期並且也增加失業率的風險巴爾說如果關稅導致全球供應鏈中斷產生持續的通脹善型壓力則每年儲家面臨兩難這點我之前分析過這就是智障模式下的貨幣政策無法兼顧通脹善型需要加稀失業善生需要降稀那到底是優優先加息還是優先降息將困擾美聯儲本週的一期會議和包圍而講話表明上半年降息的概率不高數據才是美聯儲政策決策的依據並非總統的直手畫角目前除了GDP負增長的特殊情況之外同場數據、就業數據和宏觀經濟都不足以支持美聯儲降息下週將發布的CPI將有可能影響市場時間是5月13號盤前克利夫蘭聯儲實時通賬預測顯示4月份整體CPI還比增長0.22核心CPI�比增長0.23 整體CPI 同比增長2.34 核心CPI 同比增長2.76 數據持續低燒狀態就是不回歸2% 這一美聯儲設定的政策目標在這樣的數據下6月降息概率恐怕要進一步下降本週因為蘋果服務部門老總在反壟斷案中的證詍中提出人工智能中将替代谷歌传统搜索的消息尘重打击的谷歌的股价今天ARK的木头姐捕了一刀ARK说谷歌将被人工智能替代人工智能将颠覆传统世界的秩序未来每一个人都将拥有一个人工智能助理人类使用搜索引擎查找信息的习惯将成为过去人工智能助理将为我们完成大部分的任务人工智能已经从谷歌夺取了市场奋额未来将取代搜索引擎然后凭过分析师郭明祺也评价了这个事情他认为目前生成是人工智能还没有什么广告业务所以谷歌的廣告認識廣告主的最佳選擇搜索次數必須下降到一定程度才會對廣告業務造成實質形象谷歌的廣告業務不會立刻下滑但是谷歌要避免成為下一個雅護雅護的廣告業務是從1995年起年持续增长到2088年开始走下坡路古哥在2000年开始广告业务在古哥启动广告业务后牙户的广告营收也没有立刻出现摔退那么不管是苹果的库衣天风正确的过敏旗还是ARK的木头节大老门对古哥的未来还是充满担忧的古哥的股价估值低但如果未來幾年業績下降估值了計MSTR的成交金格还排了美股第五可见头击之风盛行啊建立在比特币价格技术上的股价其实是非常不靠谱的要是能够预测比特币直接交易比特币就好了这样风险还单一一些股票有股票独特的风险比如说增发公股好 那我们今天的节目就分享到这里感谢大家收看 转发到中文愉快我们下期节目再见 拜拜'),\n",
       " Document(metadata={'source': 'docs\\\\youtube\\\\美股 下周小心，药企相关！UNH、LLY 走势糟糕！TSLA、AMZN表现不错！TSM、ARM！NVDA和老黄的心酸！.m4a', 'title': '特斯拉为何突然上涨？【2025-05-09】', 'description': '加入阳光财经会员，查看及时成交记录，完整连续。每个月还会定期推出会员视频，解答会员提问。https://www.youtube.com/channel/UC2I5em6UyBpQiO-8ZW0nV3w/join\\nIBKR不止是大券商，还免费提供分析师TIPRANKS一致数据。\\nhttps://www.interactivebrokers.com/mkt/?src=sunnyfinance6&url=%2Fcn%2Fwhyib%2Foverview.php\\n\\n\\n\\n……………………………………………….……………………………………………….\\n声明\\n本人及团队不是Financial Advisor，本节目以过往历史视频均仅供信息参考，不构成投资建议。据本频道提供的信息买卖证券，风险自负，与本节目无关。本人节目中涉及的股票均不存在与任何第三方的利益相关联，但本人可能持有或将来可能买卖相关证券。谢谢您的支持！', 'upload_date': '20250509', 'duration': 712, 'view_count': 55442, 'like_count': 2514, 'channel': '阳光财经', 'channel_url': 'https://www.youtube.com/@SUNNYFINANCE', 'tags': ['美股', '美股分析', '技术分析', '阳光财经', 'Sunny', '中概股', '大盘', '美股大盘', '股息', '被动收入', '大盘分析', '特斯拉', 'saham AS', 'Kewangan Sunshine', '陽光財經'], 'categories': ['People & Blogs'], 'thumbnail': 'https://i.ytimg.com/vi/tkFDeadKz2I/maxresdefault.jpg', 'webpage_url': 'https://www.youtube.com/watch?v=tkFDeadKz2I'}, page_content='大家好 歡迎回到視野環球財經 我是Rino現在是美東世界 二五年5月9日週五晚上的8點25分今天是標普高開不過美國總統川普提出將中國的關稅從145降到80的想法但他們表示這將取決於美國財長貝森特其實如此之高的關税是大幅高于市场的预期所以股市和国债是双双下跌回徒了高开的账赋今天的收盘价和昨天是基本持平不过今天少数的个股市走出了独立行情比如特斯拉特斯拉这边今天是放量上行朝着突破之后就是2007这个突破上行突破之后的下一个波段目标位更上一层楼这个目标位是3 2 6到367但是我这里要提醒一下这个波段目标的压力是比较大的预计一次非常难过去因为这个地方是它上看前高之前最大的压力位置而且从下个星期的月期权结算的位置来看300块钱上下大概是21美元左右的波动这就意味着下个星期的月期全結算的位置來看300塊錢上下大概是21美元左右的波動這對意味著下個星期想去突破壓力是一個非常小的概率但是如果有一些新的關稅其他的利好消息出來走入到小概率區間出外但向上是有機會摸到壓力位的下延的如果下感性机是下跌那么回撤大概是在2008的上方所以特斯拉后面还是继续上看326到367的这个波段那么做波段的朋友自行做好交易计划好 接下来时间我会直接去跟踪讲解一些个国从亚马运开始是一直会讲到李莱首先说亚马运亚马运昨天其实收盘价就已经是占稳了191块钱这个地方咱们之前曾经讲过191占稳之后它就比较稳当了但是它现在在今天收盘第二天收到了191的上方总体上大家也不要期望他能跑得特别的快因为市场对他的波动压住其实并不高下个星期大概是七八块钱左右的上下波动也就是说能够维持在182的强支撰的上方然后逐渐的寻求低点抬高高点也逐渐抬高的这么一个过程因为沿往讯这只股票的特性它不是那种暴力拉升很快几下就拉上去的它是属于罗选市上升这种走势是比较明显的股票所以所以長期持有亞馬遜的朋友如果你是在191到下方的166區間在這個區間進場的朋友暫時你可以拿得比較穩當了沒有什麼太大的問題了如果想做波段的朋友呢讓他講過不要期待他跑得特別的快會是一個比較慢较慢的过程接下来说一下关于台积电首先说一下关于整个的台湾产品出口的一个背景整个的台湾4月份商品出口是同比增长29.9%几乎是市场预期的2倍值得注意的是对于美国的出口同比增长29.5%当然很大程度上是得益于对高科技产品的旺盛需求按照产品来细分信息通信和视频产品比如电脑笔记本显示器的出货量是同比增长60.5%于是同时半导是同比增長28.2%台積電在這個大的背景下4月的銷售也非常的旺盛4月份銷售額是3495.7億新台幣還比增長28.2%同比增長48.1%遠遠超過分析師預期的38%那麼較上個月的46.5%的同比增速有所加快不過現在有一個逆風就是新台幣最近長得非常的厲害飆升這個會給台積電帶來利潤率的壓力台積電以前曾经说过是新台币每拉升1%就升值1%对美元那么营业利润率就会下降0.4个0.4%所以这一块我们今天看到台级电呢尽管是消息面是利好数据也不错但是也是高开低走最终只收涨了0.74%台级店是我的池仓股我对它的看法再重申一下目前由于标普已经突破了关键的反转的5650点位置所以我所有的滚动计划都已经停下来了台级店也不例外台積電的後續的看法因為從台積電現在的前章故事上來看的25年的前瞻是139到中位的19826年的前瞻是166到中位的236所以如果隨著自然力的推演到了越接近26年的自然力它越有機會去打出前高了但不會說這麼快所以這是一個長期的持商看法目前對於台積電沒有任何的加倉和检倉的计划直接持有避免受到关税的影响但是这个希望在前沾上面看起来似乎是有一点点失望因为Arm的管理层预进它的专利费的收入的10%到20%是来自于美国的进口商这些进口商很容易受到美国关税导致的需求批软的影响所以AMM其实是间接受到了关税的影响它没有直接影响但是它受到了间接的由于关税导致的需求皮软的影响其实所有的公司理论上都会受到类似的这种影响就是大部分的公司有一些是直接影响有一些是由于需求减缓导致的红关经济的影响另外最大的一个立空是他不选择不提供2026才年的前瞻指引因為為什麼是26才年的因為他的材料結局是3月剛剛結束的是25才年3月份的這個材料所以他現在是26年3月新的一個材料開始了材料也開始了那麼他不提供指引主要是首席财务官说市场的现在有一些不可预测的信号因为他的合作伙伴非常的谨慎认为现在的潜在的无关经济干扰是主要的原因他的合作伙伴里边几乎没有提供全年之一的所以到他手里边他就更加没有办法预估了他说特别是与关税相关的不确定性增加了另一个不可预测的因素熟悉财务官表示说如果我们提供了一个直引区间那就必须给出一个比去年更广泛的区间他说这个不知道是否会有帮助既然没有帮助他就选择不提供这也是昨天的 这些是先跌然后市场后来回过味来了也不是他自己的原因整个市场现在都面临不缺电信那大家就以不变应万变的然后就选择了在市场收负了跌幅之后的一个横盘好 这个是阿们的情况那么阿们的前张估值呢 继于高倍的参考40到60倍80到120下个才年27年是108到163中卫是136从他的前站批上来看 市价在155块钱已经是前站批高达了接近60倍这并不是一个很便宜的估值所以说暗其实已经蛮打满算的既嫁了它的增长而且这个增长这边我现在是把它给拿掉了暂时增长率预计后面会有调整的目前是基于共时得出来的一个前占估值的情况所以暗之前其实跑到什么180多块钱的很显然是明显高估的现在是逐渐的回归到基本面但是基本上也是把未来两年的增长的价格全部打进去了所以你要说一定要在这个地方要去强行上车那只能说你可能看得更远就是往后再看个三年四年就可以紧从最近两年的情况来看价格至少在一年之内肯定不算便宜 放到明年还可以 放到再过一年 但现在新的财链才刚刚开始 还有整整两年时间好 他的情况目前是一个宽的震荡区间就是上方是12到136压的下方是68.6到80.4就是上次的低点位置顶着这两个区间是他最近的正当区间他只有突破120到136才能确定结束这个正当区域只有突破148才能确定重回上行区间所以它的价格非常的宽也是一支高波動的股票接下來我想說一下英偉達有两位消息是因为达已经通知了包括头部云服务商灾内的中国的主要客户目标是在7月份发布改200的H20芯片可能会避开美国的限制谈到这件事我就开个玩笑多调侃两句我觉得吧这个芯片这事真的是替老黄为难这个事成了一个死循环为什么你看美国政府说老黄高兴能的芯片要限制因为大家说好我修改后降低性能的我们自己有长得不太一样而已。最后是任天堂结化了,说老黄你这个行,未来的Switch3游戏机我们正好能用上。老黄是不是一口劳学得喷下来不断的去降低性能配合出口的要求但是又面临着中国的竞争对手的竞争本来是高性能的领先的产品高利润毛利率的产品一定要做成低利润低毛利的产品而且本来是一片南海市场的非要跑到红海市场里边去抢夺所以有时候我们说生意归生意其实这波许可症的限制英伟达是产生了额外55亿的费用损失市场预计如果加上赢收的损失可能高达一百亿美元这个是实实在在的损失这个和鼓励美国企业创新支持美国制造的大的思路它是不相符的美国政府必须得拿出细节方案就是到底怎么在保护美国的国家安全还有保护美国企业之间找到一个平衡才行 对不对所以咱们耐心等待下一步美国政府对于芯片关税出口的新的政策细节因为之前不是说要拿掉拜登的三级分类管制嘛那可能要推出一些新的政策咱们看看后面会怎么办这是因为达价格方面就不多说了突破125他才能够确认指跌突破125例的不远还有机会别看今天下跌了实际上今天是个缩量问题不大好来看一下XP的我们在线预定商的财务信息它是第一财纪的财报非常的糟糕盘后其实今天还收服了不少的跌幅之前跌得更多由于公司在一季度财报中描绘了美国境内还有入境旅游需求的案弹前景所以这是股价大跌最主要的原因由需求弱于预期的局面前占给的更差所以优在公司的财报会议上说4月份的业级是略训于3月份而且下条了全年的预定量和收入预期他说目前预计这两项指标的增长幅度只在2%到4%之间之前给的前卵是4%到6%所以也是差不多腰展所以他的錢債估值給大家做完更新是這樣16.5倍到30.8倍的歷數博動25年的錢債是166到310大家看中位高位太高了166到23826年是199到286增速我这里没有写因为市场与记以后面面临的红关风险有可能会让他继续的下条前站这是目前看到的在这个行业里边由于EXP的生意模式经常会有朋友会把它和BKNG来做比较为什么BKNG的价格会好一点然后EXP的价格就比较皮软最主要的原因是两边的生意模式的主营队项不一样EXP的对企业的就是B2B的这个客户一层度非常的高另外BKNG它是B2C比较高所以红关经济的影响影响到企业的支出你想想如果经济大环节不好企業在支出上會稍微的請深一些那你猜旅、住宿、預定你可能都會降下來包括我們現在看到影響到了航空業也是這個原因就是因為大的經濟環境的不穩定企業其實也在減少贏的支出希望能夠保持更多的利潤所以以前可能你出差一年得七八四五六四的朋友现在可能你一年也就出去一次以前可能让你出去住非常好的酒店的朋友现在告诉你你就FBNB湊回一下得了所以这个就不一样这是宏观大经济环境对于这个在线的包括预定 旅行等等企业类要省钱这是他的目前的情况不过好的是下方的几个强制生比较的强从132到154是他比较不错的就是上次的低点到现在的强制生区域如果这个地方能盘出一个底来这个地方还行这个地方还是长线还是因为属于低估的位置还是相对可以的但是你要做好前站继续下条的准备取决于能下条多少如果它从增长转入摔退那就是另外一个故事了好吧好然后我们来看一下另外两个医药相关的一个U and H一个是理来首先说一下U and HU and H最近是麻烦不断一个是业绩成压 第二个是集体诉讼第三个是可能还会面临着依保药费用的改革问题今天是已经跌破了389块钱UH咱们上次讲过一次因为它的前脏孤之的下线目前是400它不应该跌破400就是这个389到426本来是非常强的一个支撑位置也是前章估值的下显位置他不应该跌破而一旦跌破进入低估区域同时失手了最近的强制称代表着机构也正在失去信心风险还在放大所以现在英文史的位置是先寻求指跌为主尽管可能会在下方的370到3701这一线有所反弹但是反弹的目标也只能再是看到389到426因为这是一个关键位置现在是滴破位了如果还没有持有的朋友那么最好的先不要早期进场什么时候能指跌能衡处一个底来再说如果已经持有的朋友要么跌破之后其实你可能已经做过处理了要么你就是没做处理的等反弹之后也得思考一下还值不值得继续冒险因为现在美国的要行业这边也正在面临着一些变化我们就要讲这个变化是什么现在的智要行业要行业面临着来自于政策方面的有三个可能会重大的调整这些东西这个信息有可能在下个星期会有初步的信息出来第一个是关税的调整这是一直在谈的因为有一些药品涉及到关税的问题第二美国药品定价的威胁有可能会把药品的价格给打下来第三就是对药�品送達美國患者的速度的威脅就是有要求對於送貨給藥物送到美國患者身上其實這幾個東西他們都是一個東西就是對於醫藥行業進行改革那麼每個中央的川普表示說藥品定價的相关消息即将到来我们下个星期就会公布其中的78倍政府很可能会限制药价限制药价比如很多的药期对吧像李莱他的�价是不是比较高啊为什么下跌也是因为这些利空市场的现在有点害怕不知道会怎么去限制李莱公司对于下条要价他在给媒体的电子油件回复中是这么说的啊说最会国定价是一种误导性的要品价格调整常试它对患者毫无意处同时还会危急生物质药公司进其宣布的近2,000亿美元的美国的新投资其他的公司没有立即回应智平请求那么李来回应了说明什么说明它很害怕因为它的药价高如果真的限制对他的利润是严重的打击尽管他的药效会好一些但他的药价也会更高的咱们之前还做过一个调查就是在李莱和MGO之间你会选择谁就是如果你能负担的起的情况下很多朋友还是选择能负担的起的情況下選擇要效較好的但現在如果價格被打下來那就會存在一個問題就是毛利潤會下來但是可能銷量會上去就看這裡邊兩邊的拉扯怎麼辦但對於公司來講他們總體上是利空所以下個星期我是建議手上持有要起的朋友要注意一下如果政策真的要求大幅降低要价一定会影响到公司的业绩和持有的信心特别是相对有高估部分的一些要起大家千万要注意不能再追了而且你要做好一定的防御的心态如果你是正在等待做要起比如像李萊这样的对吧711到791是激进的长现为什么是激进的因为你可以看一下他现在25年的前瞻本身就是基于30到40倍的高参考是64 4到859中卫是751那么如果不是基于这么高的增长他的利润下来了呢是不是有这么高的倍数增长呢这是值得去思考的问题所以我才说这个地方是激进的啊如果真的要加下来他也跌破了711会直接下看650的下方代表着前南固执已经市场的从机构层面已经是做出了一些调整好吧所以希望大家下个星期关注一下要起相关的信息生物质药最近很多的公司走得都非常差也主要是受到这些相关的药物改革医疗改革相关信息的影响好这个就是今天带给大家的關於市場的一些個股的更新和解讀在州務的時候那給大家也都講了不少相信大家週末的時候如果拿出來看一看應該還是會有一些幫助的那麼本週末最大的消息我們就是耐心的去等待中美的關稅的第一次談判看看大家能不能吧至少有一個相对友好的氛围吧咱们不说第一次能谈出个什么结果来至少双方谈完之后出来以后都不是怒气冲天对吧都不是互相扯皮而是以一种比较友好的态度共同发表了一些声明一些框架这个就是好消息大家不要对细节暂时抱有太大的希望没有这么快我们通过美国和其他国家的谈判的周期来看不可能有这么快得出结果你再快的话一个一个星期你稍微卖一点一个月两个月都有可能的但是开始谈了这个就是好消息啊然后到了周日的时候呢 仍舊会去更新这个打一体就是在社区下面你加入这个级别之后啊 让我打一级别你会到社区下面载一个带有QA和时间图片的铁字 你在评论区提问每天呢 我的会抽供回答周末的时候会稍微挤压一下好 这个就是咱们今天节目的全部内容希望大家周末呢 也好好的养经序内吧预计呢 計因為下個星期還有月期全的結算再加上中美關稅本週末的消息還有要起的改革的一些消息還有可能會有半導體關稅的一些消息總之一堆亂麻結合到一塊市場也不會太太平今天節目我们今天节目到这非常感谢大家持续不断的点赞评论 准发那我们就下个星期一的同一时间 不见 不散')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38c2c985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs\\\\youtube\\\\特斯拉为何突然上涨？【2025-05-09】.m4a',\n",
       " 'title': '特斯拉为何突然上涨？【2025-05-09】',\n",
       " 'description': '加入阳光财经会员，查看及时成交记录，完整连续。每个月还会定期推出会员视频，解答会员提问。https://www.youtube.com/channel/UC2I5em6UyBpQiO-8ZW0nV3w/join\\nIBKR不止是大券商，还免费提供分析师TIPRANKS一致数据。\\nhttps://www.interactivebrokers.com/mkt/?src=sunnyfinance6&url=%2Fcn%2Fwhyib%2Foverview.php\\n\\n\\n\\n……………………………………………….……………………………………………….\\n声明\\n本人及团队不是Financial Advisor，本节目以过往历史视频均仅供信息参考，不构成投资建议。据本频道提供的信息买卖证券，风险自负，与本节目无关。本人节目中涉及的股票均不存在与任何第三方的利益相关联，但本人可能持有或将来可能买卖相关证券。谢谢您的支持！',\n",
       " 'upload_date': '20250509',\n",
       " 'duration': 712,\n",
       " 'view_count': 55442,\n",
       " 'like_count': 2514,\n",
       " 'channel': '阳光财经',\n",
       " 'channel_url': 'https://www.youtube.com/@SUNNYFINANCE',\n",
       " 'tags': ['美股',\n",
       "  '美股分析',\n",
       "  '技术分析',\n",
       "  '阳光财经',\n",
       "  'Sunny',\n",
       "  '中概股',\n",
       "  '大盘',\n",
       "  '美股大盘',\n",
       "  '股息',\n",
       "  '被动收入',\n",
       "  '大盘分析',\n",
       "  '特斯拉',\n",
       "  'saham AS',\n",
       "  'Kewangan Sunshine',\n",
       "  '陽光財經'],\n",
       " 'categories': ['People & Blogs'],\n",
       " 'thumbnail': 'https://i.ytimg.com/vi/tkFDeadKz2I/maxresdefault.jpg',\n",
       " 'webpage_url': 'https://www.youtube.com/watch?v=tkFDeadKz2I'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea326e",
   "metadata": {},
   "source": [
    "**Note**: This can take several minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d02460",
   "metadata": {},
   "source": [
    "## URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09434f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "668d6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7708cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "handbook/37signals-is-you.md at master · basecamp/handbook · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign up\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Product\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Packages\n",
      "        Host and manage packages\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cod\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90673a7",
   "metadata": {},
   "source": [
    "## Notion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a079e",
   "metadata": {},
   "source": [
    "Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "\n",
    "- Duplicate the page into your own Notion space and export as Markdown / CSV.\n",
    "- Unzip it and save it as a folder that contains the markdown file for the Notion page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd29f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899134d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
